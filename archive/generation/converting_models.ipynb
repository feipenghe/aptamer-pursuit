{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File to convert .pth models into the .h5 tensorflow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "hydrophobicity = {'G': 0, 'A': 41, 'L':97, 'M': 74, 'F':100, 'W':97, 'K':-23, 'Q':-10, 'E':-31, 'S':-5, 'P':-46, 'V':76, 'I':99, 'C':49, 'Y':63, 'H':8, 'R':-14, 'N':-28, 'D':-55, 'T':13}\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*13 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "aa_dict = dict(zip(aa_list, pvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LedidiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LedidiNet, self).__init__()\n",
    "        self.name = \"LedidiNet\"\n",
    "\n",
    "        self.cnn_1 = nn.Conv1d(2, 100, 3) \n",
    "        self.cnn_2 = nn.Conv1d(100, 200, 3, padding=2) \n",
    "        self.cnn_3 = nn.Conv1d(200, 400, 3, padding=2) \n",
    "        self.cnn_4 = nn.Conv1d(400, 600, 3, padding=2) \n",
    "        self.cnn_5 = nn.Conv1d(600, 300, 3, padding=2)\n",
    "        self.cnn_6 = nn.Conv1d(300, 100, 3, padding=2)\n",
    "        self.cnn_7 = nn.Conv1d(100, 50, 3, padding=2) \n",
    "\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "\n",
    "        self.cnns = nn.Sequential(self.cnn_1, self.maxpool, self.softplus, \n",
    "                                     self.cnn_2, self.maxpool, self.softplus,\n",
    "                                     self.cnn_3, self.maxpool, self.softplus,\n",
    "                                     self.cnn_4, self.maxpool, self.softplus,\n",
    "                                     self.cnn_5, self.maxpool, self.softplus,\n",
    "                                     self.cnn_6, self.maxpool, self.softplus, \n",
    "                                     self.cnn_7, self.maxpool, self.softplus)\n",
    "\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "    \n",
    "    def forward(self, pair):\n",
    "        x = self.cnns(pair)\n",
    "        x = x.view(-1, 1).T\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model:  LedidiNet  at epoch:  1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "model = LedidiNet()\n",
    "model_name = model.name\n",
    "model_id = \"06242020\"\n",
    "model.to(device)\n",
    "\n",
    "checkpoint = '../model_checkpoints/binary/%s/%s.pth' % (model_name, model_id)\n",
    "checkpointed_model = torch.load(checkpoint)\n",
    "model.load_state_dict(checkpointed_model['model_state_dict'])\n",
    "init_epoch = checkpointed_model['epoch'] +1\n",
    "print(\"Reloading model: \", model.name, \" at epoch: \", init_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dummy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratedDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        def construct_generated_dataset(k):\n",
    "            S_new = []\n",
    "            for _, i in enumerate(tqdm.tqdm(range(k))):\n",
    "                pair = (get_x(), get_y())\n",
    "                S_new.append(pair)\n",
    "            np.random.shuffle(S_new)\n",
    "            return S_new\n",
    "        \n",
    "        # Sample x from P_X (assume apatamers follow uniform)\n",
    "        def get_x():\n",
    "            x_idx = np.random.randint(0, 4, 40)\n",
    "            x = \"\"\n",
    "            for i in x_idx:\n",
    "                x += na_list[i]\n",
    "            return x\n",
    "\n",
    "        # Sample y from P_y (assume peptides follow NNK)\n",
    "        def get_y():\n",
    "            y_idx = np.random.choice(20, 7, p=pvals)\n",
    "            y = \"M\"\n",
    "            for i in y_idx:\n",
    "                y += aa_list[i]\n",
    "            return y\n",
    "        self.gen_ds = construct_generated_dataset(n)\n",
    "    def __len__(self):\n",
    "        return len(self.gen_ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.gen_ds[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to stacked translate sequence\n",
    "def stacked_translate(sequence, seq_type='peptide', single_alphabet=True):\n",
    "    if single_alphabet:\n",
    "        apt = sequence[0]\n",
    "        pep = sequence[1]\n",
    "        \n",
    "        encoding = np.zeros((2, len(apt)))\n",
    "        \n",
    "        # Encode the aptamer first\n",
    "        for i in range(len(apt)):\n",
    "            char = apt[i]\n",
    "            idx = na_list.index(char)\n",
    "            encoding[0][i] = idx\n",
    "            \n",
    "        # Encode the peptide second\n",
    "        for i in range(len(pep)):\n",
    "            char = pep[i]\n",
    "            idx = aa_list.index(char)\n",
    "            encoding[1][i] = idx\n",
    "        return encoding     \n",
    "\n",
    "# Convert a pair to one-hot tensor\n",
    "def convert(apt, pep, label, single_alphabet=False): \n",
    "    if single_alphabet:\n",
    "        pair = stacked_translate([apt, pep], single_alphabet=True) #(2, 40)\n",
    "        pair = torch.FloatTensor(np.reshape(pair, (-1, pair.shape[0], pair.shape[1]))).to(device)\n",
    "        label = torch.FloatTensor([[label]]).to(device)\n",
    "        return pair, label\n",
    "    else:\n",
    "        apt = translate(apt, seq_type='aptamer') #(40, )\n",
    "        pep = translate(pep, seq_type='peptide') #(8, )\n",
    "        apt = torch.FloatTensor(np.reshape(apt, (-1, 1, apt.shape[0]))).to(device) #(1, 1, 40)\n",
    "        pep = torch.FloatTensor(np.reshape(pep, (-1, 1, pep.shape[0]))).to(device) #(1, 1, 8)\n",
    "        label = torch.FloatTensor([[label]]).to(device)\n",
    "        return apt, pep, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1852.61it/s]\n"
     ]
    }
   ],
   "source": [
    "S_new = GeneratedDataset(2)\n",
    "p_val, l_val = convert(S_new[0][0], S_new[0][1], 0, single_alphabet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.Tensor(p_val)\n",
    "dummy_input.requires_grad=True\n",
    "\n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "ONNX_MODEL_PATH = \"ledidi_net.onnx\"\n",
    "torch.onnx.export(model, dummy_input, ONNX_MODEL_PATH, verbose=True, input_names=input_names, output_names=output_names )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
