{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "k = 10000\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*13 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "aa_dict = dict(zip(aa_list, pvals))\n",
    "encoding_style = 'clipped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original BLOSUM62 matrix\n",
    "original_blosum62 = {}\n",
    "with open('../blosum62.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        split_line = line.strip().split()\n",
    "        aa = split_line[0]\n",
    "        encoding = [int(x) for x in split_line[1:-3]]\n",
    "        original_blosum62[aa] = encoding\n",
    "blosum_matrix = np.zeros((20, 20))\n",
    "for i, aa in enumerate(original_blosum62.keys()):\n",
    "    sims = original_blosum62[aa]\n",
    "    for j, s in enumerate(sims):\n",
    "        blosum_matrix[i][j] = s   \n",
    "u, V = LA.eig(blosum_matrix)\n",
    "clipped_u = u\n",
    "clipped_u[clipped_u < 0] = 0\n",
    "lamb = np.diag(clipped_u)\n",
    "T = V\n",
    "clip_blosum62 = {}\n",
    "for i, aa in enumerate(original_blosum62.keys()):\n",
    "    clip_blosum62[aa] = np.dot(np.sqrt(lamb), V[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide = \"MTATRLST\"\n",
    "aptamer_0 = np.full((40, 4), 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects peptides to be encoding according to BLOSUM62 matrix\n",
    "# Expects aptamers to be one hot encoded\n",
    "class BlosumLinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BlosumLinearNet, self).__init__()\n",
    "        self.name = \"BlosumLinearNet\"\n",
    "        self.single_alphabet = False\n",
    "        \n",
    "        self.fc_apt_1 = nn.Linear(160, 200) \n",
    "        self.fc_apt_2 = nn.Linear(200, 250)\n",
    "        self.fc_apt_3 = nn.Linear(250, 300)\n",
    "        \n",
    "        self.fc_pep_1 = nn.Linear(160, 200)\n",
    "        self.fc_pep_2 = nn.Linear(200, 250)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc_apt = nn.Sequential(self.fc_apt_1, self.fc_apt_2, self.fc_apt_3)\n",
    "        self.fc_pep = nn.Sequential(self.fc_pep_1, self.fc_pep_2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(550, 600)\n",
    "        self.fc2 = nn.Linear(600, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        apt = self.fc_apt(apt)\n",
    "        pep = self.fc_pep(pep)\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc2(self.fc1(x))\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model:  BlosumLinearNet  at epoch:  34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BlosumLinearNet(\n",
       "  (fc_apt_1): Linear(in_features=160, out_features=200, bias=True)\n",
       "  (fc_apt_2): Linear(in_features=200, out_features=250, bias=True)\n",
       "  (fc_apt_3): Linear(in_features=250, out_features=300, bias=True)\n",
       "  (fc_pep_1): Linear(in_features=160, out_features=200, bias=True)\n",
       "  (fc_pep_2): Linear(in_features=200, out_features=250, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc_apt): Sequential(\n",
       "    (0): Linear(in_features=160, out_features=200, bias=True)\n",
       "    (1): Linear(in_features=200, out_features=250, bias=True)\n",
       "    (2): Linear(in_features=250, out_features=300, bias=True)\n",
       "  )\n",
       "  (fc_pep): Sequential(\n",
       "    (0): Linear(in_features=160, out_features=200, bias=True)\n",
       "    (1): Linear(in_features=200, out_features=250, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=550, out_features=600, bias=True)\n",
       "  (fc2): Linear(in_features=600, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reinstantiate the model with the proper weights\n",
    "model = BlosumLinearNet()\n",
    "model_name = model.name\n",
    "model_id = \"07132020\"\n",
    "model.to(device)\n",
    "checkpointed_model = '../model_checkpoints/binary/%s/%s.pth' % (model_name, \"07102020\")\n",
    "checkpoint = torch.load(checkpointed_model)\n",
    "optimizer = SGD(model.parameters(), lr=1e-2)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "init_epoch = checkpoint['epoch'] +1\n",
    "print(\"Reloading model: \", model.name, \" at epoch: \", init_epoch)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the peptide appropriately\n",
    "def blosum62_encoding(sequence, seq_type='peptide', single_alphabet=False, style=encoding_style):\n",
    "    if single_alphabet:\n",
    "        pass\n",
    "    else:\n",
    "        if seq_type == 'peptide':\n",
    "            encoding = []\n",
    "            for i in range(len(sequence)):\n",
    "                if style == \"clipped\":\n",
    "                    encoding.append(clip_blosum62[sequence[i]])\n",
    "                else:\n",
    "                    encoding.append(original_blosum62[sequence[i]])\n",
    "            encoding = np.asarray(encoding)\n",
    "        else:\n",
    "            #Translation\n",
    "            letters = na_list\n",
    "            encoding = np.zeros(len(sequence))\n",
    "            for i in range(len(sequence)):\n",
    "                char = sequence[i]\n",
    "                idx = letters.index(char)\n",
    "                encoding[i] = idx\n",
    "        return encoding \n",
    "# Convert a pair to one-hot tensor\n",
    "def convert(apt, pep, label, single_alphabet=False): \n",
    "    if single_alphabet:\n",
    "        pair = translate([apt, pep], single_alphabet=True) #(2, 40)\n",
    "        pair = torch.FloatTensor(np.reshape(pair, (-1, pair.shape[0], pair.shape[1]))).to(device)\n",
    "        label = torch.FloatTensor([[label]]).to(device)\n",
    "        return pair, label\n",
    "    else:\n",
    "        pep = blosum62_encoding(pep, seq_type='peptide') \n",
    "        apt = torch.FloatTensor(np.reshape(apt, (-1, apt.shape[1], apt.shape[0]))).to(device) #(1, 4, 40)\n",
    "        pep = torch.FloatTensor(np.reshape(pep, (-1, pep.shape[1], pep.shape[0]))).to(device) #(1, 20, 8)\n",
    "        \n",
    "        label = torch.FloatTensor([[label]]).to(device)\n",
    "        return apt, pep, label\n",
    "\n",
    "# Getting the output of the model for a pair (aptamer, peptide)\n",
    "def update(x, y, p, single_alphabet=False):\n",
    "    if single_alphabet:\n",
    "        p.requires_grad=True\n",
    "        p = p.to(device)\n",
    "        out = model(p)\n",
    "        return out\n",
    "    else:\n",
    "        x.requires_grad=True\n",
    "        y.requires_grad=False\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = model(x, y)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n",
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n",
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n",
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n",
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n",
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n",
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n",
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n",
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n",
      "torch.Size([1, 4, 40])\n",
      "tensor([[[ 0.0101, -0.0040, -0.0188,  0.0125,  0.0080, -0.0017, -0.0206,\n",
      "           0.0119,  0.0043, -0.0057, -0.0234,  0.0106, -0.0015, -0.0121,\n",
      "          -0.0249,  0.0111,  0.0008, -0.0052, -0.0257,  0.0125,  0.0058,\n",
      "           0.0017, -0.0232,  0.0146,  0.0087,  0.0012, -0.0146,  0.0182,\n",
      "           0.0026, -0.0070, -0.0266,  0.0112,  0.0086, -0.0011, -0.0193,\n",
      "           0.0158,  0.0093, -0.0033, -0.0165,  0.0207],\n",
      "         [ 0.0013, -0.0055, -0.0228,  0.0099,  0.0009, -0.0039, -0.0243,\n",
      "           0.0118,  0.0102, -0.0012, -0.0171,  0.0231,  0.0070, -0.0010,\n",
      "          -0.0237,  0.0162,  0.0022, -0.0020, -0.0236,  0.0144,  0.0060,\n",
      "          -0.0020, -0.0195,  0.0167,  0.0060, -0.0030, -0.0188,  0.0149,\n",
      "           0.0085, -0.0015, -0.0177,  0.0162, -0.0018, -0.0136, -0.0229,\n",
      "           0.0110,  0.0052, -0.0067, -0.0221,  0.0239],\n",
      "         [ 0.0106, -0.0063, -0.0308,  0.0105,  0.0163,  0.0010, -0.0247,\n",
      "           0.0128,  0.0087,  0.0023, -0.0172,  0.0167,  0.0061, -0.0038,\n",
      "          -0.0239,  0.0124,  0.0065, -0.0007, -0.0089,  0.0196,  0.0168,\n",
      "           0.0006, -0.0165,  0.0191,  0.0207,  0.0010, -0.0200,  0.0158,\n",
      "           0.0065, -0.0036, -0.0232,  0.0164,  0.0093, -0.0020, -0.0154,\n",
      "           0.0169,  0.0095, -0.0020, -0.0205,  0.0190],\n",
      "         [ 0.0083, -0.0010, -0.0117,  0.0274,  0.0023, -0.0061, -0.0244,\n",
      "           0.0201,  0.0044, -0.0029, -0.0240,  0.0208, -0.0005, -0.0050,\n",
      "          -0.0248,  0.0175, -0.0064, -0.0138, -0.0283,  0.0119,  0.0039,\n",
      "          -0.0014, -0.0186,  0.0209, -0.0029, -0.0047, -0.0252,  0.0118,\n",
      "          -0.0021, -0.0088, -0.0202,  0.0161,  0.0009, -0.0078, -0.0135,\n",
      "           0.0173, -0.0014, -0.0061, -0.0278,  0.0192]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    for i in range(40):\n",
    "        a, p, l = convert(aptamer_0, peptide, 1, single_alphabet=False)\n",
    "        print(str(a.shape))\n",
    "        train_score = update(a, p, None, single_alphabet=False)\n",
    "        train_score.backward()\n",
    "        print(str(a.grad))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
