{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio import pairwise2\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "k = 10000\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "hydrophobicity = {'G': 0, 'A': 41, 'L':97, 'M': 74, 'F':100, 'W':97, 'K':-23, 'Q':-10, 'E':-31, 'S':-5, 'P':-46, 'V':76, 'I':99, 'C':49, 'Y':63, 'H':8, 'R':-14, 'N':-28, 'D':-55, 'T':13}\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*13 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "aa_dict = dict(zip(aa_list, pvals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset():\n",
    "    with open(aptamer_dataset_file, 'r') as f:\n",
    "        aptamer_data = json.load(f)\n",
    "    ds = []\n",
    "    for aptamer in aptamer_data:\n",
    "        peptides = aptamer_data[aptamer]\n",
    "        for peptide in peptides:\n",
    "            ds.append((aptamer, peptide))\n",
    "    ds = list(set(ds)) #removed duplicates\n",
    "    return ds\n",
    "\n",
    "# Sample x from P_X (assume apatamers follow uniform)\n",
    "def get_x():\n",
    "    x_idx = np.random.randint(0, 4, 40)\n",
    "    x = \"\"\n",
    "    for i in x_idx:\n",
    "        x += na_list[i]\n",
    "    return x\n",
    "\n",
    "# Sample y from P_y (assume peptides follow NNK)\n",
    "def get_y():\n",
    "    y_idx = np.random.choice(20, 7, p=pvals)\n",
    "    y = \"M\"\n",
    "    for i in y_idx:\n",
    "        y += aa_list[i]\n",
    "    return y\n",
    "\n",
    "# S'(train/test) contains S_train/S_test with double the size of S_train/S_test\n",
    "def get_S_prime(kind=\"train\"):\n",
    "    if kind == \"train\":\n",
    "        dset = S_train\n",
    "    else:\n",
    "        dset = S_test\n",
    "    k = len(dset)\n",
    "    S_prime_dict = dict.fromkeys(dset, 0) #indicator 0 means in S\n",
    "    for _ in range(k):\n",
    "        pair = (get_x(), get_y())\n",
    "        S_prime_dict[pair] = 1 #indicator 1 means not in S\n",
    "    S_prime = [[k,int(v)] for k,v in S_prime_dict.items()] \n",
    "    np.random.shuffle(S_prime)\n",
    "    return S_prime\n",
    "\n",
    "# S new contains unseen new examples\n",
    "def get_S_new(k):\n",
    "    S_new = []\n",
    "    for i in range(k):\n",
    "        pair = (get_x(), get_y())\n",
    "        S_new.append(pair)\n",
    "    np.random.shuffle(S_new)\n",
    "    return S_new\n",
    "    \n",
    "# Returns pmf of an aptamer\n",
    "def get_x_pmf():\n",
    "    return 0.25**40\n",
    "\n",
    "# Returns pmf of a peptide\n",
    "def get_y_pmf(y):\n",
    "    pmf = 1\n",
    "    for char in y[1:]: #skips first char \"M\"\n",
    "        pmf *= aa_dict[char]\n",
    "    return pmf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_dataset_file = \"../data/aptamer_dataset.json\"\n",
    "S = construct_dataset()\n",
    "n = len(S)\n",
    "m = int(0.8*n) #length of S_train\n",
    "S_train = S[:m]\n",
    "S_test = S[m:]\n",
    "#S_prime_train = get_S_prime(\"train\") #use for sgd \n",
    "#S_prime_test = get_S_prime(\"test\") #use for sgd \n",
    "#S_new = get_S_new(10*n) #use for eval\n",
    "#train_ds = np.hstack((S_train, S_prime_train[:len(S_prime_train)//2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetSimple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv1dModelSimple, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv1d(40, 100, 3) \n",
    "        self.cnn_apt_2 = nn.Conv1d(100, 50, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv1d(8, 50, 3)\n",
    "        self.cnn_pep_2 = nn.Conv1d(50, 25, 1)\n",
    "        self.cnn_pep_3 = nn.Conv1d(25, 10, 1)\n",
    "\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.name = \"ConvNetSimple\"\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu, self.cnn_apt_2, self.relu)\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu, self.cnn_pep_2, self.relu)\n",
    "        \n",
    "        self.fc1 = nn.Linear(275, 1)\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt(apt)\n",
    "        apt = self.relu(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        pep = self.relu(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearConv1dModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearConv1dModel, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv1d(40, 100, 3) \n",
    "        self.cnn_pep_1 = nn.Conv1d(8, 50, 3)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.name = \"LinearConv1dModel\"\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu)\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu)\n",
    "        \n",
    "        self.fc1 = nn.Linear(550, 1)\n",
    "        self.conv_type = '1d'\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dModelSimple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv1dModelSimple, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv1d(40, 100, 3) \n",
    "        self.cnn_apt_2 = nn.Conv1d(100, 50, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv1d(8, 50, 3)\n",
    "        self.cnn_pep_2 = nn.Conv1d(50, 25, 1)\n",
    "        self.cnn_pep_3 = nn.Conv1d(25, 10, 1)\n",
    "\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.name = \"Conv1dModelSimple\"\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu, self.cnn_apt_2, self.relu)\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu, self.cnn_pep_2, self.relu)\n",
    "        \n",
    "        self.fc1 = nn.Linear(275, 1)\n",
    "        self.conv_type = '1d'\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt(apt)\n",
    "        apt = self.relu(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        pep = self.relu(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrueLinearNet, self).__init__()\n",
    "        self.lin_apt_1 = nn.Linear(160, 100) \n",
    "        self.lin_apt_2 = nn.Linear(100, 50)\n",
    "        self.lin_apt_3 = nn.Linear(50, 10)\n",
    "        \n",
    "        self.lin_pep_1 = nn.Linear(160, 50)\n",
    "        self.lin_pep_2 = nn.Linear(50, 10)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.name = \"LinearNet\"\n",
    "        \n",
    "        self.lin_apt = nn.Sequential(self.lin_apt_1, self.lin_apt_2, self.lin_apt_3)\n",
    "        self.lin_pep = nn.Sequential(self.lin_pep_1, self.lin_pep_2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(20, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        apt = self.lin_apt(apt)\n",
    "        pep = self.lin_pep(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model is too complex for our input sequence size\n",
    "class ConvNetComplex(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv1dModel, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv1d(40, 500, 3) \n",
    "        self.cnn_apt_2 = nn.Conv1d(500, 300, 1)\n",
    "        self.cnn_apt_3 = nn.Conv1d(300, 150, 1)\n",
    "        self.cnn_apt_4 = nn.Conv1d(150, 75, 1)\n",
    "        self.cnn_apt_5 = nn.Conv1d(25, 10, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv1d(8, 250, 3)\n",
    "        self.cnn_pep_2 = nn.Conv1d(250, 500, 1)\n",
    "        self.cnn_pep_3 = nn.Conv1d(500, 250, 1)\n",
    "        self.cnn_pep_4 = nn.Conv1d(250, 100, 1)\n",
    "        self.cnn_pep_5 = nn.Conv1d(100, 10, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.name = \"ConvNetComplex\"\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu, self.cnn_apt_2, self.maxpool, self.relu, self.cnn_apt_3, self.maxpool, self.relu, self.cnn_apt_4, self.maxpool, self.relu, self.cnn_apt_5, self.relu)\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu, self.cnn_pep_2, self.maxpool, self.relu, self.cnn_pep_3, self.maxpool, self.relu, self.cnn_pep_4, self.maxpool, self.relu, self.cnn_pep_5, self.relu)\n",
    "        \n",
    "        self.fc1 = nn.Linear(180, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt(apt)\n",
    "        apt = self.relu(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        pep = self.relu(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueLinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrueLinearNet, self).__init__()\n",
    "        self.lin_apt_1 = nn.Linear(160, 100) \n",
    "        self.lin_apt_2 = nn.Linear(100, 50)\n",
    "        self.lin_apt_3 = nn.Linear(50, 10)\n",
    "        \n",
    "        self.lin_pep_1 = nn.Linear(160, 50)\n",
    "        self.lin_pep_2 = nn.Linear(50, 10)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.name = \"TrueLinearNet\"\n",
    "        \n",
    "        self.lin_apt = nn.Sequential(self.lin_apt_1, self.lin_apt_2, self.lin_apt_3)\n",
    "        self.lin_pep = nn.Sequential(self.lin_pep_1, self.lin_pep_2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(20, 1)\n",
    "        self.conv_type = '1d'\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        apt = self.lin_apt(apt)\n",
    "        pep = self.lin_pep(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimizedVCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MinimizedVCNet, self).__init__()\n",
    "        self.name = \"MinimizedVCNet\"\n",
    "        \n",
    "        self.cnn_apt_1 = nn.Conv1d(4, 1000, 3, padding=2) \n",
    "        self.cnn_apt_2 = nn.Conv1d(1000, 500, 3, padding=2)\n",
    "        self.cnn_apt_3 = nn.Conv1d(500, 100, 3, padding=2)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv1d(20, 500, 3, padding=2)\n",
    "        self.cnn_pep_2 = nn.Conv1d(500, 250, 3, padding=2)\n",
    "        self.cnn_pep_3 = nn.Conv1d(250, 100, 3, padding=2)\n",
    "\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)         \n",
    "        self.fc1 = nn.Linear(800, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        # apt input size [1, 40, 4]\n",
    "        apt = apt.permute(0, 2, 1)\n",
    "        \n",
    "        # conv --> relu --> pool after every one\n",
    "        apt = self.pool1(self.relu(self.cnn_apt_1(apt)))\n",
    "        apt = self.pool1(self.relu(self.cnn_apt_2(apt)))\n",
    "        apt = self.pool1(self.relu(self.cnn_apt_3(apt)))\n",
    "\n",
    "        # pep input size [1, 8, 20]\n",
    "        pep = pep.permute(0, 2, 1)\n",
    "        \n",
    "        pep = self.pool1(self.relu(self.cnn_pep_1(pep)))\n",
    "        pep = self.pool1(self.relu(self.cnn_pep_2(pep)))\n",
    "        pep = self.pool1(self.relu(self.cnn_pep_3(pep)))\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def one_hot(sequence, seq_type='peptide'):\n",
    "    if seq_type == 'peptide':\n",
    "        letters = aa_list\n",
    "    else:\n",
    "        letters = na_list\n",
    "    one_hot = np.zeros((len(sequence), len(letters)))\n",
    "    for i in range(len(sequence)):\n",
    "        char = sequence[i]\n",
    "        for _ in range(len(letters)):\n",
    "            idx = letters.index(char)\n",
    "            one_hot[i][idx] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Convert a pair to one-hot tensor\n",
    "def convert(apt, pep): \n",
    "    apt = one_hot(apt, seq_type='aptamer') #(40, 4)\n",
    "    pep = one_hot(pep, seq_type='peptide') #(8, 20)\n",
    "    apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[0], apt.shape[1]))).cuda() #(1, 40, 4)\n",
    "    pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[0], pep.shape[1]))).cuda() #(1, 8, 20)\n",
    "    return apt, pep\n",
    "\n",
    "# Getting the output of the model for a pair (aptamer, peptide)\n",
    "def update(x, y):\n",
    "    x.requires_grad=True\n",
    "    y.requires_grad=True\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    out = model(x, y)\n",
    "    return out\n",
    "\n",
    "# Generates the samples used to calculate loss\n",
    "def loss_samples(k, ds='train'): # S_train/S_test\n",
    "    if ds == 'train':\n",
    "        dset = S_train\n",
    "    else:\n",
    "        dset = S_test\n",
    "    pairs = []\n",
    "    for (apt, pep) in dset[:k]:\n",
    "        x, y = convert(apt, pep)\n",
    "        pairs.append((x, y))\n",
    "    return pairs\n",
    "\n",
    "# Generates the samples used to calculate loss from S_prime_train/S_prime_test\n",
    "def prime_loss_samples(k, ds='train'): # S_prime_train/S_prime_test\n",
    "    if ds == \"train\":\n",
    "        dset = S_prime_train[len(S_prime_train)//2:]    \n",
    "    else:\n",
    "        dset = S_prime_test[len(S_prime_test)//2:]\n",
    "    pairs = []\n",
    "    for (apt, pep), ind in dset[:k]:\n",
    "        pmf = get_y_pmf(pep)\n",
    "        x, y = convert(apt, pep)\n",
    "        pairs.append((x, y, ind, pmf))\n",
    "    return pairs\n",
    "\n",
    "# First term of the loss\n",
    "def get_log_out(dataset='train'):\n",
    "    outs = []\n",
    "    if dataset == 'train':\n",
    "        dset = train_loss_samples\n",
    "    else:\n",
    "        dset = test_loss_samples\n",
    "    for (apt, pep) in dset:\n",
    "        out = update(apt, pep)\n",
    "        outs.append(torch.log(out).cpu().detach().numpy().flatten()[0])\n",
    "    return np.average(outs)\n",
    "\n",
    "# Second term of loss\n",
    "def get_out_prime(ds=\"train\"):\n",
    "    outs = []\n",
    "    if ds == \"train\":\n",
    "        dset = prime_train_loss_samples\n",
    "        leng = m\n",
    "    else:\n",
    "        dset = prime_test_loss_samples\n",
    "        leng = n-m\n",
    "    for (apt, pep, ind, pmf) in dset:\n",
    "        x = apt.cuda()\n",
    "        y = pep.cuda()\n",
    "        out = model(x, y)\n",
    "        if ind == 0:\n",
    "            factor = (2*leng*get_x_pmf()*pmf)/(1+leng*get_x_pmf()*pmf)\n",
    "        else:\n",
    "            factor = 2\n",
    "        out_is = out.cpu().detach().numpy().flatten()[0] * factor\n",
    "        outs.append(out_is)\n",
    "    return np.average(outs)\n",
    "\n",
    "## Plotting functions\n",
    "\n",
    "def plot_loss(train_loss, test_loss, i, j, lamb, gamma):\n",
    "    plt.plot(train_loss, 'b', label='Train loss')\n",
    "    plt.plot(test_loss, 'y', label='Test loss')\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Number of iterations\")\n",
    "    plt.title('Loss after ' +  str(i) + \" iterations, \" + str(j) + \" epochs, \" + 'lambda =%.5f' % lamb  + ' gamma =%.5f' % gamma)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_recall(train_recall, test_recall, new_recall, i, j, lamb, gamma):\n",
    "    plt.plot(train_recall, 'b', label='Train recall')\n",
    "    plt.plot(test_recall, 'y', label='Test recall')\n",
    "    plt.plot(new_recall, 'r', label='New recall')\n",
    "    plt.ylabel(\"Recall (%)\")\n",
    "    plt.xlabel(\"Number of iterations\")\n",
    "    plt.title('Recall after ' + str(i) + \" iterations, \" + str(j) + \" epochs, \" + 'lambda =%.5f' % lamb  + ' gamma =%.5f' % gamma)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_ecdf_test(test_score, i, j, lamb, gamma):\n",
    "    test_idx = np.argsort(test_score)\n",
    "    test_id = test_idx > 10000\n",
    "    test = np.sort(test_score)\n",
    "    test_c = \"\"\n",
    "    for m in test_id:\n",
    "        if m:\n",
    "            test_c += \"y\"\n",
    "        else:\n",
    "            test_c += \"g\"\n",
    "    n = test_score.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    plt.scatter(y, test, c=test_c, label='Test CDF')\n",
    "    plt.xlabel(\"CDF\")\n",
    "    plt.ylabel(\"Most recent 10,000 samples\")\n",
    "    plt.title('CDF after ' + str(i) + \" iterations, \" + str(j) + \" epochs, \" + 'lambda =%.5f' % lamb  + ' gamma =%.5f' % gamma)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_ecdf_train(train_score, i, j, lamb, gamma):\n",
    "    #train_score consisits of [10000 scores generated] + [1000 scores from training set]\n",
    "    train_idx = np.argsort(train_score)\n",
    "    train_id = train_idx > 10000\n",
    "    train = np.sort(train_score)\n",
    "    train_c = \"\" #colors\n",
    "    for l in train_id:\n",
    "        if l:\n",
    "            train_c += \"r\"\n",
    "        else:\n",
    "            train_c += \"b\"\n",
    "    n = train_score.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    plt.scatter(y, train, c=train_c, label='Train CDF')\n",
    "    plt.xlabel(\"CDF\")\n",
    "    plt.ylabel(\"Most recent 10,000 samples\")\n",
    "    plt.title('CDF after ' + str(i) + \" iterations, \" + str(j) + \" epochs, \" + 'lambda =%.5f' % lamb  + ' gamma =%.5f' % gamma)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def histogram(eval_scores, train_scores, test_scores):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xlim(0, 1.1)\n",
    "    sns.distplot(eval_scores , color=\"skyblue\", label='New: not in dataset', ax=ax)\n",
    "    sns.distplot(train_scores , color=\"gold\", label='Train: in dataset', ax=ax)\n",
    "    sns.distplot(test_scores, color='red', label='Test: in the dataset', ax=ax)\n",
    "    ax.set_title(\"Distribution of Scores\")\n",
    "    ax.figure.set_size_inches(7, 4)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "checkpointed_model = '../models/model_checkpoints/MinimizedVCNet/05042020.pth'\n",
    "checkpoint = torch.load(checkpointed_model)\n",
    "model = MinimizedVCNet()\n",
    "optim = SGD(model.parameters(), lr=1e-2)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "model.to(device)\n",
    "print(str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate combinations not aware of the PMF of peptides\n",
    "def product(l, length):\n",
    "     yield from itertools.product(*([l] * length)) \n",
    "\n",
    "def generate_combinations(molecule='peptide'):\n",
    "    if molecule == 'peptide':\n",
    "        base = \"M\"\n",
    "        peptides = []\n",
    "        for combination in product(aa_list, length=7):\n",
    "            combination = ''.join(combination)\n",
    "            peptides.append('M' + str(combination))\n",
    "        return peptides\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_binding_pair(sequence, sequence_type):\n",
    "    max_score = 0\n",
    "    binding_molecule = \"\"\n",
    "    \n",
    "    if sequence_type == 'aptamer':\n",
    "        generated_peptides = []\n",
    "        for i in range(1000):\n",
    "            generated_peptides.append(get_y())\n",
    "        for pep in generated_peptides:\n",
    "            x, y = convert(sequence, pep)\n",
    "            score = model(x, y).cpu().detach().numpy().flatten()[0]\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                binding_molecule = pep\n",
    "        print(\"Aptamer requested: \", sequence)\n",
    "        print(\"Peptide selected: \", binding_molecule)\n",
    "        print(\"Confidence: \", max_score)\n",
    "    else:\n",
    "        generated_aptamers = []\n",
    "        for i in range(1000):\n",
    "            generated_aptamers.append(get_x())\n",
    "        for apt in generated_aptamers:\n",
    "            x, y = convert(apt, sequence)\n",
    "            score = model(x, y).cpu().detach().numpy().flatten()[0]\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                binding_molecule = apt\n",
    "        print(\"Peptide requested: \", sequence)\n",
    "        print(\"Aptamer selected: \", binding_molecule)\n",
    "        print(\"Confidence: \", max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aptamer requested:  TGTAAGCATACGGCTCCACGCGGCTAGCTAATTTCTATTT\n",
      "Peptide selected:  MALCAWGC\n",
      "Confidence:  0.99753714\n"
     ]
    }
   ],
   "source": [
    "# Pick a random aptamer from our train set\n",
    "aptamer_to_pair = S_train[0][0]\n",
    "generate_binding_pair(aptamer_to_pair, sequence_type='aptamer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
