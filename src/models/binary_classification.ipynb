{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*13 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "aa_dict = dict(zip(aa_list, pvals))\n",
    "k = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset():\n",
    "    with open(aptamer_dataset_file, 'r') as f:\n",
    "        aptamer_data = json.load(f)\n",
    "    full_dataset = []\n",
    "    for aptamer in aptamer_data:\n",
    "        peptides = aptamer_data[aptamer]\n",
    "        if aptamer == \"CTTTGTAATTGGTTCTGAGTTCCGTTGTGGGAGGAACATG\": #took out aptamer control\n",
    "            continue\n",
    "        for peptide, _ in peptides:\n",
    "            peptide = peptide.replace(\"_\", \"\") #removed stop codons\n",
    "            if \"RRRRRR\" in peptide: #took out peptide control\n",
    "                continue\n",
    "            if len(aptamer) == 40 and len(peptide) == 8: #making sure right length\n",
    "                full_dataset.append((aptamer.encode(\"utf-8\"), peptide.encode(\"utf-8\"), 1))\n",
    "    full_dataset = list(set(full_dataset)) #removed duplicates\n",
    "    return full_dataset\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        super(Dataset, self).__init__() \n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide, label = self.dataset[idx]\n",
    "        return aptamer, peptide, label\n",
    "    \n",
    "\n",
    "aptamer_dataset_file = \"../data/aptamer_dataset.json\"\n",
    "positive_dataset = construct_dataset()\n",
    "n = len(positive_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CGCCTTTAATGTGACGGTTAGGGATGCCCCTATCGACTAG', 'MLERPTGD', 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(1, 120, (4,4)) #similar to 4-gram\n",
    "        self.cnn_pep_1 = nn.Conv2d(1, 50, (4,20))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(4690, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt_1(apt)\n",
    "        apt = self.relu(apt)\n",
    "        pep = self.cnn_pep_1(pep)\n",
    "        pep = self.relu(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DoubleConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(1, 1000, (5,4)) #similar to 5-gram\n",
    "        self.cnn_apt_2 = nn.Conv2d(1000, 100, 1)\n",
    "        self.cnn_pep_1 = nn.Conv2d(1, 500, (5,20))\n",
    "        self.cnn_pep_2 = nn.Conv2d(500, 10, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(3640, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt_1(apt)\n",
    "        apt = self.cnn_apt_2(apt)\n",
    "        apt = self.relu(apt)\n",
    "        pep = self.cnn_pep_1(pep)\n",
    "        pep = self.cnn_pep_2(pep)\n",
    "        pep = self.relu(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoreComplexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MoreComplexNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(1, 500, 1) #similar to 5-gram\n",
    "        self.cnn_apt_2 = nn.Conv2d(500, 1000, 1)\n",
    "        self.cnn_apt_3 = nn.Conv2d(1000, 500, 2)\n",
    "        self.cnn_apt_4 = nn.Conv2d(500, 100, 2)\n",
    "        self.cnn_apt_5 = nn.Conv2d(100, 10, 2)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv2d(1, 250, 1)\n",
    "        self.cnn_pep_2 = nn.Conv2d(250, 500, 1)\n",
    "        self.cnn_pep_3 = nn.Conv2d(500, 250, 3)\n",
    "        self.cnn_pep_4 = nn.Conv2d(250, 100, 2)\n",
    "        self.cnn_pep_5 = nn.Conv2d(100, 10, 2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.relu, self.cnn_apt_2, self.relu, self.cnn_apt_3, self.relu, self.cnn_apt_4, self.relu, self.cnn_apt_5)\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.relu, self.cnn_pep_2, self.relu, self.cnn_pep_3, self.relu, self.cnn_pep_4, self.relu, self.cnn_pep_5)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(1010, 2)\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt(apt)\n",
    "        apt = self.relu(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        pep = self.relu(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.log_softmax(x, dim=0)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, prediction, label):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion(prediction, label)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length of S_new: ', 591309)\n"
     ]
    }
   ],
   "source": [
    "# Sample x from P_X (assume apatamers follow uniform)\n",
    "def get_x():\n",
    "    x_idx = np.random.randint(0, 4, 40)\n",
    "    x = \"\"\n",
    "    for i in x_idx:\n",
    "        x += na_list[i]\n",
    "    return x\n",
    "\n",
    "# Sample y from P_y (assume peptides follow NNK)\n",
    "def get_y():\n",
    "    y_idx = np.random.choice(20, 7, p=pvals)\n",
    "    y = \"M\"\n",
    "    for i in y_idx:\n",
    "        y += aa_list[i]\n",
    "    return y\n",
    "\n",
    "# S' contains S with double the size of S (domain for Importance Sampling)\n",
    "# Return S_prime, and S_new (all unseen samples)\n",
    "def get_S_new(k):\n",
    "    S_new = []\n",
    "    for _ in range(k):\n",
    "        pair = (get_x(), get_y(), 0)\n",
    "        S_new.append(pair)\n",
    "    return S_new\n",
    "\n",
    "S_new = get_S_new(n) #use for sgd and eval\n",
    "print(\"Length of S_new: \", len(S_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def one_hot(sequence, seq_type='peptide'):\n",
    "    if seq_type == 'peptide':\n",
    "        letters = aa_list\n",
    "    else:\n",
    "        letters = na_list\n",
    "    one_hot = np.zeros((len(sequence), len(letters)))\n",
    "    for i in range(len(sequence)):\n",
    "        char = sequence[i]\n",
    "        for _ in range(len(letters)):\n",
    "            idx = letters.index(char)\n",
    "            one_hot[i][idx] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Convert a pair to one-hot tensor\n",
    "def convert(apt, pep, label): \n",
    "    apt = one_hot(apt, seq_type='aptamer') #(40, 4)\n",
    "    pep = one_hot(pep, seq_type='peptide') #(8, 20)\n",
    "    apt = torch.FloatTensor(np.reshape(apt, (1, 1, apt.shape[0], apt.shape[1]))).cuda() #(1, 1, 40, 4)\n",
    "    pep = torch.FloatTensor(np.reshape(pep, (1, 1, pep.shape[0], pep.shape[1]))).cuda() #(1, 1, 8, 20)\n",
    "    return apt, pep, label.cuda()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Train/TestLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = positive_dataset + S_new\n",
    "random.shuffle(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GACGCAAAACCGGCTGGGTTCACGCCTACCCAGGAGACCA', 'MHMVLITS', 0),\n",
       " ('TACGCTTGCATATTCTGTCAATTGGAGGACACTTTACTAA', 'MQRTSKQR', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length of train dataset: ', 946094)\n",
      "('Length of val dataset: ', 118262)\n",
      "('Length of test dataset: ', 118262)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(full_dataset[:int(0.8*len(full_dataset))])\n",
    "validation_dataset = Dataset(full_dataset[int(0.8*len(full_dataset)):int(0.9*len(full_dataset))])\n",
    "test_dataset = Dataset(full_dataset[int(0.9*len(full_dataset)):])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset)\n",
    "val_loader = torch.utils.data.DataLoader(validation_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)\n",
    "print(\"Length of train dataset: \", len(train_dataset))\n",
    "print(\"Length of val dataset: \", len(validation_dataset))\n",
    "print(\"Length of test dataset: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification(t=1, lr=1e-5):\n",
    "    model = MoreComplexNet()\n",
    "    model.apply(weights_init)\n",
    "    model.cuda()\n",
    "        \n",
    "    optimizer = SGD(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(t):\n",
    "        model.train()\n",
    "        for i, data in enumerate(tqdm.tqdm(train_loader)):\n",
    "            pep = data[1][0]\n",
    "            apt = data[0][0]\n",
    "            label = data[2]\n",
    "            \n",
    "            x, y, label = convert(apt, pep, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x, y)\n",
    "            \n",
    "            loss = model.loss(output, label)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Testing loop\n",
    "            if i % 50000 == 0:\n",
    "                model.eval()\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    for j, data in enumerate(val_loader):\n",
    "                        pep = data[1][0]\n",
    "                        apt = data[0][0]\n",
    "                        label = data[2]\n",
    "                        x, y, label = convert(apt, pep, label)\n",
    "\n",
    "                        output = model(x, y)\n",
    "                        val_losses.append(model.loss(output, label))\n",
    "                        \n",
    "                        pred = torch.argmax(output).item()\n",
    "\n",
    "                        total += 1\n",
    "                        correct += (pred == label)\n",
    "\n",
    "                print('Accuracy of the network after ' + str(epoch) + ' epochs on the test samples: %d %%' % (100* correct/total))\n",
    "                _, ax = plt.subplots()\n",
    "                ax.plot(train_losses, 'g', label='Train loss')\n",
    "                ax.plot(val_losses, 'b', label='Val loss')\n",
    "                ax.set_title('Loss after ' + str(i) + \" iterations \")\n",
    "                ax.legend()\n",
    "                plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/946094 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network after 0 epochs on the test samples: 50 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7455/946094 [05:42<2:09:36, 120.69it/s]  "
     ]
    }
   ],
   "source": [
    "binary_classification(t=1, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
