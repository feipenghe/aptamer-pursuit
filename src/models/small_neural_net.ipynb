{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Neural Network that takes as input both the aptamer features and the peptide features to predict affinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate features for both aptamers and peptides + construct training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.svm import SVC\n",
    "from scipy import stats\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='TITAN Xp', major=6, minor=1, total_memory=12196MB, multi_processor_count=30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.005\n",
    "d = 200\n",
    "samples = 10000\n",
    "split = 8000\n",
    "k_apt = 4\n",
    "k_pep = 4\n",
    "random.seed(42)\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.get_device_properties(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to classify binding affinity of a sample. \n",
    "'''\n",
    "def classify_affinity(affinity):\n",
    "    if float(affinity) <= 9:\n",
    "        return 0\n",
    "    elif float(affinity) <= 50:\n",
    "        return 1\n",
    "    elif float(affinity) <= 400:\n",
    "        return 2\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"../data/mhcflurry_dataset.json\"\n",
    "'''\n",
    "Constructs a dataset that has 10,000 pairs for every class of binding affinity. \n",
    "'''\n",
    "def construct_dataset():\n",
    "    with open(dataset_file, 'r') as f:\n",
    "        mhcflurry_data = json.load(f)\n",
    "    \n",
    "    # Full dataset. The index of the list corresponds to the binding affinity class\n",
    "    full_dataset = [[], [], [], []]\n",
    "    for allele in mhcflurry_data:\n",
    "        peptides = mhcflurry_data[allele]\n",
    "        for p, b in peptides:\n",
    "            affinity_class = classify_affinity(b)\n",
    "            full_dataset[affinity_class].append((allele, p))\n",
    "    \n",
    "    subsampled_dataset = [[], [], [], []]\n",
    "    \n",
    "    for i in range(len(full_dataset)):\n",
    "        full_class = np.asarray(full_dataset[i])\n",
    "        # Sample the hardcoded number of samples pairs randomly\n",
    "        subsampled_dataset[i] = np.copy(full_class[np.random.choice(full_class.shape[0], samples, replace=False), :])\n",
    "    \n",
    "    subsampled_dataset = np.asarray(subsampled_dataset)    \n",
    "    return subsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_dataset = construct_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extracts features from the subsampled dataset\n",
    "'''\n",
    "def extract_features(dataset, d, k_apt, k_pep):\n",
    "    # Number of features\n",
    "    aptamer_features = [[], [], [], []]\n",
    "    peptide_features = [[], [], [], []]\n",
    "\n",
    "    for i in range(dataset.shape[0]):\n",
    "        flattened = dataset[i].flatten('F')\n",
    "        all_aptamers = flattened[:samples]\n",
    "        all_peptides = flattened[samples:]\n",
    "\n",
    "        split = int(0.8*len(all_aptamers))\n",
    "        all_aptamers = all_aptamers[:split]\n",
    "        all_peptides = all_peptides[:split]\n",
    "\n",
    "        # Generate the aptamer features randomly\n",
    "        for j in range(d):\n",
    "            # Find a random aptamer\n",
    "            apt = random.choice(all_aptamers)\n",
    "\n",
    "            # Find a random subsection of k elements from this sequence and the quartile\n",
    "            start = random.randint(0, len(apt)-k_apt)\n",
    "            quartile_pctg = (start + 1)/float(len(apt))\n",
    "            if quartile_pctg <= 0.25:\n",
    "                quartile = 1\n",
    "            elif quartile_pctg > 0.25 and quartile_pctg <= 0.5:\n",
    "                quartile = 2\n",
    "            elif quartile_pctg > 0.5 and quartile_pctg <= 0.75:\n",
    "                quartile = 3\n",
    "            else:\n",
    "                quartile = 4\n",
    "            \n",
    "            aptamer_features[i].append((apt[start:start+k_apt], quartile))\n",
    "\n",
    "        # Generate the peptide features randomly\n",
    "        for j in range(d):\n",
    "            # Find a random aptamer\n",
    "            pep = random.choice(all_peptides)\n",
    "\n",
    "            # Find a random subsection of k elements from this sequence\n",
    "            start = random.randint(0, len(pep)-k_pep)\n",
    "            quartile_pctg = (start + 1)/float(len(pep))\n",
    "            if quartile_pctg <= 0.25:\n",
    "                quartile = 1\n",
    "            elif quartile_pctg > 0.25 and quartile_pctg <= 0.5:\n",
    "                quartile = 2\n",
    "            elif quartile_pctg > 0.5 and quartile_pctg <= 0.75:\n",
    "                quartile = 3\n",
    "            else:\n",
    "                quartile = 4\n",
    "            \n",
    "            peptide_features[i].append((pep[start:start+k_pep], quartile))\n",
    "\n",
    "\n",
    "    return aptamer_features, peptide_features, split\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_features, peptide_features, split = extract_features(subsampled_dataset, d=d, k_apt=k_apt, k_pep=k_pep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generates training and testing sets. Training is the first 8000 samples, test is the last 2000 samples. \n",
    "'''\n",
    "def construct_train_test_sets(aptamer_features, peptide_features, split):\n",
    "    train_pairs = [[], [], [], []]\n",
    "    test_pairs = [[], [], [], []]\n",
    "    \n",
    "    for c in range(len(subsampled_dataset)):\n",
    "        train_pairs[c] = subsampled_dataset[c][:split]\n",
    "        test_pairs[c] = subsampled_dataset[c][split:]\n",
    "    \n",
    "    train_pairs = np.asarray(train_pairs)\n",
    "    test_pairs = np.asarray(test_pairs)\n",
    "    \n",
    "    train_aptamers = [[], [], [], []]\n",
    "    test_aptamers = [[], [], [], []]\n",
    "    \n",
    "    train_peptides = [[], [], [], []]\n",
    "    test_peptides = [[], [], [], []]\n",
    "    \n",
    "    # Make a 0/1 matrix for the training aptamers/peptides\n",
    "    for i in range(len(train_aptamers)):\n",
    "        pairs = train_pairs[i]\n",
    "        apt_features = aptamer_features[i]\n",
    "        pep_features = peptide_features[i]\n",
    "        \n",
    "        for j in range(len(pairs)):\n",
    "            a, p = pairs[j]\n",
    "            matrix_aptamer_train = []\n",
    "            matrix_peptide_train = []\n",
    "            \n",
    "            for k in range(len(apt_features)):\n",
    "                feat, quartile = apt_features[k]\n",
    "                starts = [m.start() for m in re.finditer(feat, a)]\n",
    "                if len(starts) == 0:\n",
    "                    matrix_aptamer_train.append(0)\n",
    "                    continue\n",
    "                exists = False\n",
    "                for s in starts:\n",
    "                    pctg = (s + 1) / len(a)\n",
    "                    if pctg <= 0.25 and quartile == 1:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif (pctg > 0.25 and pctg <= 0.5) and quartile == 2:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif (pctg > 0.5 and pctg <= 0.75) and quartile == 3:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif pctg > 0.75 and quartile == 4:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    else:\n",
    "                        exists = False\n",
    "                if exists:\n",
    "                    matrix_aptamer_train.append(1)\n",
    "                if not exists:\n",
    "                    matrix_aptamer_train.append(0)\n",
    "            \n",
    "            train_aptamers[i].append(matrix_aptamer_train)\n",
    "            \n",
    "            for k in range(len(pep_features)):\n",
    "                feat, quartile = pep_features[k]\n",
    "                starts = [m.start() for m in re.finditer(feat, p)]\n",
    "                if len(starts) == 0:\n",
    "                    matrix_peptide_train.append(0)\n",
    "                    continue\n",
    "                exists = False\n",
    "                for s in starts:\n",
    "                    pctg = (s + 1) / len(p)\n",
    "                    if pctg <= 0.25 and quartile == 1:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif (pctg > 0.25 and pctg <= 0.5) and quartile == 2:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif (pctg > 0.5 and pctg <= 0.75) and quartile == 3:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif pctg > 0.75 and quartile == 4:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    else:\n",
    "                        exists = False\n",
    "                \n",
    "                if exists:\n",
    "                    matrix_peptide_train.append(1)\n",
    "                if not exists:\n",
    "                    matrix_peptide_train.append(0)\n",
    "                    \n",
    "            train_peptides[i].append(matrix_peptide_train)\n",
    "    \n",
    "    train_aptamers = np.asarray(train_aptamers)\n",
    "    train_peptides = np.asarray(train_peptides)\n",
    "    \n",
    "    # Make a 0/1 matrix for the testing aptamers/peptides\n",
    "\n",
    "    for i in range(len(test_aptamers)):\n",
    "        pairs = test_pairs[i]\n",
    "        apt_features = aptamer_features[i]\n",
    "        pep_features = peptide_features[i]\n",
    "        \n",
    "        for j in range(len(pairs)):\n",
    "            a, p = pairs[j]\n",
    "            matrix_aptamer_test = []\n",
    "            matrix_peptide_test = []\n",
    "            \n",
    "            for k in range(len(apt_features)):\n",
    "                feat, quartile = apt_features[k]\n",
    "                starts = [m.start() for m in re.finditer(feat, a)]\n",
    "                if len(starts) == 0:\n",
    "                    matrix_aptamer_test.append(0)\n",
    "                    continue\n",
    "                exists = False\n",
    "                for s in starts:\n",
    "                    # Each s is an index of the beginning of this features\n",
    "                    # If one of them appears in the correct quartile, then this is 1\n",
    "                    pctg = (s + 1) / len(a)\n",
    "                    if pctg <= 0.25 and quartile == 1:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif (pctg > 0.25 and pctg <= 0.5) and quartile == 2:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif (pctg > 0.5 and pctg <= 0.75) and quartile == 3:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif pctg > 0.75 and quartile == 4:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    else:\n",
    "                        exists = False\n",
    "                if exists:\n",
    "                    matrix_aptamer_test.append(1)\n",
    "                if not exists:\n",
    "                    matrix_aptamer_test.append(0)\n",
    "                        \n",
    "            test_aptamers[i].append(matrix_aptamer_test)\n",
    "            \n",
    "            for k in range(len(pep_features)):\n",
    "                feat, quartile = pep_features[k]\n",
    "                starts = [m.start() for m in re.finditer(feat, p)]\n",
    "                if len(starts) == 0:\n",
    "                    matrix_peptide_test.append(0)\n",
    "                    continue\n",
    "                exists = False\n",
    "                for s in starts:\n",
    "                    pctg = (s + 1) / len(p)\n",
    "                    if pctg <= 0.25 and quartile == 1:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif (pctg > 0.25 and pctg <= 0.5) and quartile == 2:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif (pctg > 0.5 and pctg <= 0.75) and quartile == 3:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    elif pctg > 0.75 and quartile == 4:\n",
    "                        exists = True\n",
    "                        break\n",
    "                    else:\n",
    "                        exists = False\n",
    "                if exists:\n",
    "                    matrix_peptide_test.append(1)\n",
    "                else:\n",
    "                    matrix_peptide_test.append(0)\n",
    "\n",
    "            test_peptides[i].append(matrix_peptide_test)\n",
    "                \n",
    "    test_aptamers = np.asarray(test_aptamers)\n",
    "    test_peptides = np.asarray(test_peptides)\n",
    "    \n",
    "    \n",
    "    return train_aptamers, train_peptides, test_aptamers, test_peptides\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aptamers, train_peptides, test_aptamers, test_peptides = construct_train_test_sets(aptamer_features, peptide_features, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8000, 200)\n",
      "(4, 8000, 200)\n",
      "(4, 2000, 200)\n",
      "(4, 2000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(str(train_aptamers.shape))\n",
    "print(str(train_peptides.shape))\n",
    "print(str(test_aptamers.shape))\n",
    "print(str(test_peptides.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AptamerPeptideDataset(Dataset):\n",
    "    '''\n",
    "    @param: peptides = n*m\n",
    "    @param: aptamers = n*m\n",
    "    @param: affinities = n*1\n",
    "    '''\n",
    "    def __init__(self, peptides, aptamers, affinities):\n",
    "        self.peptides = peptides\n",
    "        self.aptamers = aptamers\n",
    "        affinities = np.reshape(affinities, (affinities.shape[0], 1))\n",
    "        self.affinities = affinities\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.peptides.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        pep = self.peptides[idx]\n",
    "        apt = self.aptamers[idx]        \n",
    "        aff_class = self.affinities[idx]\n",
    "        \n",
    "        sample = {'peptide': pep, 'aptamer': apt, 'affinity': aff_class}\n",
    "        \n",
    "        return sample\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the dataset to fit the dataset class\n",
    "def reshape_dataset(train_aptamers, test_aptamers, train_peptides, test_peptides):\n",
    "    all_train_aptamers = []\n",
    "    all_test_aptamers = []\n",
    "    for i in range(len(train_aptamers)):\n",
    "        all_train_aptamers.extend(train_aptamers[i])\n",
    "        all_test_aptamers.extend(test_aptamers[i])\n",
    "\n",
    "    # n * m\n",
    "    all_train_aptamers = np.array(all_train_aptamers)\n",
    "    all_test_aptamers = np.array(all_test_aptamers)\n",
    "\n",
    "    all_train_peptides = []\n",
    "    all_test_peptides = []\n",
    "    for i in range(len(train_peptides)):\n",
    "        all_train_peptides.extend(train_peptides[i])\n",
    "        all_test_peptides.extend(test_peptides[i])\n",
    "\n",
    "    # n * m\n",
    "    all_train_peptides = np.array(all_train_peptides)\n",
    "    all_test_peptides = np.array(all_test_peptides)\n",
    "\n",
    "\n",
    "    # n * 1\n",
    "    train_affinity_classes = np.repeat(np.array([[0, 1], [2, 3]]), split)\n",
    "    test_affinity_classes = np.repeat(np.array([[0, 1], [2, 3]]), samples-split)\n",
    "\n",
    "    return all_train_peptides, all_train_aptamers, all_test_peptides, all_test_aptamers, train_affinity_classes, test_affinity_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pep, train_apt, test_pep, test_apt, train_aff, test_aff = reshape_dataset(train_aptamers, test_aptamers, train_peptides, test_peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pep shape:  (32000, 200)\n",
      "Train apt shape:  (32000, 200)\n",
      "Test apt shape:  (8000, 200)\n",
      "Test_pep shape:  (8000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train pep shape: \", train_pep.shape)\n",
    "print(\"Train apt shape: \", train_apt.shape)\n",
    "print(\"Test apt shape: \", test_apt.shape)\n",
    "print(\"Test_pep shape: \", test_pep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AptamerPeptideDataset(train_pep, train_apt, train_aff)\n",
    "test_dataset = AptamerPeptideDataset(test_pep, test_apt, test_aff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "testloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a small neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "class SmallNN(nn.Module):\n",
    "    def __init__(self, d_value):\n",
    "        super(SmallNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_value, 1024)\n",
    "        self.prelu1 = nn.PReLU(num_parameters=1)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.prelu2 = nn.PReLU(num_parameters=1)\n",
    "        self.lin1 = nn.Linear(512, 250)\n",
    "        self.prelu3 = nn.PReLU(num_parameters=1)\n",
    "        self.lin2 = nn.Linear(250, 100)\n",
    "        self.fc3 = nn.Linear(250, 4)\n",
    "        self.sequential = nn.Sequential(self.fc1, self.prelu1, self.fc2, self.prelu2, self.lin1, self.prelu3, self.fc3)\n",
    "        self.fc4 = nn.Linear(8, 4)\n",
    "       \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.type(torch.FloatTensor)\n",
    "        pep = pep.type(torch.FloatTensor)\n",
    "        apt = self.sequential(apt)\n",
    "        pep = self.sequential(pep)\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc4(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, prediction, label):\n",
    "        loss = nn.MSELoss()\n",
    "        label = label.type(torch.FloatTensor)\n",
    "        label = np.reshape(label, (1, 4))\n",
    "        return loss(prediction, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallNN(d_value=d)\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainloader):\n",
    "        pep = data['peptide']\n",
    "        apt = data['aptamer']\n",
    "        label = data['affinity'].item()\n",
    "        one_hot_label = [0] * 4\n",
    "        one_hot_label[label] = 1\n",
    "        one_hot_label = torch.tensor(one_hot_label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(pep, apt)\n",
    "        loss = model.loss(output, one_hot_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'small_nn.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the performance of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test samples: 25 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader):\n",
    "        pep = data['peptide']\n",
    "        apt = data['aptamer']\n",
    "        label = data['affinity'].item()\n",
    "        \n",
    "        output = model(pep, apt)\n",
    "        pred = torch.argmax(output).item()\n",
    "        \n",
    "        total += 1\n",
    "        correct += (pred == label)\n",
    "\n",
    "print('Accuracy of the network on the test samples: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimental_loop(d, k_apt, k_pep):\n",
    "    # Construct the dataset\n",
    "    print(\"Constructing the dataset\")\n",
    "    aptamer_features, peptide_features, split = extract_features(subsampled_dataset, d=d, k_apt=k_apt, k_pep=k_pep)\n",
    "    train_aptamers, train_peptides, test_aptamers, test_peptides = construct_train_test_sets(aptamer_features, peptide_features, split)\n",
    "    train_pep, train_apt, test_pep, test_apt, train_aff, test_aff = reshape_dataset(train_aptamers, test_aptamers, train_peptides, test_peptides)\n",
    "    train_dataset = AptamerPeptideDataset(train_pep, train_apt, train_aff)\n",
    "    test_dataset = AptamerPeptideDataset(test_pep, test_apt, test_aff)\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "    testloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "    # Construct the model\n",
    "    print(\"Constructing the model\")\n",
    "    model = SmallNN(d_value=d)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    # Training loop\n",
    "    for epoch in range(1):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        model.train()\n",
    "        for i, data in enumerate(trainloader):\n",
    "            pep = data['peptide']\n",
    "            apt = data['aptamer']\n",
    "            label = data['affinity'].item()\n",
    "            one_hot_label = [0] * 4\n",
    "            one_hot_label[label] = 1\n",
    "            one_hot_label = torch.tensor(one_hot_label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(pep, apt)\n",
    "            loss = model.loss(output, one_hot_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    # Testing loop\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader):\n",
    "            pep = data['peptide']\n",
    "            apt = data['aptamer']\n",
    "            label = data['affinity'].item()\n",
    "\n",
    "            output = model(pep, apt)\n",
    "            pred = torch.argmax(output).item()\n",
    "\n",
    "            total += 1\n",
    "            correct += (pred == label)\n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimental_testing_loop(d, k_apt, k_pep):\n",
    "    # Construct the dataset\n",
    "    aptamer_features, peptide_features, split = extract_features(subsampled_dataset, d=d, k_apt=k_apt, k_pep=k_pep)\n",
    "    train_aptamers, train_peptides, test_aptamers, test_peptides = construct_train_test_sets(aptamer_features, peptide_features, split)\n",
    "    train_pep, train_apt, test_pep, test_apt, train_aff, test_aff = reshape_dataset(train_aptamers, test_aptamers, train_peptides, test_peptides)\n",
    "    train_dataset = AptamerPeptideDataset(train_pep, train_apt, train_aff)\n",
    "    test_dataset = AptamerPeptideDataset(test_pep, test_apt, test_aff)\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "    testloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "    # Construct the model\n",
    "    model = SmallNN(d_value=d)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    # Training loop\n",
    "    for epoch in range(3):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        model.train()\n",
    "        for i, data in enumerate(trainloader):\n",
    "            pep = data['peptide']\n",
    "            apt = data['aptamer']\n",
    "            label = data['affinity'].item()\n",
    "            one_hot_label = [0] * 4\n",
    "            one_hot_label[label] = 1\n",
    "            one_hot_label = torch.tensor(one_hot_label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(pep, apt)\n",
    "            loss = model.loss(output, one_hot_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        # Testing loop\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(testloader):\n",
    "                pep = data['peptide']\n",
    "                apt = data['aptamer']\n",
    "                label = data['affinity'].item()\n",
    "\n",
    "                output = model(pep, apt)\n",
    "                pred = torch.argmax(output).item()\n",
    "\n",
    "                total += 1\n",
    "                correct += (pred == label)\n",
    "        print('Accuracy of the network after ' + str(epoch) + ' epoch on the test samples: %d %%' % (100* correct/total))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_values = [1800, 2200, 2600, 3000, 3400]\n",
    "for d in d_values:\n",
    "    correct, total = experimental_loop(d=d, k_apt=4, k_pep=4)\n",
    "    print('D-value', d)\n",
    "    print('Accuracy of the network on the test samples: %d %%' % (100* correct/total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_apt_values = [4, 6, 8, 10]\n",
    "k_pep_values = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "for a in k_apt_values:\n",
    "    for p in k_pep_values:\n",
    "        correct, total = experimental_loop(d=1800, k_apt=a, k_pep=p)\n",
    "        print(\"D-value \" + str(d) + \" K_apt \" + str(a) + \" K_pep \" + str(p))\n",
    "        print('Accuracy of the network on the test samples: %d %%' % (100* correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_testing_loop(1800, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, total = experimental_loop(1800, 2, 5)\n",
    "print('Accuracy of the network on the test samples: %d %%' % (100* correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
