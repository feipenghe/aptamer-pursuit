{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_dataset_file = \"../data/aptamer_dataset.json\"\n",
    "clustered_dataset_file = \"../data/clustered_aptamer_dataset.json\"\n",
    "\n",
    "def construct_dataset():\n",
    "    with open(clustered_dataset_file, 'r') as f:\n",
    "        aptamer_data = json.load(f)\n",
    "    full_dataset = []\n",
    "    for aptamer in aptamer_data:\n",
    "        peptides = aptamer_data[aptamer]\n",
    "        for peptide, _ in peptides:\n",
    "            peptide = peptide.replace(\"_\", \"\")\n",
    "            if len(aptamer) == 40 and len(peptide) == 7:\n",
    "                peptide = \"M\" + peptide\n",
    "                full_dataset.append((aptamer, peptide))\n",
    "    return list(set(full_dataset)) #removed duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40564\n"
     ]
    }
   ],
   "source": [
    "full_dataset = construct_dataset()\n",
    "aptamers = [p[0] for p in full_dataset]\n",
    "peptides = [p[1] for p in full_dataset]\n",
    "training_set = full_dataset[:int(0.8*len(full_dataset))]\n",
    "test_set = full_dataset[int(0.8*len(full_dataset)):]\n",
    "print(str(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_set):\n",
    "        super(TrainDataset, self).__init__() \n",
    "        self.training_set = training_set\n",
    "        n = len(training_set)\n",
    "        self.training_set = training_set[:n-n%BATCH_SIZE]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.training_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.training_set[idx]\n",
    "        return aptamer, peptide\n",
    "    \n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, test_set):\n",
    "        super(TestDataset, self).__init__() \n",
    "        self.test_set = test_set\n",
    "        n = len(test_set)\n",
    "        self.test_set = test_set[:n-n%BATCH_SIZE]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.test_set[idx]\n",
    "        return aptamer, peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(training_set)\n",
    "test_dataset = TestDataset(test_set)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_list = ['A', 'C', 'G', 'T']\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y']\n",
    "pvals = [0.089]*3 + [0.065]*5 + [0.034]*12\n",
    "aa_dict = dict(zip(aa_list, pvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def one_hot(sequence_list, seq_type='peptide'):\n",
    "    if seq_type == 'peptide':\n",
    "        letters = aa_list\n",
    "    else:\n",
    "        letters = na_list\n",
    "    \n",
    "    one_hot = np.zeros((len(sequence_list), len(sequence_list[0]), len(letters)))\n",
    "    \n",
    "    for j in range(len(sequence_list)):\n",
    "        sequence = sequence_list[j]\n",
    "        for i in range(len(sequence)):\n",
    "            element = sequence[i]\n",
    "            idx = letters.index(element)\n",
    "            one_hot[j][i][idx] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayer, self).__init__()\n",
    "        self.linear_apt_1 = nn.Linear(40, 40)\n",
    "        self.linear_apt_2 = nn.Linear(40, 1)\n",
    "        \n",
    "        self.linear_pep_1 = nn.Linear(8, 8)\n",
    "        self.linear_pep_2 = nn.Linear(8, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "        self.sequential_pep = nn.Sequential(self.linear_pep_1,\n",
    "                                            self.relu,\n",
    "                                            self.linear_pep_2)\n",
    "        \n",
    "        self.sequential_apt = nn.Sequential(self.linear_apt_1,\n",
    "                                            self.relu,\n",
    "                                            self.linear_apt_2)\n",
    "                \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.sequential_apt(apt)\n",
    "        pep = self.sequential_pep(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, prediction, label):\n",
    "        l = nn.MSELoss()\n",
    "        label = torch.FloatTensor(label)\n",
    "        label = label.reshape((1, 1))\n",
    "        return l(torch.FloatTensor(prediction), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(BATCH_SIZE, 40, 1)\n",
    "        self.cnn_apt_2 = nn.Conv2d(40, 10, 1)\n",
    "        self.cnn_apt_3 = nn.Conv2d(10, 1, 1)\n",
    "        self.fc_apt_1 = nn.Linear(160, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv2d(BATCH_SIZE, 8, 1)\n",
    "        self.cnn_pep_2 = nn.Conv2d(8, 1, 1)\n",
    "        self.fc_pep_1 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.sequential_pep = nn.Sequential(self.cnn_pep_1,\n",
    "                                            #self.dropout,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_pep_2)\n",
    "        \n",
    "        self.sequential_apt = nn.Sequential(self.cnn_apt_1, \n",
    "                                            #self.dropout,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_2, \n",
    "                                            #self.dropout,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(209, BATCH_SIZE)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.sequential_apt(apt)\n",
    "        pep = self.sequential_pep(pep)\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, prediction, label):\n",
    "        l = nn.MSELoss()\n",
    "        label = torch.FloatTensor(label)\n",
    "        return l(torch.FloatTensor(prediction), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(batch_size=BATCH_SIZE)\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "\n",
    "#model_2 = TwoLayer()\n",
    "# def weights_init_2(m):\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         nn.init.xavier_uniform_(m.weight.data)\n",
    "#         nn.init.zeros_(m.bias.data)\n",
    "\n",
    "model.apply(weights_init)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/633 [00:00<?, ?it/s]/ssd1/home/aishrm2/anaconda3/envs/research/lib/python2.7/site-packages/ipykernel_launcher.py:24: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  0%|          | 1/633 [00:00<01:33,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/633 [00:01<01:10,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 61.4689205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 22/633 [00:02<01:01,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 47.9223087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 33/633 [00:03<00:58, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    30] loss: 21.0020545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 41/633 [00:04<01:05,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    40] loss: 3.3176869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 54/633 [00:05<00:48, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 1.3538689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 60/633 [00:05<00:34, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    60] loss: 1.8007408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 71/633 [00:06<01:02,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    70] loss: 1.3526288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 82/633 [00:08<01:00,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    80] loss: 0.6807662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 91/633 [00:09<01:03,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    90] loss: 0.5666671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 101/633 [00:10<01:17,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.5375870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 111/633 [00:12<01:25,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   110] loss: 0.5382289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 121/633 [00:13<01:13,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   120] loss: 0.4397897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 131/633 [00:15<01:14,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   130] loss: 0.4018961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 141/633 [00:16<01:20,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   140] loss: 0.3866037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 151/633 [00:18<01:18,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   150] loss: 0.4471696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 161/633 [00:19<01:05,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   160] loss: 0.3783663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 171/633 [00:21<01:11,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   170] loss: 0.3560505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 181/633 [00:22<01:08,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   180] loss: 0.3806872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 191/633 [00:23<00:43, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   190] loss: 0.3704663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 204/633 [00:24<00:27, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.3622590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 212/633 [00:24<00:22, 19.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   210] loss: 0.3609684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 221/633 [00:25<00:39, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   220] loss: 0.3357642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 231/633 [00:26<00:31, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   230] loss: 0.3464744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 243/633 [00:27<00:26, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   240] loss: 0.3539533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 251/633 [00:27<00:31, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   250] loss: 0.3538663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 263/633 [00:29<00:30, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   260] loss: 0.3542832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 273/633 [00:29<00:23, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   270] loss: 0.3359359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 283/633 [00:30<00:22, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   280] loss: 0.3566108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 293/633 [00:30<00:20, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   290] loss: 0.3530959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 303/633 [00:31<00:20, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 0.3533762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 313/633 [00:32<00:20, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   310] loss: 0.3367805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 321/633 [00:33<00:32,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   320] loss: 0.3155464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 331/633 [00:34<00:42,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   330] loss: 0.4013364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 342/633 [00:35<00:36,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   340] loss: 0.3346506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 352/633 [00:36<00:25, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   350] loss: 0.3184173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 362/633 [00:37<00:20, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   360] loss: 0.3654594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 372/633 [00:38<00:18, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   370] loss: 0.3621911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 381/633 [00:38<00:19, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   380] loss: 0.3320122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 392/633 [00:39<00:17, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   390] loss: 0.3899092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 402/633 [00:40<00:18, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss: 0.3275609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 410/633 [00:41<00:22,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   410] loss: 0.3556760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 422/633 [00:42<00:22,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   420] loss: 0.3336691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 430/633 [00:43<00:20,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   430] loss: 0.3690396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 441/633 [00:44<00:22,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   440] loss: 0.3625881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 451/633 [00:46<00:27,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   450] loss: 0.3259897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 461/633 [00:47<00:29,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   460] loss: 0.3679208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 471/633 [00:49<00:24,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   470] loss: 0.3515721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 480/633 [00:50<00:19,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   480] loss: 0.3347246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 491/633 [00:51<00:15,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   490] loss: 0.3577720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 501/633 [00:53<00:16,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.3906060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 511/633 [00:54<00:15,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   510] loss: 0.2983237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 521/633 [00:55<00:14,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   520] loss: 0.3809748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 531/633 [00:56<00:13,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   530] loss: 0.3464099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 541/633 [00:58<00:11,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   540] loss: 0.3708178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 551/633 [00:59<00:11,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   550] loss: 0.3290696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 561/633 [01:00<00:11,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   560] loss: 0.3778466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 571/633 [01:02<00:10,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   570] loss: 0.3535264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 581/633 [01:04<00:08,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   580] loss: 0.3388720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 591/633 [01:05<00:06,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   590] loss: 0.3836388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 601/633 [01:07<00:05,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   600] loss: 0.3157116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 611/633 [01:08<00:03,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   610] loss: 0.3897336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 621/633 [01:10<00:01,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   620] loss: 0.3457360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 631/633 [01:11<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   630] loss: 0.3450323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 633/633 [01:12<00:00,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(1):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    # Come up with a trainloader\n",
    "    for batch_idx, (aptamer, peptide) in enumerate(tqdm.tqdm(train_loader)):\n",
    "        # Peptide and aptamer, one-hot encode them \n",
    "        pep = one_hot(peptide, seq_type='peptide')\n",
    "        apt = one_hot(aptamer, seq_type='aptamer')\n",
    "        \n",
    "        pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[0], pep.shape[1], pep.shape[2])))\n",
    "        apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[0], apt.shape[1], apt.shape[2])))\n",
    "        \n",
    "        output = model(apt, pep)\n",
    "        \n",
    "        label = np.ones((1, BATCH_SIZE))\n",
    "        loss = model.loss(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        #hyperparameter\n",
    "        clip = 5\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 10 == 9:\n",
    "            print('[%d, %5d] loss: %.7f' %\n",
    "                  (epoch + 1, batch_idx + 1, running_loss / 10*BATCH_SIZE))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/158 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the network on the test samples: 100 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "for batch_idx, (aptamer, peptide) in enumerate(tqdm.tqdm(test_loader)):\n",
    "    pep = one_hot(peptide, seq_type='peptide')\n",
    "    apt = one_hot(aptamer, seq_type='aptamer')\n",
    "    \n",
    "    pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[0], pep.shape[1], pep.shape[2])))\n",
    "    apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[0], apt.shape[1], apt.shape[2])))\n",
    "\n",
    "    output = model(apt, pep).detach().numpy().flatten()\n",
    "    for i in range(output.shape[0]):\n",
    "        o = output[i]\n",
    "        if o > 0.9:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    break\n",
    "\n",
    "print('Recall of the network on the test samples: %d %%' % (100* correct/(correct + incorrect)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample x from P_X (assume peptides follow NNK)\n",
    "def get_x():\n",
    "    x_idx = np.random.choice(20, 7, p=pvals)\n",
    "    x = \"M\"\n",
    "    for i in x_idx:\n",
    "        x += aa_list[i]\n",
    "    return x\n",
    "\n",
    "# Sample y from P_Y (assume apatamers follow uniform)\n",
    "def get_y():\n",
    "    y_idx = np.random.randint(0, 4, 40)\n",
    "    y = \"\"\n",
    "    for i in y_idx:\n",
    "        y += na_list[i]\n",
    "    return y\n",
    "\n",
    "# Generate uniformly from S without replacement\n",
    "def get_xy(k):\n",
    "    samples = [full_dataset[i] for i in np.random.choice(len(full_dataset), k, replace=False)]\n",
    "    return samples\n",
    "\n",
    "# S' contains S with double the size of S (domain for Importance Sampling)\n",
    "def get_S_prime(k):\n",
    "    S_prime = full_dataset.copy()\n",
    "    for _ in range(k):\n",
    "        S_prime.append((get_y(), get_x()))\n",
    "    S_prime_new = S_prime.copy()[-n:]\n",
    "    return list(set(S_prime)), S_prime_new\n",
    "\n",
    "# Sample from S' without replacement\n",
    "def get_xy_prime(k):\n",
    "    samples = [S_prime[i] for i in np.random.choice(len(S_prime), k, replace=False)]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test whether naive sampling would generate pairs in S -- nope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(full_dataset)\n",
    "S_prime, S_prime_new = get_S_prime(n)\n",
    "print(\"Size of S: \", n)\n",
    "print(\"Size of naively sampled dataset: \", len(S_prime_new))\n",
    "diff = set(full_dataset) - set(S_prime_new)\n",
    "print(\"Size of set difference: \", len(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivates importance sampling in SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns pmf of a peptide\n",
    "def get_x_pmf(x):\n",
    "    pmf = 1\n",
    "    for char in x[1:]: #skips first char \"M\"\n",
    "        pmf *= aa_dict[char]\n",
    "    return pmf\n",
    "\n",
    "# Returns pmf of an aptamer\n",
    "def get_y_pmf():\n",
    "    return 0.25**40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(t=int(1e5), #num of iter\n",
    "        gamma=1e-2, #step size\n",
    "        batch=1): #batch size\n",
    "    for _ in range(t):\n",
    "        xy = get_xy(1) #sample pair from S\n",
    "        xy_prime = get_xy_prime(1) #sample pair from S'\n",
    "        const = 1 #indicator\n",
    "        x_prime_pmf = get_x_pmf(xy_prime[0][1])\n",
    "        y_prime_pmf = get_y_pmf()\n",
    "        if xy_prime in full_dataset:\n",
    "            const = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
