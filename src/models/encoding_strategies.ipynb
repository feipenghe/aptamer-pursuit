{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding strategies\n",
    "* This file implements different encoding strategies like direct translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "k = 10000\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "hydrophobicity = {'G': 0, 'A': 41, 'L':97, 'M': 74, 'F':100, 'W':97, 'K':-23, 'Q':-10, 'E':-31, 'S':-5, 'P':-46, 'V':76, 'I':99, 'C':49, 'Y':63, 'H':8, 'R':-14, 'N':-28, 'D':-55, 'T':13}\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*13 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "aa_dict = dict(zip(aa_list, pvals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        def construct_binary_dataset(filepath):\n",
    "            with open(filepath, 'r') as f:\n",
    "                aptamer_data = json.load(f)\n",
    "            ds = []\n",
    "            for aptamer in aptamer_data:\n",
    "                peptides = aptamer_data[aptamer]\n",
    "                for peptide in peptides:\n",
    "                    ds.append((aptamer, peptide, 1))\n",
    "                    ds.append((get_x(), get_y(), 0))\n",
    "            ds = list(set(ds)) #removed duplicates, random order\n",
    "            return ds\n",
    "\n",
    "        # Sample x from P_X (assume apatamers follow uniform)\n",
    "        def get_x():\n",
    "            x_idx = np.random.randint(0, 4, 40)\n",
    "            x = \"\"\n",
    "            for i in x_idx:\n",
    "                x += na_list[i]\n",
    "            return x\n",
    "\n",
    "        # Sample y from P_y (assume peptides follow NNK)\n",
    "        def get_y():\n",
    "            y_idx = np.random.choice(20, 7, p=pvals)\n",
    "            y = \"M\"\n",
    "            for i in y_idx:\n",
    "                y += aa_list[i]\n",
    "            return y\n",
    "\n",
    "        self.binary_ds=construct_binary_dataset(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.binary_ds)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return(self.binary_ds[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_ds=BinaryDataset(filepath=\"../data/aptamer_dataset.json\")\n",
    "n = len(binary_ds)\n",
    "m = int(0.8*n) #length of train\n",
    "binary_train = binary_ds[:m]\n",
    "binary_val = binary_ds[m:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.name = \"LinearNet\"\n",
    "        \n",
    "        self.fc_apt_1 = nn.Linear(160, 200) \n",
    "        self.fc_apt_2 = nn.Linear(200, 250)\n",
    "        self.fc_apt_3 = nn.Linear(250, 300)\n",
    "        \n",
    "        self.fc_pep_1 = nn.Linear(160, 200)\n",
    "        self.fc_pep_2 = nn.Linear(200, 250)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc_apt = nn.Sequential(self.fc_apt_1, self.fc_apt_2, self.fc_apt_3)\n",
    "        self.fc_pep = nn.Sequential(self.fc_pep_1, self.fc_pep_2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(550, 600)\n",
    "        self.fc2 = nn.Linear(600, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        apt = self.fc_apt(apt)\n",
    "        pep = self.fc_pep(pep)\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc2(self.fc1(x))\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearConv1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearConv1d, self).__init__()\n",
    "        self.name = \"LinearConv1d\"\n",
    "        \n",
    "        self.cnn_apt_1 = nn.Conv1d(4, 10, 3) \n",
    "        self.cnn_apt_2 = nn.Conv1d(10, 25, 3) \n",
    "        self.cnn_apt_3 = nn.Conv1d(25, 50, 3) \n",
    "        self.cnn_apt_4 = nn.Conv1d(50, 100, 1) \n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv1d(20, 50, 3)\n",
    "        self.cnn_pep_2 = nn.Conv1d(50, 100, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu, \n",
    "                                     self.cnn_apt_2, self.maxpool, self.relu,\n",
    "                                     self.cnn_apt_3, self.maxpool, self.relu,\n",
    "                                     self.cnn_apt_4, self.maxpool, self.relu)\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu,\n",
    "                                     self.cnn_pep_2, self.maxpool, self.relu)\n",
    "        \n",
    "        self.fc1 = nn.Linear(200, 200)\n",
    "        self.fc2 = nn.Linear(200, 1)\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.permute(0, 2, 1)\n",
    "        pep = pep.permute(0, 2, 1)\n",
    "        apt = self.cnn_apt(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        #print(apt.size())\n",
    "        #print(pep.size())\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='sigmoid')\n",
    "        nn.init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslateNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TranslateNet, self).__init__()\n",
    "        self.name = \"TranslateNet\"\n",
    "        \n",
    "        self.cnn_apt_1 = nn.Conv1d(40, 25, 2, padding=2) \n",
    "        self.cnn_apt_2 = nn.Conv1d(25, 15, 2, padding=2) \n",
    "        self.cnn_apt_3 = nn.Conv1d(15, 10, 2, padding=2) \n",
    "        self.cnn_apt_4 = nn.Conv1d(10, 5, 1) \n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv1d(8, 15, 3, padding=2)\n",
    "        self.cnn_pep_2 = nn.Conv1d(15, 5, 1, padding=2)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu, \n",
    "                                     self.cnn_apt_2, self.maxpool, self.relu,\n",
    "                                     self.cnn_apt_3, self.maxpool, self.relu,\n",
    "                                     self.cnn_apt_4, self.maxpool, self.relu)\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu,\n",
    "                                     self.cnn_pep_2, self.maxpool, self.relu)\n",
    "        \n",
    "        self.fc1 = nn.Linear(15, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.permute(1, 2, 0)\n",
    "        pep = pep.permute(1, 2, 0)\n",
    "        apt = self.cnn_apt(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def translate(sequence, seq_type='peptide', single_alphabet=False):\n",
    "    if single_alphabet:\n",
    "        apt = sequence[0]\n",
    "        pep = sequence[1]\n",
    "        \n",
    "        encoding = np.zeros(len(apt) + len(pep))\n",
    "        \n",
    "        # Encode the aptamer first\n",
    "        for i in range(len(apt)):\n",
    "            char = apt[i]\n",
    "            idx = na_list.index(char)\n",
    "            encoding[i] = idx\n",
    "            \n",
    "        # Encode the peptide second\n",
    "        for i in range(len(pep)):\n",
    "            char = pep[i]\n",
    "            idx = aa_list.index(char)\n",
    "            encoding[i+len(apt)] = idx\n",
    "        return encoding     \n",
    "    else:\n",
    "        if seq_type == 'peptide':\n",
    "            letters = aa_list\n",
    "        else:\n",
    "            letters = na_list\n",
    "        \n",
    "        encoding = np.zeros(len(sequence))\n",
    "        for i in range(len(sequence)):\n",
    "            char = sequence[i]\n",
    "            idx = letters.index(char)\n",
    "            encoding[i] = idx\n",
    "        return encoding\n",
    "\n",
    "# Convert a pair to one-hot tensor\n",
    "def convert(apt, pep, label, single_alphabet=False): \n",
    "    if single_alphabet:\n",
    "        pair = translate([apt, pep], single_alphabet=True)\n",
    "        pair = torch.FloatTensor(np.reshape(pair, (-1, pair.shape[0], pair.shape[1]))).to(device)\n",
    "        label = torch.FloatTensor([label]).to(device)\n",
    "        return pair, label\n",
    "    else:\n",
    "        apt = translate(apt, seq_type='aptamer') #(40, )\n",
    "        pep = translate(pep, seq_type='peptide') #(8, )\n",
    "        apt = torch.FloatTensor(np.reshape(apt, (-1, 1, apt.shape[0]))).to(device) #(1, 1, 40)\n",
    "        pep = torch.FloatTensor(np.reshape(pep, (-1, 1, pep.shape[0]))).to(device) #(1, 1, 8)\n",
    "        label = torch.FloatTensor([label]).to(device)\n",
    "        return apt, pep, label\n",
    "\n",
    "# Getting the output of the model for a pair (aptamer, peptide)\n",
    "def update(x, y, p, single_alphabet=False):\n",
    "    if single_alphabet:\n",
    "        p.requires_grad=True\n",
    "        p = p.to(device)\n",
    "        out = model(p)\n",
    "        return out\n",
    "    else:\n",
    "        x.requires_grad=True\n",
    "        y.requires_grad=True\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = model(x, y)\n",
    "        return out\n",
    "\n",
    "## Plotting functions\n",
    "def plot_loss(iters, train_losses, val_losses, model_name, model_id):\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.plot(train_losses, label=\"Train\")\n",
    "    plt.plot(val_losses, label=\"Validation\")\n",
    "    plt.xlabel(\"%d Iterations\" %iters)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('plots/binary/%s/%s/loss.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(iters, train_acc, val_acc, model_name, model_id):\n",
    "    plt.title(\"Training Accuracy Curve\")\n",
    "    plt.plot(train_acc, label=\"Train\")\n",
    "    plt.plot(val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"%d Iterations\" %iters)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('plots/binary/%s/%s/accuracy.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram(gen_scores, train_scores, val_scores, model_name, model_id):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xlim(0, 1.1)\n",
    "    sns.distplot(gen_scores , color=\"skyblue\", label='Generated', ax=ax)\n",
    "    sns.distplot(train_scores , color=\"gold\", label='Train', ax=ax)\n",
    "    sns.distplot(val_scores, color='red', label='Validation', ax=ax)\n",
    "    ax.set_title(\"Distribution of Scores\")\n",
    "    ax.figure.set_size_inches(7, 4)\n",
    "    ax.legend()\n",
    "    plt.savefig('plots/binary/%s/%s/histogram.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Modify these to be for binary classification\n",
    "def plot_ecdf_test(test_score, iters, epoch, lamb, gamma, model_name, model_id):\n",
    "    test_idx = np.argsort(test_score)\n",
    "    test_id = test_idx >= 10000\n",
    "    test = np.sort(test_score)\n",
    "    test_c = \"\"\n",
    "    for m in test_id:\n",
    "        if m:\n",
    "            test_c += \"y\"\n",
    "        else:\n",
    "            test_c += \"g\"\n",
    "    n = test_score.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    plt.scatter(y, test, c=test_c, label='Test CDF')\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.xlabel(\"Most recent 10,000 samples after training %d samples\" %iters)\n",
    "    plt.title('Test CDF at epoch %d' %epoch+ \" Lambda :%.5f\" %lamb + \", Gamma:%.5f\" %gamma)\n",
    "    plt.legend()\n",
    "    plt.savefig('plots/mle/%s/%s/test_cdf.png' %(model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_ecdf_train(train_score, iters, epoch, lamb, gamma, model_name, model_id):\n",
    "    train_idx = np.argsort(train_score)\n",
    "    train_id = train_idx >= 10000\n",
    "    train = np.sort(train_score)\n",
    "    train_c = \"\" #colors\n",
    "    for l in train_id:\n",
    "        if l:\n",
    "            train_c += \"r\"\n",
    "        else:\n",
    "            train_c += \"b\"\n",
    "    n = train_score.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    plt.scatter(y, train, c=train_c, label='Train CDF')\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.xlabel(\"Most recent 10,000 samples after training %d samples\" %iters)\n",
    "    plt.title('Train CDF at epoch %d' %epoch+ \" Lambda :%.5f\" %lamb + \", Gamma:%.5f\" %gamma)\n",
    "    plt.legend()\n",
    "    plt.savefig('plots/mle/%s/%s/train_cdf.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the regular translate method\n",
    "oh = translate('LL', seq_type='peptide')\n",
    "oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the translate method with single alphabet\n",
    "oh = translate([\"GGGG\", \"LL\"], single_alphabet=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(model, \n",
    "               train, \n",
    "               val,\n",
    "               lr,\n",
    "               model_id,\n",
    "               num_epochs=50,\n",
    "               batch_size=16,\n",
    "               single_alphabet=False,\n",
    "               run_from_checkpoint=None, \n",
    "               save_checkpoints=None):\n",
    "    \n",
    "    if run_from_checkpoint is not None:\n",
    "        checkpointed_model = run_from_checkpoint\n",
    "        checkpoint = torch.load(checkpointed_model)\n",
    "        optimizer = SGD(model.parameters(), lr=5e-3)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        init_epoch = checkpoint['epoch']\n",
    "        print(\"Reloading model: \", model.name, \" at epoch: \", init_epoch)\n",
    "    else:\n",
    "        model.apply(weights_init)\n",
    "        init_epoch = 0\n",
    "    \n",
    "    train_losses, val_losses, train_losses_avg, val_losses_avg, train_acc, val_acc = [], [], [], [], [], []\n",
    "    iters, train_correct, val_correct = 0, 0, 0\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=3, gamma=0.9) #Decays lr by gamma factor every step_size epochs. \n",
    "    \n",
    "    train_scores, val_scores, gen_scores = [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        scheduler.step()\n",
    "        full_epoch = init_epoch + epoch\n",
    "        print(\"Starting epoch: %d\" %full_epoch, \" with learning rate: \", scheduler.get_lr())\n",
    "        for (apt, pep, label) in train:\n",
    "            model_name = model.name\n",
    "            model.train()\n",
    "            if single_alphabet:\n",
    "                p, l = convert(apt, pep, label, single_alphabet=True)\n",
    "                train_score = update(None, None, p, single_alphabet=True)\n",
    "            else:\n",
    "                a, p, l = convert(apt, pep, label, single_alphabet=False)\n",
    "                train_score = update(a, p, None, single_alphabet=False)\n",
    "                \n",
    "            if (train_score.item() >= 0.5 and label == 1.0) or (train_score.item() <= 0.5 and label == 0.0):\n",
    "                train_correct += 1\n",
    "            \n",
    "            if label == 0.0:\n",
    "                gen_scores.append(train_score.item())\n",
    "            elif label == 1.0:\n",
    "                train_scores.append(train_score.item())\n",
    "                \n",
    "            iters += 1\n",
    "            train_loss = criterion(train_score, l) \n",
    "            total_train_loss += train_loss\n",
    "            \n",
    "            if iters % batch_size == 0:\n",
    "                ave_train_loss = total_train_loss/batch_size\n",
    "                train_losses.append(ave_train_loss.item())\n",
    "                optimizer.zero_grad()\n",
    "                ave_train_loss.backward()\n",
    "                optimizer.step()\n",
    "                total_train_loss = 0\n",
    "\n",
    "            if iters % 5000 == 0:\n",
    "                train_acc.append(100*train_correct/iters)\n",
    "                train_losses_avg.append(np.average(train_losses[-5000:]))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "            if single_alphabet:\n",
    "                p_val, l_val = convert(val[iters%(n-m)][0], val[iters%(n-m)][1], val[iters%(n-m)][2], single_alphabet=True)\n",
    "                val_score = model(p_val)\n",
    "            else:\n",
    "                a_val, p_val, l_val = convert(val[iters%(n-m)][0], val[iters%(n-m)][1], val[iters%(n-m)][2])\n",
    "                val_score = model(a_val, p_val)\n",
    "            if (val_score.item() >= 0.5 and val[iters%(n-m)][2] == 1.0) or (val_score.item() <= 0.5 and val[iters%(n-m)][2] == 0.0):\n",
    "                val_correct += 1\n",
    "            \n",
    "            val_scores.append(val_score.item())\n",
    "            val_loss = criterion(val_score, l_val) \n",
    "            total_val_loss += val_loss\n",
    "            if iters % batch_size == 0:\n",
    "                ave_val_loss = total_val_loss/batch_size\n",
    "                val_losses.append(ave_val_loss.item())\n",
    "                total_val_loss = 0\n",
    "            if iters % 5000 == 0:\n",
    "                val_acc.append(100*val_correct/iters)\n",
    "                val_losses_avg.append(np.average(val_losses[-5000:]))\n",
    "\n",
    "            if iters % 50000 == 0:\n",
    "                plot_loss(iters, train_losses_avg, val_losses_avg, model_name, model_id)\n",
    "                plot_accuracy(iters, train_acc, val_acc, model_name, model_id)\n",
    "                plot_histogram(gen_scores, train_scores, val_scores, model_name, model_id)\n",
    "                \n",
    "                print(\"Training Accuracy at epoch %d: {}\".format(train_acc[-1]) %epoch)\n",
    "                print(\"Validation Accuracy epoch %d: {}\".format(val_acc[-1]) %epoch)\n",
    "        if save_checkpoints is not None:\n",
    "            print(\"Saving to: \", save_checkpoints)\n",
    "            checkpoint_name = save_checkpoints\n",
    "            torch.save({'epoch': full_epoch,\n",
    "                        'model_state_dict': model.state_dict(), \n",
    "                        'optimizer_state_dict': optimizer.state_dict()}, checkpoint_name)\n",
    "        \n",
    "        # Clear unused gpu memory at the end of the epoch\n",
    "        if device == torch.cuda:\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd1/home/aishrm2/anaconda3/envs/aptamers/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:117: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0  with learning rate:  [0.1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd1/home/aishrm2/anaconda3/envs/aptamers/lib/python3.8/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plots/binary/TranslateNet/06162020/loss.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b1439f9dd6fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_alphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-95ee3fcff2a7>\u001b[0m in \u001b[0;36mclassifier\u001b[0;34m(model, train, val, lr, model_id, num_epochs, batch_size, single_alphabet, run_from_checkpoint, save_checkpoints)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miters\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mplot_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mplot_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-067b2def1afc>\u001b[0m in \u001b[0;36mplot_loss\u001b[0;34m(iters, train_losses, val_losses, model_name, model_id)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plots/binary/%s/%s/loss.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aptamers/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aptamers/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aptamers/lib/python3.8/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m                 result = print_method(\n\u001b[0m\u001b[1;32m   2085\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m                     \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aptamers/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m                     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 _png.write_png(renderer._renderer, fh,\n",
      "\u001b[0;32m~/anaconda3/envs/aptamers/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aptamers/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aptamers/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plots/binary/TranslateNet/06162020/loss.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TranslateNet()\n",
    "model_name = model.name\n",
    "model_id = \"06162020\"\n",
    "model.to(device)\n",
    "checkpoint = None\n",
    "save_path = 'model_checkpoints/binary/%s/%s.pth' % (model_name, model_id)\n",
    "single_alphabet = False\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "gamma = 1e-1\n",
    "classifier(model, binary_train, binary_val, gamma, model_id, NUM_EPOCHS, BATCH_SIZE, single_alphabet, checkpoint, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aptamers",
   "language": "python",
   "name": "aptamers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
