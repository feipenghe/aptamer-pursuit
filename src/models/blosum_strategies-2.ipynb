{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blosum strategies\n",
    "* This file compares using the original blosum rows as features vs. doing eigenvalue decomposition and then constructing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "k = 10000\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*12 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "uniform_pvals = [0.05]*20\n",
    "\n",
    "encoding_style = 'regular'\n",
    "alpha=10\n",
    "beta=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New distribution (not NNK exactly)\n",
    "aa_list_2 = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\",  \"I\",  \"K\",  \"L\",  \"M\",  \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\",  \"W\", \"Y\"]\n",
    "pvals_2 = [0.07668660126327106, 0.035596693992742914, 0.02474465797607849, 0.04041795457599785, 0.02319916677865878, 0.1149711060341352, 0.02187206020696143, 0.021972853111140975, 0.030170675984410696, 0.0904280338664158, 0.030069883080231154, 0.017672355866147026, 0.03937642789947588, 0.03156497782556108, 0.1183812659588765, 0.07880325225104153, 0.043290552345114905, 0.08557317564843435, 0.053369842763069476, 0.02183846257223492]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original BLOSUM62 matrix\n",
    "original_blosum62 = {}\n",
    "with open('blosum62.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        split_line = line.strip().split()\n",
    "        aa = split_line[0]\n",
    "        encoding = [int(x) for x in split_line[1:-3]]\n",
    "        original_blosum62[aa] = encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blosum_matrix = np.zeros((20, 20))\n",
    "for i, aa in enumerate(original_blosum62.keys()):\n",
    "    sims = original_blosum62[aa]\n",
    "    for j, s in enumerate(sims):\n",
    "        blosum_matrix[i][j] = s   \n",
    "u, V = LA.eig(blosum_matrix)\n",
    "clipped_u = u\n",
    "clipped_u[clipped_u < 0] = 0\n",
    "lamb = np.diag(clipped_u)\n",
    "T = V\n",
    "clip_blosum62 = {}\n",
    "for i, aa in enumerate(original_blosum62.keys()):\n",
    "    clip_blosum62[aa] = np.dot(np.sqrt(lamb), V[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biological features\n",
    "# kd hydrophobicity scale\n",
    "hydrophobicity = {'G': -0.4, 'A': 1.8, 'L':3.8, 'M': 1.9, 'F':2.8, 'W':-0.9, 'K':-3.9, 'Q':-3.5, 'E':-3.5, 'S':-0.8, 'P':-1.6, 'V':4.2, 'I':4.5, 'C':2.5, 'Y':-1.3, 'H':-3.2, 'R':-4.5, 'N':-3.5, 'D':-3.5, 'T':-0.7}\n",
    "# Ranked\n",
    "polarity = {'A': 0.45, 'R': 0.75, 'N': 0.8, 'D': 0.95, 'C':0.35, 'Q': 0.85, 'E': 0.90, 'G': 0.55, 'H': 0.5, 'I': 0.05, 'L': 0.15, 'K': 1, 'M': 0.25, 'F': 0.1, 'P': 0.65, 'S': 0.7, 'T': 0.6, 'W': 0.3, 'Y': 0.4, 'V': 0.2}\n",
    "# Van der waal's volume\n",
    "volume = {'A': 67, 'R': 148, 'N': 96, 'D': 91, 'C':86, 'Q': 114, 'E': 109, 'G': 48, 'H': 118, 'I': 124, 'L': 124, 'K': 135, 'M': 124, 'F': 135, 'P': 90, 'S': 73, 'T': 93, 'W':163, 'Y':141, 'V': 105}\n",
    "\n",
    "# TODO: branched, hydrophilic, hydrophobic, shape\n",
    "charge = {'A': 2, 'R': 3, 'N': 2, 'D': 1, 'C': 2, 'E':1, 'Q':2, 'G':2, 'H': 3, 'I':2, 'L': 2, 'K': 3, 'M':2, 'F':2, 'P':2, 'S':2, 'T': 2, 'W':2, 'Y': 2, 'V':2 }\n",
    "\n",
    "# Normalize all of the biological features:\n",
    "# Charge\n",
    "for k,v in charge.items():\n",
    "    if v == 1:\n",
    "        charge[k] = 0\n",
    "    elif v == 2:\n",
    "        charge[k] = 0.5\n",
    "    else:\n",
    "        charge[k] = 1.0\n",
    "\n",
    "# Volume\n",
    "for k,v in volume.items():\n",
    "    volume[k] = v/163.0\n",
    "\n",
    "#Polarity\n",
    "min_v = -4.5\n",
    "max_v = 4.5\n",
    "for k,v in hydrophobicity.items():\n",
    "    hydrophobicity[k] = (v - min_v)/(max_v - min_v)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class BinaryDataset(Dataset):\n",
    "    def __init__(self, filepath, distribution='NNK', negfilepath=None):\n",
    "        def construct_binary_dataset(filepath, distribution='NNK', negfilepath=None):\n",
    "            with open(filepath, 'r') as f:\n",
    "                aptamer_data = json.load(f)\n",
    "            pos_ds = []\n",
    "            neg_ds = []\n",
    "            gen_ds = []\n",
    "            for aptamer in aptamer_data:\n",
    "                peptides = aptamer_data[aptamer]\n",
    "                for peptide in peptides:\n",
    "                    pos_ds.append((aptamer, peptide, 1))\n",
    "                    gen_ds.append((get_x(), get_y(distribution), 0))\n",
    "            with open(negfilepath, 'r') as f:\n",
    "                neg_data = json.load(f)\n",
    "            for aptamer in neg_data:\n",
    "                peptides = neg_data[aptamer]\n",
    "                for peptide in peptides:\n",
    "                    neg_ds.append((aptamer, peptide, 0))\n",
    "            \n",
    "            pos_ds = list(set(pos_ds)) #removed duplicates, random order\n",
    "            neg_ds = list(set(neg_ds))\n",
    "            gen_ds = list(set(gen_ds))\n",
    "            return pos_ds, neg_ds, gen_ds\n",
    "\n",
    "        # Sample x from P_X (assume apatamers follow uniform)\n",
    "        def get_x():\n",
    "            x_idx = np.random.randint(0, 4, 40)\n",
    "            x = \"\"\n",
    "            for i in x_idx:\n",
    "                x += na_list[i]\n",
    "            return x\n",
    "\n",
    "        # Sample y from P_y (assume peptides follow NNK)\n",
    "        def get_y(distribution):\n",
    "            if distribution == 'NNK':\n",
    "                y_idx = np.random.choice(20, 7, p=pvals)\n",
    "                lst = aa_list\n",
    "            elif distribution == 'uniform':\n",
    "                y_idx = np.random.choice(20, 7, p=uniform_pvals)\n",
    "                lst = aa_list\n",
    "            elif distribution == 'new_nnk':\n",
    "                y_idx = np.random.choice(20, 7, p=pvals_2)\n",
    "                lst = aa_list_2\n",
    "            y = \"M\"\n",
    "            for i in y_idx:\n",
    "                y += lst[i]\n",
    "            return y\n",
    "\n",
    "        self.pos_ds, self.neg_ds, self.gen_ds =construct_binary_dataset(filepath, distribution, negfilepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.pos_ds), len(self.neg_ds))\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return(self.pos_ds[idx], self.neg_ds[idx], self.gen_ds[idx])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "source": [
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        def construct_binary_dataset(filepath):\n",
    "            with open(filepath, 'r') as f:\n",
    "                aptamer_data = json.load(f)\n",
    "            ds = []\n",
    "            for aptamer in aptamer_data:\n",
    "                peptides = aptamer_data[aptamer]\n",
    "                for peptide in peptides:\n",
    "                    ds.append((aptamer, peptide, 1))\n",
    "            ds = list(set(ds)) #removed duplicates, random order\n",
    "            return ds\n",
    "\n",
    "        self.binary_ds=construct_binary_dataset(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.binary_ds)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return(self.binary_ds[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class AUCDataset(Dataset):\n",
    "    def __init__(self, filepath, negfilepath=None):\n",
    "        def construct_dataset(filepath, negfilepath=None):\n",
    "            with open(filepath, 'r') as f:\n",
    "                aptamer_data = json.load(f)\n",
    "            bio_ds = []\n",
    "            neg_ds = []\n",
    "            gen_ds = []\n",
    "            for aptamer in aptamer_data:\n",
    "                peptides = aptamer_data[aptamer]\n",
    "                for peptide in peptides:\n",
    "                    bio_ds.append((aptamer, peptide, 1))\n",
    "                    gen_ds.append((get_x(), get_y('NNK'), 0))\n",
    "            with open(negfilepath, 'r') as f:\n",
    "                neg_data = json.load(f)\n",
    "            for aptamer in neg_data:\n",
    "                peptides = neg_data[aptamer]\n",
    "                for peptide in peptides:\n",
    "                    neg_ds.append((aptamer, peptide, 0))\n",
    "            bio_ds = list(set(bio_ds)) #removed duplicates, random order\n",
    "            gen_ds = list(set(gen_ds)) #removed duplicates, random order\n",
    "            neg_ds = list(set(neg_ds))\n",
    " \n",
    "            return bio_ds, neg_ds, gen_ds\n",
    "\n",
    "        # Sample x from P_X (assume apatamers follow uniform)\n",
    "        def get_x():\n",
    "            x_idx = np.random.randint(0, 4, 40)\n",
    "            x = \"\"\n",
    "            for i in x_idx:\n",
    "                x += na_list[i]\n",
    "            return x\n",
    "        \n",
    "         # Sample y from P_y (assume peptides follow NNK)\n",
    "        def get_y(distribution='NNK'):\n",
    "            if distribution == 'NNK':\n",
    "                y_idx = np.random.choice(20, 7, p=pvals)\n",
    "                lst = aa_list\n",
    "            elif distribution == 'uniform':\n",
    "                y_idx = np.random.choice(20, 7, p=uniform_pvals)\n",
    "                lst = aa_list\n",
    "            elif distribution == 'new_nnk':\n",
    "                y_idx = np.random.choice(20, 7, p=pvals_2)\n",
    "                lst = aa_list_2\n",
    "            y = \"M\"\n",
    "            for i in y_idx:\n",
    "                y += lst[i]\n",
    "            return y\n",
    "\n",
    "        self.bio_ds, self.neg_ds, self.gen_ds = construct_dataset(filepath, negfilepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.bio_ds), len(self.neg_ds))\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return(self.bio_ds[idx], self.neg_ds[idx], self.gen_ds[idx])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "source": [
    "class GeneratedDataset(Dataset):\n",
    "    def __init__(self, n):\n",
    "        def construct_generated_dataset(k):\n",
    "            S_new = []\n",
    "            for _, i in enumerate(tqdm.tqdm(range(k))):\n",
    "                pair = (get_x(), get_y())\n",
    "                S_new.append(pair)\n",
    "            np.random.shuffle(S_new)\n",
    "            return S_new\n",
    "        \n",
    "        # Sample x from P_X (assume apatamers follow uniform)\n",
    "        def get_x():\n",
    "            x_idx = np.random.randint(0, 4, 40)\n",
    "            x = \"\"\n",
    "            for i in x_idx:\n",
    "                x += na_list[i]\n",
    "            return x\n",
    "\n",
    "        # Sample y from P_y (assume peptides follow NNK)\n",
    "        def get_y():\n",
    "            y_idx = np.random.choice(20, 7, p=pvals)\n",
    "            y = \"M\"\n",
    "            for i in y_idx:\n",
    "                y += aa_list[i]\n",
    "            return y\n",
    "        self.gen_ds = construct_generated_dataset(n)\n",
    "    def __len__(self):\n",
    "        return len(self.gen_ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.gen_ds[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_ds1=BinaryDataset(filepath=\"../data/pos_datasets/experimental_replicate_1.json\", distribution='NNK', negfilepath='../data/neg_datasets/neg1_all_pairs_noArgi_noHis.json')\n",
    "binary_ds2=BinaryDataset(filepath=\"../data/pos_datasets/experimental_replicate_2.json\", distribution='NNK', negfilepath='../data/neg_datasets/neg2_all_pairs_noArgi_noHis.json')\n",
    "n = len(binary_ds1.pos_ds)\n",
    "m = int(0.8*n)\n",
    "train_pos = binary_ds1.pos_ds[:m]\n",
    "val_pos = binary_ds1.pos_ds[m:]\n",
    "n = len(binary_ds1.neg_ds)\n",
    "m = int(0.8*n)\n",
    "train_neg = binary_ds1.neg_ds[:m]\n",
    "val_neg = binary_ds1.neg_ds[m:]\n",
    "n = len(binary_ds1.gen_ds)\n",
    "m = int(0.8*n)\n",
    "train_gen = binary_ds1.gen_ds[:m]\n",
    "val_gen = binary_ds1.gen_ds[m:]\n",
    "\n",
    "n = len(binary_ds2.pos_ds)\n",
    "m = int(0.8*n)\n",
    "train_pos2 = binary_ds2.pos_ds[:m]\n",
    "val_pos2 = binary_ds2.pos_ds[m:]\n",
    "n = len(binary_ds2.neg_ds)\n",
    "m = int(0.8*n)\n",
    "train_neg2 = binary_ds2.neg_ds[:m]\n",
    "val_neg2 = binary_ds2.neg_ds[m:]\n",
    "n = len(binary_ds2.gen_ds)\n",
    "m = int(0.8*n)\n",
    "train_gen2 = binary_ds2.gen_ds[:m]\n",
    "val_gen2 = binary_ds2.gen_ds[m:]\n",
    "\n",
    "train_pos += train_pos2\n",
    "train_neg += train_neg2\n",
    "train_gen += train_gen2\n",
    "val_pos += val_pos2\n",
    "val_neg += val_neg2\n",
    "val_gen += val_gen2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_ds_1 = AUCDataset(filepath='../data/pos_datasets/experimental_replicate_3.json', negfilepath='../data/neg_datasets/neg3_all_pairs_noArgi_noHis.json')\n",
    "auc_ds_2 = AUCDataset(filepath='../data/pos_datasets/experimental_replicate_4.json', negfilepath='../data/neg_datasets/neg4_all_pairs_noArgi_noHis.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Expects peptides to be encoding according to BLOSUM62 matrix\n",
    "# Expects aptamers to be one hot encoded\n",
    "class BlosumNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BlosumNet, self).__init__()\n",
    "        self.name = \"BlosumNet\"\n",
    "        self.single_alphabet = False\n",
    "        \n",
    "        self.cnn_apt_1 = nn.Conv1d(4, 25, 3, padding=2) \n",
    "        self.cnn_apt_2 = nn.Conv1d(25, 50, 3, padding=2) \n",
    "        self.cnn_apt_3 = nn.Conv1d(50, 25, 3, padding=2) \n",
    "        self.cnn_apt_4 = nn.Conv1d(25, 10, 3) \n",
    "        \n",
    "        # There are 20 channels\n",
    "        self.cnn_pep_1 = nn.Conv1d(20, 40, 3, padding=2)\n",
    "        self.cnn_pep_2 = nn.Conv1d(40, 80, 3, padding=2)\n",
    "        self.cnn_pep_3 = nn.Conv1d(80, 150, 3, padding=2)\n",
    "        self.cnn_pep_4 = nn.Conv1d(150, 50, 3, padding=2)\n",
    "        self.cnn_pep_5 = nn.Conv1d(50, 10, 3, padding=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu, \n",
    "                                     self.cnn_apt_2, self.maxpool, self.relu)\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu,\n",
    "                                     self.cnn_pep_2, self.maxpool, self.relu)\n",
    "        \n",
    "        self.fc1 = nn.Linear(790, 500)\n",
    "        self.fc2 = nn.Linear(500, 200)\n",
    "        self.fc3 = nn.Linear(200, 1)\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Expects peptides to be encoding according to BLOSUM62 matrix\n",
    "# Expects aptamers to be one hot encoded\n",
    "class BlosumConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BlosumConvNet, self).__init__()\n",
    "        self.name = \"BlosumConvNet\"\n",
    "        self.single_alphabet = False\n",
    "        \n",
    "        self.cnn_apt_1 = nn.Conv1d(4, 25, 3, padding=2) \n",
    "        self.cnn_apt_2 = nn.Conv1d(25, 100, 3, padding=2) \n",
    "        self.cnn_apt_3 = nn.Conv1d(100, 200, 3, padding=2) \n",
    "        self.cnn_apt_4 = nn.Conv1d(200, 300, 3) \n",
    "        \n",
    "        # There are 20 channels\n",
    "        self.cnn_pep_1 = nn.Conv1d(20, 40, 3, padding=2)\n",
    "        self.cnn_pep_2 = nn.Conv1d(40, 100, 3, padding=2)\n",
    "        self.cnn_pep_3 = nn.Conv1d(100, 200, 3, padding=2)\n",
    "        self.cnn_pep_4 = nn.Conv1d(200, 300, 3, padding=2)\n",
    "        self.cnn_pep_5 = nn.Conv1d(300, 350, 3, padding=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu, \n",
    "                                     self.cnn_apt_2, self.maxpool, self.relu)\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu,\n",
    "                                     self.cnn_pep_2, self.maxpool, self.relu)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1400, 700 )\n",
    "        self.fc2 = nn.Linear(700, 250)\n",
    "        self.fc3 = nn.Linear(250, 1)\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Expects peptides to be encoding according to BLOSUM62 matrix\n",
    "# Expects aptamers to be one hot encoded\n",
    "class BlosumLinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BlosumLinearNet, self).__init__()\n",
    "        self.name = \"BlosumLinearNet\"\n",
    "        self.single_alphabet = False\n",
    "        \n",
    "        self.fc_apt_1 = nn.Linear(160, 200) \n",
    "        self.fc_apt_2 = nn.Linear(200, 250)\n",
    "        self.fc_apt_3 = nn.Linear(250, 300)\n",
    "        \n",
    "        self.fc_pep_1 = nn.Linear(160, 200)\n",
    "        self.fc_pep_2 = nn.Linear(200, 250)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc_apt = nn.Sequential(self.fc_apt_1, self.fc_apt_2, self.fc_apt_3)\n",
    "        self.fc_pep = nn.Sequential(self.fc_pep_1, self.fc_pep_2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(550, 600)\n",
    "        self.fc2 = nn.Linear(600, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        apt = self.fc_apt(apt)\n",
    "        pep = self.fc_pep(pep)\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc2(self.fc1(x))\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class LinearBaseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearBaseline, self).__init__()\n",
    "        self.name = \"LinearBaseline\"\n",
    "        self.single_alphabet = False\n",
    "        \n",
    "        self.fc_1 = nn.Linear(320, 1)\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc_1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ConvBaseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBaseline, self).__init__()\n",
    "        self.name = \"ConvBaseline\"\n",
    "        self.single_alphabet = True\n",
    "        \n",
    "        self.cnn_1 = nn.Conv1d(24, 1000, 3)\n",
    "        self.fc_1 = nn.Linear(4500, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(7) \n",
    "        \n",
    "    \n",
    "    def forward(self, pair):\n",
    "        x = self.cnn_1(pair)\n",
    "        x = self.relu(self.maxpool(x))\n",
    "        x = x.view(-1, 1).T\n",
    "        x = self.fc_1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class LinearTwoHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearTwoHead, self).__init__()\n",
    "        self.name = \"LinearTwoHead\"\n",
    "        self.single_alphabet=False\n",
    "        \n",
    "        self.fc_apt_1 = nn.Linear(160, 200) \n",
    "        self.fc_apt_2 = nn.Linear(200, 150)\n",
    "        self.fc_apt_3 = nn.Linear(150, 100)\n",
    "        \n",
    "        self.fc_pep_1 = nn.Linear(160, 250)\n",
    "        self.fc_pep_2 = nn.Linear(250, 100)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "\n",
    "        \n",
    "        \n",
    "        self.fc_apt = nn.Sequential(self.fc_apt_1, self.relu, self.fc_apt_2, self.relu,  self.fc_apt_3)\n",
    "        self.fc_pep = nn.Sequential(self.fc_pep_1, self.relu,  self.fc_pep_2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(200, 100)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        apt = self.fc_apt(apt)\n",
    "        pep = self.fc_pep(pep)\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc2(self.fc1(x))\n",
    "        x = torch.sigmoid(x)\n",
    "        return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ConvTwoHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvTwoHead, self).__init__()\n",
    "        self.name = \"ConvTwoHead\"\n",
    "        self.single_alphabet=False\n",
    "        \n",
    "        self.cnn_apt_1 = nn.Conv1d(4, 100, 3, padding=2) \n",
    "        self.cnn_apt_2 = nn.Conv1d(50, 150, 3, padding=2) \n",
    "\n",
    "        \n",
    "        # There are 20 channels\n",
    "        self.cnn_pep_1 = nn.Conv1d(20, 100, 3, padding=2)\n",
    "        self.cnn_pep_2 = nn.Conv1d(75, 150, 3, padding=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(2) \n",
    "        \n",
    "        self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu, \n",
    "                                     )\n",
    "        self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu,\n",
    "                                     )\n",
    "        \n",
    "        self.fc1 = nn.Linear(2600, 1300)\n",
    "        self.fc2 = nn.Linear(1300, 1)\n",
    "    \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt(apt)\n",
    "        pep = self.cnn_pep(pep)\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# class TwoHeadedConv(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TwoHeadedConv, self).__init__()\n",
    "#         self.name = \"TwoHeadedConv\"\n",
    "#         self.single_alphabet=False\n",
    "        \n",
    "#         self.cnn_apt_1 = nn.Conv1d(4, 1000, 3, padding=2)\n",
    "#         self.cnn_apt_2 = nn.Conv1d(1000, 500, 3, padding=2)\n",
    "\n",
    "        \n",
    "#         # There are 20 channels\n",
    "#         self.cnn_pep_1 = nn.Conv1d(20, 1000, 3, padding=2)\n",
    "#         self.cnn_pep_2 = nn.Conv1d(1000, 500, 3, padding=2)\n",
    "        \n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.maxpool = nn.MaxPool1d(3) \n",
    "        \n",
    "#         self.cnn_apt = nn.Sequential(self.cnn_apt_1, self.maxpool, self.relu, \n",
    "#                                      self.cnn_apt_2, self.maxpool, self.relu,\n",
    "#                                      )\n",
    "#         self.cnn_pep = nn.Sequential(self.cnn_pep_1, self.maxpool, self.relu,\n",
    "#                                      self.cnn_pep_2, self.maxpool, self.relu,\n",
    "#                                      )\n",
    "        \n",
    "#         self.fc1 = nn.Linear(3000, 1500)\n",
    "#         self.fc2 = nn.Linear(1500, 1)\n",
    "    \n",
    "#     def forward(self, apt, pep):\n",
    "#         apt = self.cnn_apt(apt)\n",
    "#         pep = self.cnn_pep(pep)\n",
    "        \n",
    "#         apt = apt.view(-1, 1).T\n",
    "#         pep = pep.view(-1, 1).T\n",
    "#         x = torch.cat((apt, pep), 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = torch.sigmoid(x)\n",
    "#         return x\n",
    "    \n",
    "    \n",
    "class TwoHeadedConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoHeadedConv, self).__init__()\n",
    "        self.name = \"TwoHeadedConv\"\n",
    "        self.single_alphabet=False\n",
    "        self.cnn_apt_1 = nn.Conv1d(4, 1000, 3) \n",
    "        self.cnn_apt_2 = nn.Conv1d(1000, 2500, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv1d(20, 1000, 3)\n",
    "        self.cnn_pep_2 = nn.Conv1d(1000, 2500, 1)\n",
    "       \n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(5)         \n",
    "        self.fc1 = nn.Linear(5000, 2500)\n",
    "        self.fc2 = nn.Linear(2500, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "\n",
    "        \n",
    "        apt = self.pool1(self.relu(self.cnn_apt_1(apt)))\n",
    "        apt = self.pool1(self.relu(self.cnn_apt_2(apt)))\n",
    "\n",
    "        pep = self.relu(self.cnn_pep_1(pep))\n",
    "        pep = self.pool1(self.relu(self.cnn_pep_2(pep)))\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc2(self.fc1(x))\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='sigmoid')\n",
    "        nn.init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     1,
     36,
     66,
     105,
     154,
     169,
     179,
     189,
     204,
     224,
     244
    ]
   },
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def one_hot(sequence, seq_type='peptide', single_alphabet=False):\n",
    "    if single_alphabet:\n",
    "        apt = sequence[0]\n",
    "        pep = sequence[1]\n",
    "        one_hot = np.zeros((len(apt) + len(pep), 24))\n",
    "        # Encode the aptamer first\n",
    "        for i in range(len(apt)):\n",
    "            char = apt[i]\n",
    "            for _ in range(len(na_list)):\n",
    "                idx = na_list.index(char)\n",
    "                one_hot[i][idx] = 1\n",
    "            \n",
    "        # Encode the peptide second\n",
    "        for i in range(len(pep)):\n",
    "            char = pep[i]\n",
    "            for _ in range(len(aa_list)):\n",
    "                idx = aa_list.index(char) + len(na_list)\n",
    "                one_hot[i+len(apt)][idx] = 1\n",
    "        \n",
    "        return one_hot       \n",
    "    else:\n",
    "        if seq_type == 'peptide':\n",
    "            letters = aa_list\n",
    "        else:\n",
    "            letters = na_list\n",
    "        one_hot = np.zeros((len(sequence), len(letters)))\n",
    "        for i in range(len(sequence)):\n",
    "            char = sequence[i]\n",
    "            for _ in range(len(letters)):\n",
    "                idx = letters.index(char)\n",
    "                one_hot[i][idx] = 1\n",
    "        return one_hot\n",
    "    \n",
    "## For aptamer sequence, translate\n",
    "## For peptide sequence, translate and add additional biological properties\n",
    "def extract_features(sequence, seq_type='peptide', single_alphabet=False):\n",
    "    if single_alphabet:\n",
    "        pass\n",
    "    else:\n",
    "        if seq_type == 'peptide':\n",
    "            letters = aa_list\n",
    "            encoding = np.zeros((4, len(sequence)))\n",
    "            for i in range(len(sequence)):\n",
    "                char = sequence[i]\n",
    "                \n",
    "                idx = letters.index(char)\n",
    "                char_hydro = hydrophobicity[char]\n",
    "                char_polar = polarity[char]\n",
    "                char_vol = volume[char]\n",
    "                char_charge = charge[char]\n",
    "                \n",
    "                # Put in the biological features of the amino acids\n",
    "                encoding[0][i] = char_polar\n",
    "                encoding[1][i] = char_vol\n",
    "                encoding[2][i] = char_charge\n",
    "                encoding[3][i] = char_hydro\n",
    "        else:\n",
    "            letters = na_list\n",
    "            encoding = np.zeros(len(sequence))\n",
    "            for i in range(len(sequence)):\n",
    "                char = sequence[i]\n",
    "                idx = letters.index(char)\n",
    "                encoding[i] = idx\n",
    "        return encoding \n",
    "\n",
    "def blosum62_encoding(sequence, seq_type='peptide', single_alphabet=False, style=encoding_style):\n",
    "    if single_alphabet:\n",
    "        apt = sequence[0]\n",
    "        pep = sequence[1]\n",
    "        encoding = np.zeros((len(apt) + len(pep), 24))\n",
    "        # Encode the aptamer first\n",
    "        for i in range(len(apt)):\n",
    "            char = apt[i]\n",
    "            for _ in range(len(na_list)):\n",
    "                idx = na_list.index(char)\n",
    "                encoding[i][idx] = 1\n",
    "            \n",
    "        # Encode the peptide second\n",
    "        for i in range(len(pep)):\n",
    "            char = pep[i]\n",
    "            for j in range(len(original_blosum62[char])):\n",
    "                encoding[i+len(apt)][j+4] = original_blosum62[char][j]\n",
    "        \n",
    "        return encoding      \n",
    "    else:\n",
    "        if seq_type == 'peptide':\n",
    "            encoding = []\n",
    "            for i in range(len(sequence)):\n",
    "                if style == \"clipped\":\n",
    "                    encoding.append(clip_blosum62[sequence[i]])\n",
    "                else:\n",
    "                    encoding.append(original_blosum62[sequence[i]])\n",
    "            encoding = np.asarray(encoding)\n",
    "        else:\n",
    "            #Translation\n",
    "            letters = na_list\n",
    "            encoding = np.zeros(len(sequence))\n",
    "            for i in range(len(sequence)):\n",
    "                char = sequence[i]\n",
    "                idx = letters.index(char)\n",
    "                encoding[i] = idx\n",
    "        return encoding \n",
    "\n",
    "## Takes a peptide and aptamer sequence and converts to directly translated sequence\n",
    "def translate(sequence, seq_type='peptide', single_alphabet=False):\n",
    "    if single_alphabet:\n",
    "        apt = sequence[0]\n",
    "        pep = sequence[1]\n",
    "        \n",
    "        encoding = np.zeros(len(apt) + len(pep))\n",
    "        \n",
    "        # Encode the aptamer first\n",
    "        for i in range(len(apt)):\n",
    "            char = apt[i]\n",
    "            idx = na_list.index(char)\n",
    "            encoding[i] = idx\n",
    "            \n",
    "        # Encode the peptide second\n",
    "        for i in range(len(pep)):\n",
    "            char = pep[i]\n",
    "            idx = aa_list.index(char)\n",
    "            encoding[i+len(apt)] = idx\n",
    "        return encoding     \n",
    "    else:\n",
    "        if seq_type == 'peptide':\n",
    "            letters = aa_list\n",
    "        else:\n",
    "            letters = na_list\n",
    "        \n",
    "        encoding = np.zeros(len(sequence))\n",
    "        for i in range(len(sequence)):\n",
    "            char = sequence[i]\n",
    "            idx = letters.index(char)\n",
    "            encoding[i] = idx\n",
    "        return encoding\n",
    "\n",
    "# Convert a pair to one-hot tensor\n",
    "def convert(apt, pep, label, single_alphabet=False): \n",
    "    if single_alphabet:\n",
    "        pair = one_hot([apt, pep], single_alphabet=True) #(2, 40)\n",
    "        pair = torch.FloatTensor(np.reshape(pair, (-1, pair.shape[1], pair.shape[0]))).to(device)\n",
    "        label = torch.FloatTensor([[label]]).to(device)\n",
    "        return pair, label\n",
    "    else:\n",
    "        apt = one_hot(apt, seq_type='aptamer') \n",
    "        pep = one_hot(pep, seq_type='peptide') \n",
    "        apt = torch.FloatTensor(np.reshape(apt, (-1, apt.shape[1], apt.shape[0]))).to(device) #(1, 1, 40)\n",
    "        pep = torch.FloatTensor(np.reshape(pep, (-1, pep.shape[1], pep.shape[0]))).to(device) #(1, 1, 8)\n",
    "        \n",
    "        label = torch.FloatTensor([[label]]).to(device)\n",
    "        return apt, pep, label\n",
    "\n",
    "# Getting the output of the model for a pair (aptamer, peptide)\n",
    "def update(x, y, p, single_alphabet=False):\n",
    "    if single_alphabet:\n",
    "        p.requires_grad=True\n",
    "        p = p.to(device)\n",
    "        out = model(p)\n",
    "        return out\n",
    "    else:\n",
    "        x.requires_grad=True\n",
    "        y.requires_grad=True\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = model(x, y)\n",
    "        return out\n",
    "\n",
    "## Plotting functions\n",
    "def plot_loss(iters, train_losses, val_losses, model_name, model_id):\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.plot(train_losses, label=\"Train\")\n",
    "    plt.plot(val_losses, label=\"Validation\")\n",
    "    plt.xlabel(\"%d Iterations\" %iters)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('plots/binary/%s/%s/loss.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(iters, train_acc, val_acc, model_name, model_id):\n",
    "    plt.title(\"Training Accuracy Curve\")\n",
    "    plt.plot(train_acc, label=\"Train\")\n",
    "    plt.plot(val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"%d Iterations\" %iters)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('plots/binary/%s/%s/accuracy.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram(train_gen_scores, train_scores, val_gen_scores, val_scores, model_name, model_id):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xlim(0, 1.1)\n",
    "    \n",
    "    sns.distplot(train_gen_scores , color=\"skyblue\", label='Generated Train Samples', ax=ax)\n",
    "    sns.distplot(val_gen_scores, color='dodgerblue', label='Generated Validation Samples')\n",
    "    sns.distplot(train_scores , color=\"lightcoral\", label='Dataset Train Samples', ax=ax)\n",
    "    sns.distplot(val_scores, color='red', label='Dataset Validation Samples', ax=ax)\n",
    "    \n",
    "    ax.set_title(\"Categorizing the output scores of the model\")\n",
    "    ax.figure.set_size_inches(7, 4)\n",
    "    ax.legend()\n",
    "    plt.savefig('plots/binary/%s/%s/histogram.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_ecdf_test(test_score, iters, epoch, gamma, model_name, model_id):\n",
    "    test_idx = np.argsort(test_score)\n",
    "    test_id = test_idx >= 10000\n",
    "    test = np.sort(test_score)\n",
    "    test_c = \"\"\n",
    "    for m in test_id:\n",
    "        if m:\n",
    "            test_c += \"y\"\n",
    "        else:\n",
    "            test_c += \"g\"\n",
    "    n = test_score.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    plt.scatter(y, test, c=test_c, label='Test CDF')\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.xlabel(\"Most recent 10,000 samples after training %d samples\" %iters)\n",
    "    plt.title('Test CDF at epoch %d' %epoch + \", Gamma:%.5f\" %gamma)\n",
    "    plt.legend()\n",
    "    plt.savefig('plots/binary/%s/%s/test_cdf.png' %(model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_ecdf_train(train_score, iters, epoch, gamma, model_name, model_id):\n",
    "    train_idx = np.argsort(train_score)\n",
    "    train_id = train_idx >= 10000\n",
    "    train = np.sort(train_score)\n",
    "    train_c = \"\" #colors\n",
    "    for l in train_id:\n",
    "        if l:\n",
    "            train_c += \"r\"\n",
    "        else:\n",
    "            train_c += \"b\"\n",
    "    n = train_score.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    plt.scatter(y, train, c=train_c, label='Train CDF')\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.xlabel(\"Most recent 10,000 samples after training %d samples\" % iters)\n",
    "    plt.title('Train CDF at epoch %d' %epoch+ \", Gamma:%.5f\" %gamma)\n",
    "    plt.legend()\n",
    "    plt.savefig('plots/binary/%s/%s/train_cdf.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def auc_cdf(train, new, model_name, model_id, val=False): \n",
    "    #train is the sorted list of outputs from the model with training pairs as inputs\n",
    "    #new is the list of outputs from the model with generated pairs as inputs\n",
    "    a = train + new\n",
    "    n = len(a)\n",
    "    m = len(train)\n",
    "    train = np.asarray(train)\n",
    "    new = np.asarray(new)\n",
    "    y = np.arange(0, m+2)/m\n",
    "    gamma = [0]\n",
    "    for x in train:\n",
    "        gamma.append(sum(a<=x)/n)\n",
    "    gamma.append(1)\n",
    "    plt.plot(gamma, y)\n",
    "    if val:\n",
    "        plt.title(\"Validation CDF\")\n",
    "    else:\n",
    "        plt.title(\"Train CDF\")\n",
    "    plt.xlim([0,1])\n",
    "    if val:\n",
    "        plt.savefig('plots/binary/%s/%s/val_cdf.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig('plots/binary/%s/%s/train_cdf.png' % (model_name, model_id), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return np.trapz(y, gamma)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test the regular translate method\n",
    "oh = blosum62_encoding('LL', seq_type='peptide')\n",
    "oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the translate method with single alphabet\n",
    "pair, label = convert(\"GGGG\", \"LL\", label=1.0, single_alphabet=True)\n",
    "pair.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if device == torch.cuda:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     16,
     24
    ]
   },
   "outputs": [],
   "source": [
    "def classifier(model, \n",
    "               pos, \n",
    "               neg,\n",
    "               gen,\n",
    "               val_pos,\n",
    "               val_neg,\n",
    "               val_gen,\n",
    "               lr,\n",
    "               model_id,\n",
    "               num_epochs=50,\n",
    "               batch_size=16,\n",
    "               single_alphabet=False,\n",
    "               run_from_checkpoint=None, \n",
    "               save_checkpoints=None,\n",
    "               cdf=False):\n",
    "    \n",
    "    if run_from_checkpoint is not None:\n",
    "        checkpointed_model = run_from_checkpoint\n",
    "        checkpoint = torch.load(checkpointed_model)\n",
    "        optimizer = SGD(model.parameters(), lr=lr)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        init_epoch = checkpoint['epoch'] +1\n",
    "        print(\"Reloading model: \", model.name, \" at epoch: \", init_epoch)\n",
    "    else:\n",
    "        model.apply(weights_init)\n",
    "        optimizer = SGD(model.parameters(), lr=lr)\n",
    "        init_epoch = 0\n",
    "    \n",
    "    train_losses, val_losses, train_losses_avg, val_losses_avg, train_acc, val_acc = [], [], [], [], [], []\n",
    "    \n",
    "    iters, train_correct, val_correct = 0, 0, 0\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.9) #Decays lr by gamma factor every step_size epochs. \n",
    "    \n",
    "    # Keep track of the scores across four classes\n",
    "    train_scores, train_gen_scores, val_scores, val_gen_scores = [], [], [], []\n",
    "    \n",
    "    # TP, TN, FP, FN\n",
    "    train_stats = [0, 0, 0, 0]\n",
    "    val_stats = [0, 0, 0, 0]\n",
    "    \n",
    "    # Number of times that val_score < train_score\n",
    "    auc_tracker = 0\n",
    "    auc_count = 0\n",
    "    \n",
    "    alpha = 10\n",
    "    beta = 0.1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        full_epoch = epoch + init_epoch\n",
    "        print(\"Starting epoch: %d\" % full_epoch, \" with learning rate: \", scheduler.get_lr())\n",
    "        for i in tqdm.tqdm(range(100000)):\n",
    "            num = random.uniform(0, 1)\n",
    "            if num < 0.33:\n",
    "                lam = 1\n",
    "                apt,pep,label = random.choice(pos)\n",
    "            elif num >= 0.33 and num < 0.67:\n",
    "                lam = alpha\n",
    "                apt,pep,label = random.choice(neg)\n",
    "            elif num >= 0.67 and num <= 1:\n",
    "                lam = beta\n",
    "                apt,pep,label = random.choice(gen)\n",
    "            \n",
    "            # Pick \n",
    "            model_name = model.name\n",
    "            model.train()\n",
    "            if single_alphabet:\n",
    "                p, l = convert(apt, pep, label, single_alphabet=True)\n",
    "                train_score = update(None, None, p, single_alphabet=True)\n",
    "            else:\n",
    "                a, p, l = convert(apt, pep, label, single_alphabet=False)\n",
    "                train_score = update(a, p, None, single_alphabet=False)\n",
    "\n",
    "                \n",
    "            iters += 1\n",
    "            train_loss = criterion(train_score, l)\n",
    "            total_train_loss += lam * train_loss\n",
    "\n",
    "            \n",
    "            if iters % batch_size == 0:\n",
    "                ave_train_loss = total_train_loss/batch_size\n",
    "                train_losses.append(ave_train_loss.item())\n",
    "                optimizer.zero_grad()\n",
    "                ave_train_loss.backward()\n",
    "                optimizer.step()\n",
    "                total_train_loss = 0\n",
    "\n",
    "            if iters % 5000 == 0:\n",
    "                train_acc.append(100*train_correct/iters)\n",
    "                train_losses_avg.append(np.average(train_losses[-5000:]))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "            num = random.uniform(0, 1)\n",
    "            if num < 0.33:\n",
    "                lam = 1\n",
    "                apt,pep,label = random.choice(val_pos)\n",
    "            elif num >= 0.33 and num < 0.67:\n",
    "                lam = alpha\n",
    "                apt,pep,label = random.choice(val_neg)\n",
    "            elif num >= 0.67 and num <= 1:\n",
    "                lam = beta\n",
    "                apt,pep,label = random.choice(val_gen)\n",
    "                \n",
    "                \n",
    "            if single_alphabet:\n",
    "                p_val, l_val = convert(apt, pep, label, single_alphabet=True)\n",
    "                val_score = model(p_val)\n",
    "            else:\n",
    "                a_val, p_val, l_val = convert(apt,pep,label)\n",
    "                val_score = model(a_val, p_val)\n",
    "            \n",
    "            val_loss = criterion(val_score, l_val) \n",
    "            total_val_loss += lam * val_loss\n",
    "            \n",
    "            \n",
    "            # Calculate AUC\n",
    "            auc_count += 1\n",
    "            idx = int(random.random()*len(val_pos))\n",
    "            bio_sample = val_pos[idx]\n",
    "            idx = int(random.random()*len(val_neg))\n",
    "            gen_sample = val_neg[idx]\n",
    "            if single_alphabet:\n",
    "                p, l = convert(bio_sample[0], bio_sample[1], bio_sample[2], single_alphabet=True)\n",
    "                bio_score = model(p)\n",
    "                p, l = convert(gen_sample[0], gen_sample[1], gen_sample[2], single_alphabet=True)\n",
    "                gen_score = model(p)\n",
    "            else:\n",
    "                a, p, l = convert(bio_sample[0], bio_sample[1], bio_sample[2])\n",
    "                bio_score = model(a, p)\n",
    "                a, p, l = convert(gen_sample[0], gen_sample[1], gen_sample[2])\n",
    "                gen_score = model(a, p)\n",
    "            if bio_score > gen_score:\n",
    "                auc_tracker += 1\n",
    "\n",
    "            if iters % batch_size == 0:\n",
    "                ave_val_loss = total_val_loss/batch_size\n",
    "                val_losses.append(ave_val_loss.item())\n",
    "                total_val_loss = 0\n",
    "            if iters % 5000 == 0:\n",
    "                val_acc.append(100*val_correct/iters)\n",
    "                val_losses_avg.append(np.average(val_losses[-5000:]))\n",
    "                \n",
    "            if iters % 50000 == 0:\n",
    "                plot_loss(iters, train_losses_avg, val_losses_avg, model_name, model_id)\n",
    "                plot_accuracy(iters, train_acc, val_acc, model_name, model_id)\n",
    "                plot_histogram(train_gen_scores, train_scores, val_gen_scores, val_scores, model_name, model_id)\n",
    "                #val_auc = auc_cdf(sorted(val_scores[-1000:]), sorted(val_gen_scores[-10000:]), model_name, model_id, val=True)\n",
    "                #train_auc = auc_cdf(sorted(train_scores[-1000:]), sorted(train_gen_scores[-10000:]), model_name, model_id)\n",
    "                \n",
    "                print(\"Training Accuracy at epoch %d: {}\".format(train_acc[-1]) %full_epoch)\n",
    "                print(\"Validation Accuracy epoch %d: {}\".format(val_acc[-1]) %full_epoch)\n",
    "                #print(\"Training CDF at epoch %d: {}\".format(train_auc) % full_epoch)\n",
    "                #print(\"Validation CDF epoch %d: {}\".format(val_auc) % full_epoch)\n",
    "                print(\"AUC epoch %d: {}\".format(auc_tracker/float(auc_count)) % full_epoch)\n",
    "                #print(\"Train: Sensitivity: \" + str(train_stats[0]/(train_stats[0] + train_stats[3])) + \" Specificity: \" + str(train_stats[1]/(train_stats[2] + train_stats[1])))\n",
    "                #print(\"Val: Sensitivity: \" + str(val_stats[0]/(val_stats[0] + val_stats[3])) + \" Specificity: \" + str(val_stats[1]/(val_stats[2] + val_stats[1])))\n",
    "                # TP, TN, FP, FN\n",
    "#                 print(\"Train Precision: \", train_stats[0]/(train_stats[0] + train_stats[2]))\n",
    "#                 print(\"Train Recall: \", train_stats[0]/(train_stats[0] + train_stats[3]))\n",
    "\n",
    "        scheduler.step()\n",
    "        if save_checkpoints is not None:\n",
    "            print(\"Saving to: \", save_checkpoints)\n",
    "            checkpoint_name = save_checkpoints\n",
    "            torch.save({'epoch': full_epoch,\n",
    "                        'model_state_dict': model.state_dict(), \n",
    "                        'optimizer_state_dict': optimizer.state_dict()}, checkpoint_name)\n",
    "        \n",
    "        # Clear unused gpu memory at the end of the epoch\n",
    "        if device == torch.cuda:\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using encoding_style= regular\n",
      "Starting epoch: 0  with learning rate:  [0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 49996/100000 [23:44<29:10, 28.57it/s]  "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuhaowan/anaconda3/lib/python3.7/site-packages/numpy/lib/histograms.py:898: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return n/db/n.sum(), bin_edges\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 50006/100000 [23:45<56:08, 14.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy at epoch 0: 0.0\n",
      "Validation Accuracy epoch 0: 0.0\n",
      "AUC epoch 0: 0.51268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 98101/100000 [46:37<00:58, 32.66it/s]"
     ]
    }
   ],
   "source": [
    "model = TwoHeadedConv()\n",
    "model_name = model.name\n",
    "model_id = \"09302020_2\"\n",
    "model.to(device)\n",
    "checkpoint = None\n",
    "save_path = 'model_checkpoints/binary/%s/%s.pth' % (model_name, model_id)\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "cdf=False\n",
    "if cdf:\n",
    "   # For the CDF functions, we need to generate a dataset of new examples\n",
    "    S_new = GeneratedDataset(10*m) \n",
    "gamma = 1e-2\n",
    "#print(\"Using lambda val=\", lambda_val)\n",
    "print(\"Using encoding_style=\", encoding_style)\n",
    "classifier(model, train_pos, train_neg, train_gen, val_pos, val_neg, val_gen, gamma, model_id, NUM_EPOCHS, BATCH_SIZE, model.single_alphabet, checkpoint, save_path, cdf=cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "model = BlosumConvNet()\n",
    "model_name = model.name\n",
    "model.to(device)\n",
    "checkpointed_model = 'model_checkpoints/binary/%s/%s.pth' % (model_name, \"09152020\")\n",
    "checkpoint = torch.load(checkpointed_model)\n",
    "optimizer = SGD(model.parameters(), lr=1e-3)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "init_epoch = checkpoint['epoch'] +1\n",
    "print(\"Reloading model: \", model.name, \" at epoch: \", init_epoch)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calculate AUC\n",
    "val_ds = [auc_ds_1, auc_ds_2, auc_ds_3]\n",
    "for ds in val_ds:\n",
    "    auc_tracker = 0\n",
    "    for i in range(10000):\n",
    "        idx = int(random.random()*len(ds))\n",
    "        bio_sample, gen_sample = ds[idx]\n",
    "        if model.single_alphabet:\n",
    "            p, l = convert(bio_sample[0], bio_sample[1], bio_sample[2], single_alphabet=True)\n",
    "            bio_score = model(p)\n",
    "            p, l = convert(gen_sample[0], gen_sample[1], gen_sample[2], single_alphabet=True)\n",
    "            gen_score = model(p)\n",
    "        else:\n",
    "            a, p, l = convert(bio_sample[0], bio_sample[1], bio_sample[2])\n",
    "            bio_score = model(a, p)\n",
    "            a, p, l = convert(gen_sample[0], gen_sample[1], gen_sample[2])\n",
    "            gen_score = model(a, p)\n",
    "        if bio_score > 0.5:\n",
    "            auc_tracker += 1\n",
    "        if gen_score < 0.5:\n",
    "            auc_tracker += 1\n",
    "\n",
    "    print(\"Test Accuracy: \", auc_tracker/20000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the decision threshold\n",
    "def evaluate(model_name, model_id, dataset=\"ds2\", use_gen=False):\n",
    "    if model_name == \"ConvBaseline\":\n",
    "        model = ConvBaseline()\n",
    "    elif model_name == \"LinearBaseline\":\n",
    "        model = LinearBaseline()\n",
    "    elif model_name == \"LinearTwoHead\":\n",
    "        model = LinearTwoHead()\n",
    "    model.to(device)\n",
    "    checkpointed_model = 'model_checkpoints/binary/%s/%s.pth' % (model.name, model_id)\n",
    "    checkpoint = torch.load(checkpointed_model)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    if dataset==\"3\":\n",
    "        ds = auc_ds_1\n",
    "    elif dataset=='4':\n",
    "        ds = auc_ds_2\n",
    "    thresholds = [i for i in range(1, 100)]\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    for i, t in enumerate(tqdm.tqdm(thresholds)):\n",
    "        t = t*0.01\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\n",
    "        for i in range(100):\n",
    "            idx = int(random.random()*len(ds))\n",
    "            bio_sample, neg_sample, gen_sample = ds[idx]\n",
    "            if model.single_alphabet:\n",
    "                p, l = convert(bio_sample[0], bio_sample[1], bio_sample[2], single_alphabet=True)\n",
    "                bio_score = model(p)\n",
    "                if use_gen:\n",
    "                    p, l = convert(gen_sample[0], gen_sample[1], gen_sample[2], single_alphabet=True)\n",
    "                else:\n",
    "                    p, l = convert(neg_sample[0], neg_sample[1], gen_sample[2], single_alphabet=True)\n",
    "                gen_score = model(p) \n",
    "            else:\n",
    "                a, p, l = convert(bio_sample[0], bio_sample[1], bio_sample[2])\n",
    "                bio_score = model(a, p)\n",
    "                if use_gen:\n",
    "                    a, p, l = convert(gen_sample[0], gen_sample[1], gen_sample[2])\n",
    "                else:\n",
    "                    a, p, l = convert(neg_sample[0], neg_sample[1], gen_sample[2])\n",
    "                gen_score = model(a, p)\n",
    "            if bio_score >= t:\n",
    "                tp += 1\n",
    "            elif bio_score < t:\n",
    "                fn += 1    \n",
    "            if gen_score < t:\n",
    "                tn += 1\n",
    "            elif gen_score >= t:\n",
    "                fp += 1\n",
    "\n",
    "\n",
    "        try:\n",
    "            precision = tp/float(tp + fp)\n",
    "        except:\n",
    "            precision = tp/1\n",
    "        try:\n",
    "            recall = tp/float(tp + fn)\n",
    "        except:\n",
    "            recall = tp/1\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "        # ROC stats\n",
    "        fpr = fp/float(fp+tn)\n",
    "        tpr = tp/float(tp+fn)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "    \n",
    "    roc_curve = zip(fprs, tprs)\n",
    "    pr_curve = zip(recalls, precisions)\n",
    "    \n",
    "    roc_curve = sorted(roc_curve, key=lambda x: x[0])\n",
    "    pr_curve = sorted(pr_curve, key=lambda x: x[0])\n",
    "    \n",
    "    roc_curve = list(zip(*roc_curve))\n",
    "    pr_curve = list(zip(*pr_curve))\n",
    "    return list(roc_curve[0]), list(roc_curve[1]), list(pr_curve[0]), list(pr_curve[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate ROC Curves for each method\n",
    "methods = {'LinearBaseline': ['09272020_2', '09272020'],\n",
    "           'ConvBaseline': ['09282020', '09282020_2'],\n",
    "           'LinearTwoHead': ['09292020', '09292020']}\n",
    "\n",
    "colors = [\"lightcoral\", \"crimson\", \"lightgreen\", \"powderblue\", \"mediumpurple\", \"gold\"]\n",
    "use_gen = True\n",
    "method = 'roc'\n",
    "for ds in [\"3\", \"4\"]:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i, network in enumerate(methods):\n",
    "        blosum_method = methods[network][0]\n",
    "        oh_method = methods[network][1]\n",
    "        \n",
    "        fprs, tprs, recalls, precisions = evaluate(network, blosum_method, ds, use_gen=use_gen)\n",
    "        if method == 'prc':\n",
    "            plt.plot(recalls, precisions, c=colors[2*i], label=str(network) + \" blosum\")\n",
    "        else:\n",
    "            plt.plot(fprs, tprs, c=colors[2*i], label=str(network) + \" blosum \")\n",
    "        \n",
    "        fprs, tprs, recalls, precisions = evaluate(network, oh_method, ds, use_gen=use_gen)\n",
    "        if method == 'prc':\n",
    "            plt.plot(recalls, precisions, c=colors[2*i + 1], label=str(network) + \" oh\")\n",
    "        else:\n",
    "            plt.plot(fprs, tprs, c=colors[2*i + 1], label=str(network) + \" oh \")\n",
    "        \n",
    "        \n",
    "    \n",
    "    plt.legend()\n",
    "    if method == 'prc':\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        if use_gen:\n",
    "            plt.title(\"Precision Recall Curve, Test Dataset: \" + str(ds) + \" using generated data\")\n",
    "        else:\n",
    "            plt.title(\"Precision Recall Curve, Test Dataset: \" + str(ds) + \" using negative data\")\n",
    "    else:\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        \n",
    "        if use_gen:\n",
    "            plt.title(\"ROC Curve, Test Dataset: \" + str(ds) + \" using generated data\")\n",
    "        else:\n",
    "            plt.title(\"ROC Curve, Test Dataset: \" + str(ds) + \" using negative data\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "walnutree",
   "language": "python",
   "name": "walnutree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
