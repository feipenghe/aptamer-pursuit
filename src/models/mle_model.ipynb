{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*13 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "aa_dict = dict(zip(aa_list, pvals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset():\n",
    "    with open(aptamer_dataset_file, 'r') as f:\n",
    "        aptamer_data = json.load(f)\n",
    "    full_dataset = []\n",
    "    for aptamer in aptamer_data:\n",
    "        peptides = aptamer_data[aptamer]\n",
    "        if aptamer == \"CTTTGTAATTGGTTCTGAGTTCCGTTGTGGGAGGAACATG\": #took out aptamer control\n",
    "            continue\n",
    "        for peptide, _ in peptides:\n",
    "            peptide = peptide.replace(\"_\", \"\") #removed stop codons\n",
    "            if \"RRRRRR\" in peptide: #took out peptide control\n",
    "                continue\n",
    "            if len(aptamer) == 40 and len(peptide) == 8: #making sure right length\n",
    "                full_dataset.append((aptamer, peptide))\n",
    "    full_dataset = list(set(full_dataset)) #removed duplicates\n",
    "    return full_dataset\n",
    "\n",
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_set):\n",
    "        super(TrainDataset, self).__init__() \n",
    "        self.training_set = training_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.training_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.training_set[idx]\n",
    "        return aptamer, peptide\n",
    "    \n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, test_set):\n",
    "        super(TestDataset, self).__init__() \n",
    "        self.test_set = test_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.test_set[idx]\n",
    "        return aptamer, peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_dataset_file = \"../data/aptamer_dataset.json\"\n",
    "full_dataset = construct_dataset()\n",
    "n = len(full_dataset)\n",
    "training_set = full_dataset[:int(0.8*n)]\n",
    "test_set = full_dataset[int(0.8*n):]\n",
    "train_dataset = TrainDataset(training_set)\n",
    "test_dataset = TestDataset(test_set)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(1, 5, (3,4)) #similar to 3-gram\n",
    "        self.cnn_pep_1 = nn.Conv2d(1, 5, (3,20))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(220, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.cnn_apt_1(apt)\n",
    "        apt = self.relu(apt)\n",
    "        pep = self.cnn_pep_1(pep)\n",
    "        pep = self.relu(pep)\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample x from P_X (assume apatamers follow uniform)\n",
    "def get_x():\n",
    "    x_idx = np.random.randint(0, 4, 40)\n",
    "    x = \"\"\n",
    "    for i in x_idx:\n",
    "        x += na_list[i]\n",
    "    return x\n",
    "\n",
    "# Sample y from P_y (assume peptides follow NNK)\n",
    "def get_y():\n",
    "    y_idx = np.random.choice(20, 7, p=pvals)\n",
    "    y = \"M\"\n",
    "    for i in y_idx:\n",
    "        y += aa_list[i]\n",
    "    return y\n",
    "\n",
    "# Generate uniformly from S without replacement\n",
    "def get_xy(k):\n",
    "    samples = [full_dataset[i] for i in np.random.choice(len(full_dataset), k, replace=False)]\n",
    "    return samples\n",
    "\n",
    "# S' contains S with double the size of S (domain for Importance Sampling)\n",
    "def get_S_prime(k):\n",
    "    S_prime_dict = dict.fromkeys(full_dataset, 0) #indicator 0 means in the original dataset\n",
    "    S_new = []\n",
    "    for _ in range(k):\n",
    "        pair = (get_x(), get_y())\n",
    "        S_prime_dict[pair] = 1 #indicator 1 means not in the original dataset\n",
    "        S_new.append(pair)\n",
    "    S_prime = [[k,int(v)] for k,v in S_prime_dict.items()]\n",
    "    random.shuffle(S_prime)\n",
    "    return S_prime, S_new\n",
    "\n",
    "# Returns pmf of an aptamer\n",
    "def get_x_pmf():\n",
    "    return 0.25**40\n",
    "\n",
    "# Returns pmf of a peptide\n",
    "def get_y_pmf(y):\n",
    "    pmf = 1\n",
    "    for char in y[1:]: #skips first char \"M\"\n",
    "        pmf *= aa_dict[char]\n",
    "    return pmf\n",
    "\n",
    "S_prime, S_new = get_S_prime(n) #use for sgd and eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def one_hot(sequence, seq_type='peptide'):\n",
    "    if seq_type == 'peptide':\n",
    "        letters = aa_list\n",
    "    else:\n",
    "        letters = na_list\n",
    "    one_hot = np.zeros((len(sequence), len(letters)))\n",
    "    for i in range(len(sequence)):\n",
    "        char = sequence[i]\n",
    "        for _ in range(len(letters)):\n",
    "            idx = letters.index(char)\n",
    "            one_hot[i][idx] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Convert a pair to one-hot tensor\n",
    "def convert(apt, pep): \n",
    "    apt = one_hot(apt, seq_type='aptamer') #(40, 4)\n",
    "    pep = one_hot(pep, seq_type='peptide') #(8, 20)\n",
    "    apt = torch.FloatTensor(np.reshape(apt, (1, 1, apt.shape[0], apt.shape[1]))).cuda() #(1, 1, 40, 4)\n",
    "    pep = torch.FloatTensor(np.reshape(pep, (1, 1, pep.shape[0], pep.shape[1]))).cuda() #(1, 1, 8, 20)\n",
    "    return apt, pep\n",
    "\n",
    "def update(x, y):\n",
    "    pmf = get_y_pmf(y)\n",
    "    x.requires_grad=True\n",
    "    y.requires_grad=True\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    out = model(x, y)\n",
    "    return pmf, out\n",
    "\n",
    "def apply_param_grad(grads1, grads2, fn):\n",
    "    gs = []\n",
    "    for grad1, grad2 in zip(grads1, grads2):\n",
    "        gs.append(fn(grad1, grad2))\n",
    "    return gs\n",
    "\n",
    "def sgd(t=1, #num of iter over the training set\n",
    "        lamb=1e-1, #hyperparam\n",
    "        gamma=1e-2): #step size\n",
    "    optim = SGD(model.parameters(), lr=gamma)\n",
    "    model.train()\n",
    "    for i, (apt, pep) in enumerate(tqdm.tqdm(train_loader)):\n",
    "        if i % 5000 == 0:\n",
    "            print(\"loss\")\n",
    "            #torch.save(model.state_dict(), PATH)\n",
    "        optim.zero_grad()\n",
    "        x, y = convert(apt[0], pep[0])\n",
    "        _, out = update(x, y)\n",
    "        log_out = torch.log(out)\n",
    "        log_out.backward(retain_graph=True)\n",
    "        g1 = []\n",
    "        for param in model.parameters():\n",
    "            g1.append(param.grad)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        x_prime, y_prime = convert(S_prime[i][0][0], S_prime[i][0][1])\n",
    "        y_pmf, out_prime = update(x_prime, y_prime)\n",
    "        out_prime = out_prime*y_pmf*get_x_pmf()*2*n\n",
    "        out_prime.backward()\n",
    "        g2 = []\n",
    "        for param in model.parameters():\n",
    "            g2.append(param.grad)\n",
    "        \n",
    "        const = S_prime[i][1] #indicator\n",
    "        gs = apply_param_grad(g1, g2, lambda g1, g2: lamb*const*g2 - g1)\n",
    "        for param, g in zip(model.parameters(), gs): #update params\n",
    "            param.grad = g\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall on train set of size k to test for overfitting\n",
    "def recall_train(k):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    train_recall_outputs = []\n",
    "    ### TODO: plot this?\n",
    "    for (apt, pep) in recall_train_samples:\n",
    "        apt, pep = convert(apt, pep)\n",
    "        out = model(apt, pep).cpu().detach().numpy().flatten()[0]\n",
    "        train_recall_outputs.append(out)\n",
    "        if out > 0.75:\n",
    "            correct += 1\n",
    "    train_recall = 100*correct/k #recall rate of k samples from training set\n",
    "    return train_recall, train_recall_outputs #list of k outputs\n",
    "\n",
    "\n",
    "# Recall on test set of size k\n",
    "def recall_test(k):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_recall_outputs = []\n",
    "    ### TODO: plot this?\n",
    "    for i, (aptamer, peptide) in enumerate(tqdm.tqdm(test_loader)):\n",
    "        if i > k:\n",
    "            break\n",
    "        apt, pep = convert(aptamer[0], peptide[0])\n",
    "        output = model(apt, pep).cpu().detach().numpy().flatten()[0]\n",
    "        test_recall_outputs.append(output)\n",
    "        if output > 0.75:\n",
    "            correct += 1\n",
    "    test_recall = 100*correct/k #recall rate of k samples from test set\n",
    "    return test_recall, test_recall_outputs #list of k outputs\n",
    "\n",
    "\n",
    "# Eval on m new unseen pairs in S_new (not in our dataset)\n",
    "def eval_unknown(m):\n",
    "    model.eval()\n",
    "    eval_unknown_outputs = []\n",
    "    for i, (x, y) in enumerate(S_new[:m]):\n",
    "        apt, pep = convert(x, y)\n",
    "        output = model(apt, pep).cpu().detach().numpy().flatten()[0]\n",
    "        eval_unknown_outputs.append(output)\n",
    "    return eval_unknown_outputs #list of m outputs\n",
    "\n",
    "\n",
    "# AUC Plot\n",
    "def cdf(scores, i): # i is the index\n",
    "    plt.hist(scores, 100, histtype='step', density=True, cumulative=True)\n",
    "    g = gammas[i//len(lambdas)]\n",
    "    l = lambdas[i%len(lambdas)]\n",
    "    label = 'lambda =%.5f' % l  + ' gamma =%.5f' % g\n",
    "    plt.legend([label])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [1e-2]\n",
    "lambdas = [1e-1, 1e-3, 1e-5]\n",
    "train_recalls = []\n",
    "train_scores = []\n",
    "train_cdfs = []\n",
    "test_recalls = []\n",
    "test_scores = []\n",
    "test_cdfs = []\n",
    "\n",
    "m = int(1e6) # number of unknown samples\n",
    "k = m//10 # number of binding samples (test set size is 118262, k is just some limit we set)\n",
    "recall_train_samples = get_xy(k) #use for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/473047 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 20/473047 [00:00<44:43, 176.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Training=======================\n",
      "=============Evaluating train===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 53/118262 [00:00<03:44, 526.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma:  0.01000 Lambda:  0.10000 Train recall:  0.00\n",
      "=============Evaluating test================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 96/118262 [00:00<04:00, 491.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma:  0.01000 Lambda:  0.10000 Test recall:  0.00\n",
      "=============Evaluating unknown=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/473047 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 18/473047 [00:00<52:33, 150.01it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:  0.01000 L:  0.10000 Train CDF:  0.499 Test CDF:  0.499\n",
      "=============Training=======================\n",
      "=============Evaluating train===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 57/118262 [00:00<06:04, 324.46it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma:  0.01000 Lambda:  0.00100 Train recall:  0.00\n",
      "=============Evaluating test================\n",
      "Gamma:  0.01000 Lambda:  0.00100 Test recall:  0.00\n",
      "=============Evaluating unknown=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/473047 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 19/473047 [00:00<47:12, 167.02it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:  0.01000 L:  0.00100 Train CDF:  0.499 Test CDF:  0.500\n",
      "=============Training=======================\n",
      "=============Evaluating train===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 59/118262 [00:00<05:39, 348.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma:  0.01000 Lambda:  0.00001 Train recall:  0.00\n",
      "=============Evaluating test================\n",
      "Gamma:  0.01000 Lambda:  0.00001 Test recall:  0.00\n",
      "=============Evaluating unknown=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:  0.01000 L:  0.00001 Train CDF:  0.500 Test CDF:  0.500\n",
      "Train CDFs:  [(0.01, 0.1, 0.49926835702156086), (0.01, 0.001, 0.49949869455225165), (0.01, 1e-05, 0.49983050644577437)]\n",
      "Test CDFs:  [(0.01, 0.1, 0.4993758552177761), (0.01, 0.001, 0.49971169473851074), (0.01, 1e-05, 0.5004482553021411)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 96/118262 [00:20<04:00, 491.35it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for g in range(len(gammas)):\n",
    "    for l in range(len(lambdas)):\n",
    "        model = SimpleConvNet()\n",
    "        model.apply(weights_init)\n",
    "        model.cuda()\n",
    "    \n",
    "        print(\"=============Training=======================\")\n",
    "        sgd(t=1, gamma=gammas[g], lamb=lambdas[l])\n",
    "        \n",
    "        print(\"=============Evaluating train===============\")\n",
    "        train_recall, train_recall_outputs = recall_train(k)\n",
    "        print(\"Gamma: \", \"%.5f\" % gammas[g], \"Lambda: \", \"%.5f\" % lambdas[l], \\\n",
    "              \"Train recall: \", \"%.2f\" % train_recall)\n",
    "        \n",
    "        print(\"=============Evaluating test================\")\n",
    "        test_recall, test_recall_outputs = recall_test(k)\n",
    "        print(\"Gamma: \", \"%.5f\" % gammas[g], \"Lambda: \", \"%.5f\" % lambdas[l], \\\n",
    "              \"Test recall: \", \"%.2f\" % test_recall)\n",
    "        \n",
    "        print(\"=============Evaluating unknown=============\")\n",
    "        eval_unknown_outputs = eval_unknown(m)\n",
    "        \n",
    "        train_score = np.asarray(eval_unknown_outputs + train_recall_outputs)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        test_score = np.asarray(eval_unknown_outputs + test_recall_outputs)\n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "        train_cdf = np.sum(np.cumsum(train_score), dtype=float)/(np.sum(train_score)*len(train_score))\n",
    "        test_cdf = np.sum(np.cumsum(test_score), dtype=float)/(np.sum(test_score)*len(test_score))\n",
    "        print(\"G: \", \"%.5f\" % gammas[g], \"L: \", \"%.5f\" % lambdas[l], \\\n",
    "              \"Train CDF: \", \"%.3f\" % train_cdf, \"Test CDF: \", \"%.3f\" % test_cdf)\n",
    "        \n",
    "        train_recalls.append(train_recall)\n",
    "        test_recalls.append(test_recall)\n",
    "        train_cdfs.append((gammas[g], lambdas[l], train_cdf))\n",
    "        test_cdfs.append((gammas[g], lambdas[l], test_cdf))\n",
    "\n",
    "print(\"Train CDFs: \", train_cdfs)\n",
    "print(\"Test CDFs: \", test_cdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "#### 1. figure out what loss to save\n",
    "#### 2. config saving/loading model\n",
    "#### 3. show all outputs on a single plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "walnutree",
   "language": "python",
   "name": "walnutree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
