{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*13 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "aa_dict = dict(zip(aa_list, pvals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_dataset_file = \"../data/aptamer_dataset.json\"\n",
    "\n",
    "def construct_dataset():\n",
    "    with open(aptamer_dataset_file, 'r') as f:\n",
    "        aptamer_data = json.load(f)\n",
    "    full_dataset = []\n",
    "    aptamers = []\n",
    "    peptides = []\n",
    "    for aptamer in aptamer_data:\n",
    "        peptides = aptamer_data[aptamer]\n",
    "        if aptamer == \"CTTTGTAATTGGTTCTGAGTTCCGTTGTGGGAGGAACATG\": #took out aptamer control\n",
    "            continue\n",
    "        for peptide, _ in peptides:\n",
    "            peptide = peptide.replace(\"_\", \"\") #removed stop codons\n",
    "            if \"RRRRRR\" in peptide: #took out peptide control\n",
    "                continue\n",
    "            if len(aptamer) == 40 and len(peptide) == 8: #making sure right length\n",
    "                full_dataset.append((aptamer, peptide))\n",
    "    full_dataset = list(set(full_dataset)) #removed duplicates\n",
    "    for pair in full_dataset:\n",
    "        aptamers.append(pair[0])\n",
    "        peptides.append(pair[1])\n",
    "    return full_dataset, aptamers, peptides "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_set):\n",
    "        super(TrainDataset, self).__init__() \n",
    "        self.training_set = training_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.training_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.training_set[idx]\n",
    "        return aptamer, peptide\n",
    "    \n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, test_set):\n",
    "        super(TestDataset, self).__init__() \n",
    "        self.test_set = test_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.test_set[idx]\n",
    "        return aptamer, peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset, aptamers, peptides = construct_dataset()\n",
    "n = len(full_dataset)\n",
    "training_set = full_dataset[:int(0.8*n)]\n",
    "test_set = full_dataset[int(0.8*n):]\n",
    "train_dataset = TrainDataset(training_set)\n",
    "test_dataset = TestDataset(test_set)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def one_hot(sequence_list, seq_type='peptide'):\n",
    "    if seq_type == 'peptide':\n",
    "        letters = aa_list\n",
    "    else:\n",
    "        letters = na_list\n",
    "    \n",
    "    one_hot = np.zeros((len(sequence_list), len(sequence_list[0]), len(letters)))\n",
    "    \n",
    "    for j in range(len(sequence_list)):\n",
    "        sequence = sequence_list[j]\n",
    "        for i in range(len(sequence)):\n",
    "            element = sequence[i]\n",
    "            idx = letters.index(element)\n",
    "            one_hot[j][i][idx] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(40, 20, 1)\n",
    "        self.cnn_apt_2 = nn.Conv2d(20, 10, 1)\n",
    "        self.cnn_apt_3 = nn.Conv2d(10, 1, 1)\n",
    "        self.fc_apt_1 = nn.Linear(160, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv2d(8, 4, 1)\n",
    "        self.cnn_pep_2 = nn.Conv2d(4, 3, 1)\n",
    "        self.fc_pep_1 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "                \n",
    "        self.sequential_pep = nn.Sequential(self.cnn_pep_1,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_pep_2)\n",
    "        \n",
    "        self.sequential_apt = nn.Sequential(self.cnn_apt_1, \n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_2, \n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.sequential_apt(apt).cuda()\n",
    "        pep = self.sequential_pep(pep).cuda()\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(40, 20, 1)\n",
    "        self.cnn_apt_2 = nn.Conv2d(20, 10, 1)\n",
    "        self.cnn_apt_3 = nn.Conv2d(10, 1, 1)\n",
    "        self.fc_apt_1 = nn.Linear(160, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv2d(8, 4, 1)\n",
    "        self.cnn_pep_2 = nn.Conv2d(4, 3, 1)\n",
    "        self.fc_pep_1 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "                \n",
    "        self.sequential_pep = nn.Sequential(self.cnn_pep_1,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_pep_2)\n",
    "        \n",
    "        self.sequential_apt = nn.Sequential(self.cnn_apt_1, \n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_2, \n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.sequential_apt(apt).cuda()\n",
    "        pep = self.sequential_pep(pep).cuda()\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (cnn_apt_1): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cnn_apt_2): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cnn_apt_3): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc_apt_1): Linear(in_features=160, out_features=1, bias=True)\n",
       "  (cnn_pep_1): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cnn_pep_2): Conv2d(4, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc_pep_1): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (sequential_pep): Sequential(\n",
       "    (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(4, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (sequential_apt): Sequential(\n",
       "    (0): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (fc1): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "\n",
    "model.apply(weights_init)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample x from P_X (assume peptides follow NNK)\n",
    "def get_x():\n",
    "    x_idx = np.random.choice(20, 7, p=pvals)\n",
    "    x = \"M\"\n",
    "    for i in x_idx:\n",
    "        x += aa_list[i]\n",
    "    return x\n",
    "\n",
    "# Sample y from P_Y (assume apatamers follow uniform)\n",
    "def get_y():\n",
    "    y_idx = np.random.randint(0, 4, 40)\n",
    "    y = \"\"\n",
    "    for i in y_idx:\n",
    "        y += na_list[i]\n",
    "    return y\n",
    "\n",
    "# Generate uniformly from S without replacement\n",
    "def get_xy(k):\n",
    "    samples = [full_dataset[i] for i in np.random.choice(len(full_dataset), k, replace=False)]\n",
    "    return samples\n",
    "\n",
    "# S' contains S with double the size of S (domain for Importance Sampling)\n",
    "def get_S_prime(k):\n",
    "    S_prime = full_dataset[:]\n",
    "    for _ in range(k):\n",
    "        S_prime.append((get_y(), get_x()))\n",
    "    return list(set(S_prime))\n",
    "\n",
    "# Sample from S' without replacement\n",
    "def get_xy_prime(k):\n",
    "    samples = [S_prime[i] for i in np.random.choice(len(S_prime), k, replace=False)]\n",
    "    return samples\n",
    "\n",
    "# Returns pmf of a peptide\n",
    "def get_x_pmf(x):\n",
    "    pmf = 1\n",
    "    for char in x[1:]: #skips first char \"M\"\n",
    "        pmf *= aa_dict[char]\n",
    "    return pmf\n",
    "\n",
    "# Returns pmf of an aptamer\n",
    "def get_y_pmf():\n",
    "    return 0.25**40\n",
    "\n",
    "S_prime = get_S_prime(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(type=\"original\"):\n",
    "    if type == \"original\":\n",
    "        xy = get_xy(1)[0]\n",
    "    else:\n",
    "        xy = get_xy_prime(1)[0]\n",
    "    x = one_hot(xy[0], seq_type='aptamer') \n",
    "    y = one_hot(xy[1], seq_type='peptide') \n",
    "    x = torch.FloatTensor(np.reshape(x, (1, x.shape[0], x.shape[1], x.shape[2])))\n",
    "    y = torch.FloatTensor(np.reshape(y, (1, y.shape[0], y.shape[1], y.shape[2])))\n",
    "    x.requires_grad=True\n",
    "    y.requires_grad=True\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    out = model(x, y)\n",
    "    return xy, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(t=1000, #num of iter\n",
    "        lamb=1e-5, #hyperparam\n",
    "        gamma=1e-4): #step size\n",
    "    \n",
    "    model.train()\n",
    "    for a, _ in enumerate(tqdm.tqdm(range(t))):\n",
    "        xy, out = update()\n",
    "        out.retain_grad()\n",
    "        log_out = torch.log(out)\n",
    "        log_out.retain_grad()\n",
    "        model.zero_grad()\n",
    "        log_out.backward()\n",
    "        \n",
    "        xy_prime, out_prime = update(\"prime\")\n",
    "        out_prime = out_prime * get_x_pmf(xy_prime[0]) * get_y_pmf() * 2 * n\n",
    "        out_prime.retain_grad()\n",
    "        model.zero_grad()\n",
    "        out_prime.backward()\n",
    "        \n",
    "        const = 0 if xy_prime in full_dataset else 1 #indicator\n",
    "        g = log_out.grad - lamb*const*out_prime.grad\n",
    "        g = g.item()\n",
    "        \n",
    "        #Update the weights according to SGD\n",
    "        for param in model.parameters():\n",
    "            param.data += gamma * g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval on test set of size k (split from our dataset)\n",
    "def recall(k):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    binding_outputs = []\n",
    "    model.eval()\n",
    "    for _, (aptamer, peptide) in enumerate(tqdm.tqdm(test_loader)):\n",
    "        if count > k:\n",
    "            break\n",
    "        pep = one_hot(peptide, seq_type='peptide')\n",
    "        apt = one_hot(aptamer, seq_type='aptamer')\n",
    "        pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[1], pep.shape[2], pep.shape[0]))).cuda()\n",
    "        apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[1], apt.shape[2], apt.shape[0]))).cuda()\n",
    "        output = model(apt, pep).cpu().detach().numpy().flatten()[0]\n",
    "        binding_outputs.append('%.2f'% output)\n",
    "        if output > 0.5:\n",
    "            correct += 1\n",
    "        count += 1\n",
    "    recall = (100*correct/k) #recall rate of k samples\n",
    "    return recall, binding_outputs #list of k outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(apt, pep): \n",
    "    apt = one_hot(apt, seq_type='aptamer') #(40, 1, 4)\n",
    "    pep = one_hot(pep, seq_type='peptide') #(8, 1, 20)\n",
    "    apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[0], apt.shape[2], apt.shape[1]))).cuda() #(1, 40, 4, 1)\n",
    "    pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[0], pep.shape[2], pep.shape[1]))).cuda() #(1, 8, 20, 1)\n",
    "    return apt, pep\n",
    "\n",
    "# Eval on m new unseen pairs(not in our dataset)\n",
    "def evaluate(m):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    for _ in range(m):\n",
    "        x, y = get_x(), get_y()\n",
    "        apt, pep = convert(y, x)\n",
    "        output = model(apt, pep).cpu().detach().numpy().flatten()[0]\n",
    "        outputs.append('%.2f'% output)\n",
    "    return outputs #list of m outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:38<00:00,  6.32it/s]\n",
      "  0%|          | 35/118262 [00:00<05:40, 347.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 490/118262 [00:01<05:42, 343.37it/s]\n",
      "  0%|          | 1/1000 [00:00<02:28,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.1 , lambda: 0.1 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [00:17<02:53,  5.18it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0dfad0a1438d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgammas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# use for AUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ae2dadb8f854>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(t, lamb, gamma)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlog_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mxy_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prime\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mout_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_prime\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mget_x_pmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mget_y_pmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout_prime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-803c8313abbf>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(type)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xy_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'aptamer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-074bf79bf33c>\u001b[0m in \u001b[0;36mget_xy_prime\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Sample from S' without replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_xy_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mS_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gammas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "lambdas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "recalls = []\n",
    "scores = []\n",
    "\n",
    "m = int(3e3) # number of unknown samples\n",
    "k = int(5e2) # number of binding samples (test set size is 118262, k is just some limit we set)\n",
    "\n",
    "M = np.zeros((len(gammas), len(lambdas)))\n",
    "for g in range(len(gammas)):\n",
    "    for l in range(len(lambdas)):\n",
    "        model = ConvNet()\n",
    "        model.apply(weights_init)\n",
    "        model.cuda()\n",
    "        print(\"Training...\")\n",
    "        sgd(t=1000, gamma=gammas[g], lamb=lambdas[l])\n",
    "        print(\"Evaluating...\")\n",
    "        # use for AUC\n",
    "        recall, binding_outputs = recall(k)\n",
    "        unknown_outputs = evaluate(m)\n",
    "        scores.append((unknown_outputs, binding_outputs))\n",
    "        # use for heatmap\n",
    "        M[g][l] += recall\n",
    "        recalls.append(recall)\n",
    "        print(\"Recall with gamma: \"+ str(gammas[g]) + \" , lambda: \" + str(lambdas[l]) + \" recall: \", '%.2f'% recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma:  0.10000 Lambda:  0.10000 Recall:  100.20\n"
     ]
    }
   ],
   "source": [
    "# Table of recalls with different params\n",
    "idx = sorted(range(len(recalls)), key=lambda k: recalls[k])\n",
    "for i in idx:\n",
    "    g = gammas[i//len(gammas)]\n",
    "    l = lambdas[i%len(lambdas)]\n",
    "    print(\"Gamma: \", \"%.5f\" % g, \"Lambda: \", \"%.5f\" % l, \"Recall: \", \"%.2f\" % recalls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heatmap of recalls\n",
    "mat = sns.heatmap(M, vmin=0, vmax=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUC (one config for now)\n",
    "unknown, binding = scores[0]\n",
    "total = unknown + binding\n",
    "plt.hist(total, 50, histtype='step', density=True, cumulative=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "walnutree",
   "language": "python",
   "name": "walnutree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
