{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*13 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "aa_dict = dict(zip(aa_list, pvals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_dataset_file = \"../data/aptamer_dataset.json\"\n",
    "\n",
    "def construct_dataset():\n",
    "    with open(aptamer_dataset_file, 'r') as f:\n",
    "        aptamer_data = json.load(f)\n",
    "    full_dataset = []\n",
    "    aptamers = []\n",
    "    peptides = []\n",
    "    for aptamer in aptamer_data:\n",
    "        peptides = aptamer_data[aptamer]\n",
    "        if aptamer == \"CTTTGTAATTGGTTCTGAGTTCCGTTGTGGGAGGAACATG\": #took out aptamer control\n",
    "            continue\n",
    "        for peptide, _ in peptides:\n",
    "            peptide = peptide.replace(\"_\", \"\") #removed stop codons\n",
    "            if \"RRRRRR\" in peptide: #took out peptide control\n",
    "                continue\n",
    "            if len(aptamer) == 40 and len(peptide) == 8: #making sure right length\n",
    "                full_dataset.append((aptamer, peptide))\n",
    "    full_dataset = list(set(full_dataset)) #removed duplicates\n",
    "    for pair in full_dataset:\n",
    "        aptamers.append(pair[0])\n",
    "        peptides.append(pair[1])\n",
    "    return full_dataset, aptamers, peptides "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_set):\n",
    "        super(TrainDataset, self).__init__() \n",
    "        self.training_set = training_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.training_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.training_set[idx]\n",
    "        return aptamer, peptide\n",
    "    \n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, test_set):\n",
    "        super(TestDataset, self).__init__() \n",
    "        self.test_set = test_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.test_set[idx]\n",
    "        return aptamer, peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset, aptamers, peptides = construct_dataset()\n",
    "n = len(full_dataset)\n",
    "training_set = full_dataset[:int(0.8*n)]\n",
    "test_set = full_dataset[int(0.8*n):]\n",
    "train_dataset = TrainDataset(training_set)\n",
    "test_dataset = TestDataset(test_set)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def one_hot(sequence_list, seq_type='peptide'):\n",
    "    if seq_type == 'peptide':\n",
    "        letters = aa_list\n",
    "    else:\n",
    "        letters = na_list\n",
    "    \n",
    "    one_hot = np.zeros((len(sequence_list), len(sequence_list[0]), len(letters)))\n",
    "    \n",
    "    for j in range(len(sequence_list)):\n",
    "        sequence = sequence_list[j]\n",
    "        for i in range(len(sequence)):\n",
    "            element = sequence[i]\n",
    "            idx = letters.index(element)\n",
    "            one_hot[j][i][idx] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(40, 20, 1)\n",
    "        self.cnn_apt_2 = nn.Conv2d(20, 10, 1)\n",
    "        self.cnn_apt_3 = nn.Conv2d(10, 1, 1)\n",
    "        self.fc_apt_1 = nn.Linear(160, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv2d(8, 4, 1)\n",
    "        self.cnn_pep_2 = nn.Conv2d(4, 3, 1)\n",
    "        self.fc_pep_1 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "                \n",
    "        self.sequential_pep = nn.Sequential(self.cnn_pep_1,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_pep_2)\n",
    "        \n",
    "        self.sequential_apt = nn.Sequential(self.cnn_apt_1, \n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_2, \n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.sequential_apt(apt).cuda()\n",
    "        pep = self.sequential_pep(pep).cuda()\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayer, self).__init__(),\n",
    "        self.linear_apt_1 = nn.Linear(40, 20, 1)\n",
    "        self.linear_apt_2 = nn.Linear(20, 10, 1)\n",
    "        \n",
    "        self.linear_pep_1 = nn.Linear(8, 4, 1)\n",
    "        self.linear_pep_2 = nn.Linear(4, 2, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.sequential_pep = nn.Sequential(self.linear_pep_1,\n",
    "                                            self.relu,\n",
    "                                            self.linear_pep_2)\n",
    "        \n",
    "        self.sequential_apt = nn.Sequential(self.linear_apt_1,\n",
    "                                            self.relu,\n",
    "                                            self.linear_apt_2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.sequential_apt(apt).cuda()\n",
    "        pep = self.sequential_pep(pep).cuda()\n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample x from P_X (assume peptides follow NNK)\n",
    "def get_x():\n",
    "    x_idx = np.random.choice(20, 7, p=pvals)\n",
    "    x = \"M\"\n",
    "    for i in x_idx:\n",
    "        x += aa_list[i]\n",
    "    return x\n",
    "\n",
    "# Sample y from P_Y (assume apatamers follow uniform)\n",
    "def get_y():\n",
    "    y_idx = np.random.randint(0, 4, 40)\n",
    "    y = \"\"\n",
    "    for i in y_idx:\n",
    "        y += na_list[i]\n",
    "    return y\n",
    "\n",
    "# Generate uniformly from S without replacement\n",
    "def get_xy(k):\n",
    "    samples = [full_dataset[i] for i in np.random.choice(len(full_dataset), k, replace=False)]\n",
    "    return samples\n",
    "\n",
    "# S' contains S with double the size of S (domain for Importance Sampling)\n",
    "def get_S_prime(k):\n",
    "    S_prime = full_dataset[:]\n",
    "    for _ in range(k):\n",
    "        S_prime.append((get_y(), get_x()))\n",
    "    return list(set(S_prime))\n",
    "\n",
    "# Sample from S' without replacement\n",
    "def get_xy_prime(k):\n",
    "    samples = [S_prime[i] for i in np.random.choice(len(S_prime), k, replace=False)]\n",
    "    return samples\n",
    "\n",
    "# Returns pmf of a peptide\n",
    "def get_x_pmf(x):\n",
    "    pmf = 1\n",
    "    for char in x[1:]: #skips first char \"M\"\n",
    "        pmf *= aa_dict[char]\n",
    "    return pmf\n",
    "\n",
    "# Returns pmf of an aptamer\n",
    "def get_y_pmf():\n",
    "    return 0.25**40\n",
    "\n",
    "S_prime = get_S_prime(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(type=\"original\"):\n",
    "    if type == \"original\":\n",
    "        xy = get_xy(1)[0]\n",
    "    else:\n",
    "        xy = get_xy_prime(1)[0]\n",
    "    x = one_hot(xy[0], seq_type='aptamer') \n",
    "    y = one_hot(xy[1], seq_type='peptide') \n",
    "    x = torch.FloatTensor(np.reshape(x, (1, x.shape[0], x.shape[1], x.shape[2])))\n",
    "    y = torch.FloatTensor(np.reshape(y, (1, y.shape[0], y.shape[1], y.shape[2])))\n",
    "    x.requires_grad=True\n",
    "    y.requires_grad=True\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    out = model(x, y)\n",
    "    return xy, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(t=1000, #num of iter\n",
    "        lamb=1e-5, #hyperparam\n",
    "        gamma=1e-4): #step size\n",
    "    \n",
    "    model.train()\n",
    "    for a, _ in enumerate(tqdm.tqdm(range(t))):\n",
    "        xy, out = update()\n",
    "        out.retain_grad()\n",
    "        log_out = torch.log(out)\n",
    "        log_out.retain_grad()\n",
    "        model.zero_grad()\n",
    "        log_out.backward()\n",
    "        \n",
    "        xy_prime, out_prime = update(\"prime\")\n",
    "        out_prime = out_prime * get_x_pmf(xy_prime[0]) * get_y_pmf() * 2 * n\n",
    "        out_prime.retain_grad()\n",
    "        model.zero_grad()\n",
    "        out_prime.backward()\n",
    "        \n",
    "        const = 0 if xy_prime in full_dataset else 1 #indicator\n",
    "        g = log_out.grad - lamb*const*out_prime.grad\n",
    "        g = g.item()\n",
    "        \n",
    "        #Update the weights according to SGD\n",
    "        for param in model.parameters():\n",
    "            param.data += gamma * g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval on test set of size k (split from our dataset)\n",
    "def recall_eval(k):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    binding_outputs = []\n",
    "    model.eval()\n",
    "    for _, (aptamer, peptide) in enumerate(tqdm.tqdm(test_loader)):\n",
    "        if count > k:\n",
    "            break\n",
    "        pep = one_hot(peptide, seq_type='peptide')\n",
    "        apt = one_hot(aptamer, seq_type='aptamer')\n",
    "        pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[1], pep.shape[2], pep.shape[0]))).cuda()\n",
    "        apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[1], apt.shape[2], apt.shape[0]))).cuda()\n",
    "        output = model(apt, pep).cpu().detach().numpy().flatten()[0]\n",
    "        binding_outputs.append('%.2f'% output)\n",
    "        if output > 0.5:\n",
    "            correct += 1\n",
    "        count += 1\n",
    "    recall = 100*correct/k #recall rate of k samples\n",
    "    return recall, binding_outputs #list of k outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(apt, pep): \n",
    "    apt = one_hot(apt, seq_type='aptamer') #(40, 1, 4)\n",
    "    pep = one_hot(pep, seq_type='peptide') #(8, 1, 20)\n",
    "    apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[0], apt.shape[2], apt.shape[1]))).cuda() #(1, 40, 4, 1)\n",
    "    pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[0], pep.shape[2], pep.shape[1]))).cuda() #(1, 8, 20, 1)\n",
    "    return apt, pep\n",
    "\n",
    "# Eval on m new unseen pairs(not in our dataset)\n",
    "def evaluate(m):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    for _ in range(m):\n",
    "        x, y = get_x(), get_y()\n",
    "        apt, pep = convert(y, x)\n",
    "        output = model(apt, pep).cpu().detach().numpy().flatten()[0]\n",
    "        outputs.append('%.2f'% output)\n",
    "    return outputs #list of m outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:46<00:00,  6.00it/s]\n",
      "  0%|          | 26/118262 [00:00<07:53, 249.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 491/118262 [00:01<06:23, 307.14it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.1 , lambda: 0.1 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:43<00:00,  6.11it/s]\n",
      "  0%|          | 22/118262 [00:00<09:10, 214.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 483/118262 [00:01<06:30, 301.96it/s]\n",
      "  0%|          | 1/1000 [00:00<02:36,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.1 , lambda: 0.01 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:41<00:00,  6.19it/s]\n",
      "  0%|          | 21/118262 [00:00<09:48, 200.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 458/118262 [00:01<06:48, 288.67it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.1 , lambda: 0.001 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:44<00:00,  6.07it/s]\n",
      "  0%|          | 29/118262 [00:00<06:49, 288.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 498/118262 [00:01<06:18, 311.07it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.1 , lambda: 0.0001 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:43<00:00,  6.13it/s]\n",
      "  0%|          | 46/118262 [00:00<04:20, 453.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 489/118262 [00:01<06:30, 301.69it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.1 , lambda: 1e-05 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:48<00:00,  5.94it/s]\n",
      "  0%|          | 22/118262 [00:00<08:57, 219.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 460/118262 [00:01<06:48, 288.23it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.01 , lambda: 0.1 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:46<00:00,  6.00it/s]\n",
      "  0%|          | 44/118262 [00:00<04:29, 438.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 477/118262 [00:01<06:05, 321.89it/s]\n",
      "  0%|          | 1/1000 [00:00<02:58,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.01 , lambda: 0.01 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:46<00:00,  5.99it/s]\n",
      "  0%|          | 29/118262 [00:00<06:50, 287.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 497/118262 [00:01<06:15, 313.40it/s]\n",
      "  0%|          | 1/1000 [00:00<02:30,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.01 , lambda: 0.001 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:44<00:00,  6.10it/s]\n",
      "  0%|          | 26/118262 [00:00<07:54, 249.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 470/118262 [00:01<06:24, 306.70it/s]\n",
      "  0%|          | 1/1000 [00:00<02:20,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.01 , lambda: 0.0001 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:46<00:00,  5.99it/s]\n",
      "  0%|          | 32/118262 [00:00<06:19, 311.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 477/118262 [00:01<06:34, 298.73it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.01 , lambda: 1e-05 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:50<00:00,  5.88it/s]\n",
      "  0%|          | 21/118262 [00:00<09:27, 208.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 474/118262 [00:01<06:32, 300.18it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.001 , lambda: 0.1 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:46<00:00,  5.99it/s]\n",
      "  0%|          | 44/118262 [00:00<04:30, 437.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 486/118262 [00:01<05:57, 328.99it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.001 , lambda: 0.01 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:47<00:00,  5.96it/s]\n",
      "  0%|          | 22/118262 [00:00<09:10, 214.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 469/118262 [00:01<06:24, 306.47it/s]\n",
      "  0%|          | 1/1000 [00:00<03:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.001 , lambda: 0.001 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:45<00:00,  6.03it/s]\n",
      "  0%|          | 20/118262 [00:00<09:57, 197.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 501/118262 [00:01<06:25, 305.51it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.001 , lambda: 0.0001 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:45<00:00,  6.03it/s]\n",
      "  0%|          | 21/118262 [00:00<09:34, 205.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 462/118262 [00:01<06:39, 294.84it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.001 , lambda: 1e-05 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:48<00:00,  5.92it/s]\n",
      "  0%|          | 40/118262 [00:00<04:58, 396.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 481/118262 [00:01<06:02, 325.26it/s]\n",
      "  0%|          | 1/1000 [00:00<02:49,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.0001 , lambda: 0.1 recall:  24.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:46<00:00,  6.01it/s]\n",
      "  0%|          | 36/118262 [00:00<05:30, 358.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 475/118262 [00:01<06:11, 317.18it/s]\n",
      "  0%|          | 2/1000 [00:00<01:14, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.0001 , lambda: 0.01 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:46<00:00,  6.02it/s]\n",
      "  0%|          | 43/118262 [00:00<04:42, 418.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 480/118262 [00:01<06:51, 286.49it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.0001 , lambda: 0.001 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:47<00:00,  5.96it/s]\n",
      "  0%|          | 35/118262 [00:00<05:41, 346.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 494/118262 [00:01<06:23, 307.20it/s]\n",
      "  0%|          | 1/1000 [00:00<02:56,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.0001 , lambda: 0.0001 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:50<00:00,  5.86it/s]\n",
      "  0%|          | 45/118262 [00:00<04:29, 439.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 478/118262 [00:01<06:00, 326.51it/s]\n",
      "  0%|          | 1/1000 [00:00<02:03,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 0.0001 , lambda: 1e-05 recall:  100.20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:45<00:00,  6.03it/s]\n",
      "  0%|          | 45/118262 [00:00<04:28, 439.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 500/118262 [00:01<06:22, 307.93it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 1e-05 , lambda: 0.1 recall:  5.80\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:49<00:00,  5.89it/s]\n",
      "  0%|          | 31/118262 [00:00<06:41, 294.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 501/118262 [00:01<05:53, 333.35it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 1e-05 , lambda: 0.01 recall:  81.40\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:55<00:00,  5.71it/s]\n",
      "  0%|          | 15/118262 [00:00<13:49, 142.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 490/118262 [00:02<10:20, 189.76it/s]\n",
      "  0%|          | 1/1000 [00:00<02:03,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 1e-05 , lambda: 0.001 recall:  73.60\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:56<00:00,  5.65it/s]\n",
      "  0%|          | 17/118262 [00:00<11:36, 169.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 496/118262 [00:02<10:29, 187.05it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 1e-05 , lambda: 0.0001 recall:  34.60\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:55<00:00,  5.69it/s]\n",
      "  0%|          | 37/118262 [00:00<05:21, 368.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 488/118262 [00:01<06:48, 288.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall with gamma: 1e-05 , lambda: 1e-05 recall:  40.00\n"
     ]
    }
   ],
   "source": [
    "gammas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "lambdas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "recalls = []\n",
    "scores = []\n",
    "\n",
    "m = int(3e3) # number of unknown samples\n",
    "k = int(5e2) # number of binding samples (test set size is 118262, k is just some limit we set)\n",
    "\n",
    "M = np.zeros((len(gammas), len(lambdas)))\n",
    "for g in range(len(gammas)):\n",
    "    for l in range(len(lambdas)):\n",
    "        model = ConvNet()\n",
    "        model.apply(weights_init)\n",
    "        model.cuda()\n",
    "        print(\"Training...\")\n",
    "        sgd(t=1000, gamma=gammas[g], lamb=lambdas[l])\n",
    "        print(\"Evaluating...\")\n",
    "        # use for AUC\n",
    "        recall, binding_outputs = recall_eval(k)\n",
    "        unknown_outputs = evaluate(m)\n",
    "        scores.append((unknown_outputs, binding_outputs))\n",
    "        # use for heatmap\n",
    "        M[g][l] += recall\n",
    "        recalls.append(recall)\n",
    "        print(\"Recall with gamma: \"+ str(gammas[g]) + \" , lambda: \" + str(lambdas[l]) + \" recall: \", '%.2f'% recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma:  0.00001 Lambda:  0.10000 Recall:  5.80\n",
      "Gamma:  0.00010 Lambda:  0.10000 Recall:  24.00\n",
      "Gamma:  0.00001 Lambda:  0.00010 Recall:  34.60\n",
      "Gamma:  0.00001 Lambda:  0.00001 Recall:  40.00\n",
      "Gamma:  0.00001 Lambda:  0.00100 Recall:  73.60\n",
      "Gamma:  0.00001 Lambda:  0.01000 Recall:  81.40\n",
      "Gamma:  0.10000 Lambda:  0.10000 Recall:  100.20\n",
      "Gamma:  0.10000 Lambda:  0.01000 Recall:  100.20\n",
      "Gamma:  0.10000 Lambda:  0.00100 Recall:  100.20\n",
      "Gamma:  0.10000 Lambda:  0.00010 Recall:  100.20\n",
      "Gamma:  0.10000 Lambda:  0.00001 Recall:  100.20\n",
      "Gamma:  0.01000 Lambda:  0.10000 Recall:  100.20\n",
      "Gamma:  0.01000 Lambda:  0.01000 Recall:  100.20\n",
      "Gamma:  0.01000 Lambda:  0.00100 Recall:  100.20\n",
      "Gamma:  0.01000 Lambda:  0.00010 Recall:  100.20\n",
      "Gamma:  0.01000 Lambda:  0.00001 Recall:  100.20\n",
      "Gamma:  0.00100 Lambda:  0.10000 Recall:  100.20\n",
      "Gamma:  0.00100 Lambda:  0.01000 Recall:  100.20\n",
      "Gamma:  0.00100 Lambda:  0.00100 Recall:  100.20\n",
      "Gamma:  0.00100 Lambda:  0.00010 Recall:  100.20\n",
      "Gamma:  0.00100 Lambda:  0.00001 Recall:  100.20\n",
      "Gamma:  0.00010 Lambda:  0.01000 Recall:  100.20\n",
      "Gamma:  0.00010 Lambda:  0.00100 Recall:  100.20\n",
      "Gamma:  0.00010 Lambda:  0.00010 Recall:  100.20\n",
      "Gamma:  0.00010 Lambda:  0.00001 Recall:  100.20\n"
     ]
    }
   ],
   "source": [
    "# Table of recalls with different params\n",
    "idx = sorted(range(len(recalls)), key=lambda k: recalls[k])\n",
    "for i in idx:\n",
    "    g = gammas[i//len(gammas)]\n",
    "    l = lambdas[i%len(lambdas)]\n",
    "    print(\"Gamma: \", \"%.5f\" % g, \"Lambda: \", \"%.5f\" % l, \"Recall: \", \"%.2f\" % recalls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD8CAYAAABJsn7AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQPklEQVR4nO3dfawldX3H8feHp6olFqhKKUsF260PtRGFAC2JsdBEQCOkkURtYWOx6x+K2NoqNmmJiW009bGJbboB6hINiGgCUWNLEGL6IAJCLbA20K3FhZWVKD7ERrj3fvvHma2nm733nHvunP3tGd4vMrn3zDl35jts9nO/+5vfzKSqkCQdeIe0LkCSnqoMYElqxACWpEYMYElqxACWpEYMYElqxACWpFUkuTrJniT3jq07JsnNSR7ovh7drU+Sv07yYJKvJ3nZpO1PDOAkL0jyrm7DH+2+f+HGDkuSFsLHgXP2WXc5cEtVbQZu6V4DnAts7patwN9O2viaAZzkXcB1QICvAnd031+b5PK1flaSFl1VfRn47j6rzwe2d99vBy4YW39NjXwFOCrJcWtt/7AJ+78E+LWqenJ8ZZIPAfcB79vfDyXZyug3AH/zwfee8qaLXz9hN5IEhz/rednoNp58bOfUl/ce8exffjNdVnW2VdW2CT92bFXtBqiq3Ume060/HvjW2Od2det2r7ahSQG8Avwi8N/7rD+ue2+/ugPYBuv7nyFJB9J4VvVgf7881sy/SQH8duCWJA/w02T/JeBXgLeuuzxJmreV5Xnv4dEkx3Xd73HAnm79LuCEsc9tAh5Za0NrBnBVfTHJrwKnMWql0+3kjqqa+1FK0rotL817DzcBWxgNwW4Bbhxb/9Yk1wGnA9/fO1SxmkkdMFW1AnxlQ+VK0gEyiqx+JLkWeAXwrCS7gCsYBe/1SS4BHgIu7D7+BeA84EHgx8AbJ21/YgBL0kJZ6S+Aq2q1GQRn7+ezBbxlPds3gCUNS48d8LwZwJKGZf4n4XpjAEsaFjtgSWqj5j8LojcGsKRh6fEk3LwZwJKGxSEISWrEk3CS1IgdsCQ14kk4SWrEk3CS1MYi3SfMAJY0LI4BS1IjDkFIUiN2wJLUyPKTkz9zkDCAJQ2LQxCS1IhDEJLUiB2wJDViAEtSG+VJOElqxDFgSWrEIQhJasQOWJIasQOWpEbsgCWpkSVvyC5JbdgBS1IjjgFLUiN2wJLUiB2wJDViByxJjTgLQpIaqWpdwdQMYEnD4hiwJDWyQAF8SOsCJKlXtTL9MkGSP0xyX5J7k1yb5GlJTkpye5IHknwqyRGzlmoASxqW5eXplzUkOR54G3BqVb0YOBR4HfB+4MNVtRn4HnDJrKUawJKGZWVl+mWyw4CnJzkMeAawGzgLuKF7fztwwaylGsCShmUdAZxka5I7x5atezdTVQ8DHwAeYhS83wfuAh6vqr1z3XYBx89aqifhJA3LOi7EqKptwLb9vZfkaOB84CTgceDTwLn728z6ixwxgCUNSq30Ng/4t4H/qqrvACT5LPCbwFFJDuu64E3AI7PuwCEIScPS3xjwQ8AZSZ6RJMDZwP3ArcBru89sAW6ctVQ7YEnDMmF2w7Sq6vYkNwBfA5aAuxkNV3weuC7Je7t1V826DwNY0rD0eCFGVV0BXLHP6p3AaX1s3wCWNCwLdCWcASxpWLwZjyQ1YgcsSY30Nw1t7maehpbkjX0WIkm96OleEAfCRuYBv2e1N8Yv77vymms3sAtJWp9aWZl6aW3NIYgkX1/tLeDY1X5u/PK+Jx/buTj/HpC0+BZoCGLSGPCxwCsZ3XJtXIB/mUtFkrQRA3oo5+eAI6vqnn3fSHLbXCqSpI0YSgdcVaveaLiq3tB/OZK0QUvtT65Ny2lokoZlQEMQkrRYhjIEIUmL5mCYXjYtA1jSsNgBS1IjBrAkNXIQXGI8LQNY0qD0+Ey4uTOAJQ2LASxJjTgLQpIasQOWpEYMYElqo5YdgpCkNuyAJakNp6FJUisGsCQ1sjhDwAawpGGppcVJYANY0rAsTv4awJKGxZNwktSKHbAktWEHLEmt2AFLUhu11LqC6RnAkgZlgZ5KzyGtC5CkXq2sY5kgyVFJbkjyjSQ7kvxGkmOS3Jzkge7r0bOWagBLGpRamX6ZwkeBL1bVC4CXADuAy4FbqmozcEv3eiYGsKRB6SuAkzwTeDlwFUBVPVFVjwPnA9u7j20HLpi1VgNY0qDUcqZekmxNcufYsnVsU88DvgP8fZK7k1yZ5GeBY6tqN0D39Tmz1upJOEmDsp6TcFW1Ddi2ytuHAS8DLq2q25N8lA0MN+yPHbCkQamVTL1MsAvYVVW3d69vYBTIjyY5DqD7umfWWg1gSYPS1xhwVX0b+FaS53erzgbuB24CtnTrtgA3zlqrQxCSBqVqYme7HpcCn0xyBLATeCOjxvX6JJcADwEXzrpxA1jSoPR5IUZV3QOcup+3zu5j+wawpEFZWe61A54rA1jSoExxcu2gYQBLGhQDWJIaqcW5HbABLGlY7IAlqZGep6HNlQEsaVCWnQUhSW3YAUtSI44BS1IjzoKQpEbsgCWpkeWVxbnJowEsaVAcgpCkRlYWaBbExF49yQuSnJ3kyH3WnzO/siRpNlWZemltzQBO8jZGd3u/FLg3yfljb//lPAuTpFlUTb+0NqkD/gPglKq6AHgF8GdJLuveW/XXx/iTRq+85tp+KpWkKaxUpl5amzQGfGhV/Qigqr6Z5BXADUmeyxoBPP6k0Scf23kQ/J6R9FSxSLMgJlX67SQn733RhfGrgWcBvz7PwiRpFrWOpbVJHfDFwNL4iqpaAi5O8ndzq0qSZnQwDC1Ma80Arqpda7z3z/2XI0kbczDMbpiW84AlDUqPD0WeOwNY0qDU6vMDDjoGsKRBWXIIQpLasAOWpEYcA5akRuyAJakRO2BJamTZDliS2ligJxIZwJKGZcUOWJLaOBhusjMtA1jSoHgSTpIaWYlDEJLUxHLrAtZhcW4dL0lTWMn0yzSSHJrk7iSf616flOT2JA8k+VSSI2at1QCWNCgrZOplSpcBO8Zevx/4cFVtBr4HXDJrrQawpEHp85FESTYBrwKu7F4HOAu4ofvIduCCWWs1gCUNynqGIMaf4N4tW/fZ3EeAd/LTyRU/DzzePZoNYBdw/Ky1ehJO0qCsZxra+BPc95Xk1cCeqrqreyI87P9p8DNPPTaAJQ3Kcn+z0M4EXpPkPOBpwDMZdcRHJTms64I3AY/MugOHICQNyso6lrVU1buralNVnQi8DvhSVf0ucCvw2u5jW4AbZ63VAJY0KH0F8BreBfxRkgcZjQlfNeuG5j4E8fun/PG8d3HAXX3XB1qXIGkV83gkXFXdBtzWfb8TOK2P7ToGLGlQvBeEJDWySJciG8CSBsUbsktSIw5BSFIjBrAkNeITMSSpEceAJakRZ0FIUiMrCzQIYQBLGhRPwklSI4vT/xrAkgbGDliSGlnK4vTABrCkQVmc+DWAJQ2MQxCS1IjT0CSpkcWJXwNY0sA4BCFJjSwvUA9sAEsaFDtgSWqk7IAlqQ07YElqxGloktTI4sSvASxpYJYWKIInBnCS04CqqjuSvAg4B/hGVX1h7tVJ0joN5iRckiuAc4HDktwMnA7cBlye5KVV9Rer/NxWYCvA6ceczOYjT+q1aElazZBOwr0WOBn4GeDbwKaq+kGSvwJuB/YbwFW1DdgGcNFzf2dxfh1JWniD6YCBpapaBn6c5D+r6gcAVfU/SRbpF42kp4hFCqZJAfxEkmdU1Y+BU/auTPJzLNZxSnqKWK7hdMAvr6qfAFTVeOAeDmyZW1WSNKPBzAPeG777Wf8Y8NhcKpKkDRjSGLAkLZRFGhs1gCUNyiINQRzSugBJ6lOt47+1JDkhya1JdiS5L8ll3fpjktyc5IHu69Gz1moASxqU5aqplwmWgHdU1QuBM4C3dFcDXw7cUlWbgVu61zMxgCUNygo19bKWqtpdVV/rvv8hsAM4Hjgf2N59bDtwway1GsCSBmVlHUuSrUnuHFu27m+bSU4EXsroCuBjq2o3jEIaeM6stXoSTtKgrGca2vhtE1aT5EjgM8Dbu1sxbKzAMQawpEHpcxZEksMZhe8nq+qz3epHkxxXVbuTHAfsmXX7DkFIGpSqmnpZS0at7lXAjqr60NhbN/HTK4G3ADfOWqsdsKRB6fGx9GcCFwH/nuSebt2fAu8Drk9yCfAQcOGsOzCAJQ1KX0MQVfVPwGoDvmf3sQ8DWNKgTBpaOJgYwJIGZZEuRTaAJQ2Kd0OTpEaGdEN2SVooDkFIUiMGsCQ14iwISWrEDliSGnEWhCQ1slyL81S4uQfwPz5+/7x3ccAtffGq1iXMxcrOb7YuoXcfu6q/WwceTH5hqXUF83Hxw5/Y8DYcA5akRhwDlqRGHAOWpEZWHIKQpDbsgCWpEWdBSFIjDkFIUiMOQUhSI3bAktSIHbAkNbJcy61LmJoBLGlQvBRZkhrxUmRJasQOWJIacRaEJDXiLAhJasRLkSWpEceAJakRx4AlqRE7YElqxHnAktSIHbAkNeIsCElqxJNwktTIIg1BHNK6AEnqU63jv0mSnJPkP5I8mOTyvmtddwAnuabvIiSpL1U19bKWJIcCHwPOBV4EvD7Ji/qsdc0hiCQ37bsK+K0kRwFU1Wv6LEaSNqrHMeDTgAeraidAkuuA84H7+9rBpDHgTd3OrgSKUQCfCnxwrR9KshXY2r18c1Vt22CdU0my9UDt60Aa4nEdqGN655/Pew//n39W7S098XCm/ew+WQWwbexYjwe+NfbeLuD0jVc4tv+12vAkhwCXAecBf1JV9yTZWVXP67OIviS5s6pObV1H34Z4XEM8JhjmcQ3xmKaR5ELglVX1pu71RcBpVXVpX/tYswOuqhXgw0k+3X19dNLPSNJA7AJOGHu9CXikzx1MFaZVtQu4MMmrgB/0WYAkHaTuADYnOQl4GHgd8IY+d7CubraqPg98vs8CerYw41TrNMTjGuIxwTCPa4jHNFFVLSV5K/APwKHA1VV1X5/7WHMMWJI0P16IIUmNGMCS1MggAnjelwu2kOTqJHuS3Nu6lj4lOSHJrUl2JLkvyWWta9qoJE9L8tUk/9Yd03ta19SnJIcmuTvJ51rXMjQLH8AH4nLBRj4OnNO6iDlYAt5RVS8EzgDeMoA/r58AZ1XVS4CTgXOSnNG4pj5dBuxoXcQQLXwAM3a5YFU9Aey9XHChVdWXge+2rqNvVbW7qr7Wff9DRn+xj29b1cbUyI+6l4d3yyDObifZBLyK0dWw6tkQAnh/lwsu9F/op4okJwIvBW5vW8nGdf9MvwfYA9xcVQt/TJ2PAO8EFucu5wtkCAG8v+u+B9F9DFmSI4HPAG+vqoW/uKeqlqvqZEZXS52W5MWta9qoJK8G9lTVXa1rGaohBPDcLxdUv5Iczih8P1lVn21dT5+q6nHgNoYxfn8m8Jok32Q0tHdWkk+0LWlYhhDA/3e5YJIjGF0uuO9tNHWQSBLgKmBHVX2odT19SPLsvbdoTfJ04LeBb7StauOq6t1VtamqTmT09+pLVfV7jcsalIUP4KpaAvZeLrgDuL7vywVbSHIt8K/A85PsSnJJ65p6ciZwEaNu6p5uOa91URt0HHBrkq8zaghuriqnbGkiL0WWpEYWvgOWpEVlAEtSIwawJDViAEtSIwawJDViAEtSIwawJDXyv3XARBCyE468AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heatmap of recalls\n",
    "mat = sns.heatmap(M, vmin=0, vmax=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUC (one config for now)\n",
    "unknown, binding = scores[0]\n",
    "total = unknown + binding\n",
    "plt.hist(total, 50, histtype='step', density=True, cumulative=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test other NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TwoLayer()\n",
    "# model.apply(weights_init)\n",
    "# model.cuda()\n",
    "# print(\"Training...\")\n",
    "# sgd(t=1000, gamma=0.01, lamb=0.01)\n",
    "# print(\"Evaluating...\")\n",
    "# # use for AUC\n",
    "# recall, binding_outputs = recall_eval(50)\n",
    "# unknown_outputs = evaluate(500)\n",
    "# # use for heatmap\n",
    "# print(\"Recall with gamma: \"+ str(0.01) + \" , lambda: \" + str(0.01) + \" recall: \", '%.2f'% recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "walnutree",
   "language": "python",
   "name": "walnutree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
