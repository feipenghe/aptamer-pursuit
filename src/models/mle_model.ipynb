{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_list = ['A', 'C', 'G', 'T'] #nucleic acids\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y'] #amino acids\n",
    "NNK_freq = [0.09375]*3 + [0.0625]*5 + [0.03125]*13 #freq of 21 NNK codons including the stop codon\n",
    "sum_20 = 0.0625*5 + 0.09375*3 + 0.03125*12 #sum of freq without the stop codon\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*12 #normalize freq for 20 codons\n",
    "pvals = [0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11 + \\\n",
    "        [1- sum([0.09375/sum_20]*3 + [0.0625/sum_20]*5 + [0.03125/sum_20]*11)] \n",
    "        #adjust sum to 1 due to numerical issue\n",
    "aa_dict = dict(zip(aa_list, pvals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_dataset_file = \"../data/aptamer_dataset.json\"\n",
    "\n",
    "def construct_dataset():\n",
    "    with open(aptamer_dataset_file, 'r') as f:\n",
    "        aptamer_data = json.load(f)\n",
    "    full_dataset = []\n",
    "    aptamers = []\n",
    "    peptides = []\n",
    "    for aptamer in aptamer_data:\n",
    "        peptides = aptamer_data[aptamer]\n",
    "        if aptamer == \"CTTTGTAATTGGTTCTGAGTTCCGTTGTGGGAGGAACATG\": #took out aptamer control\n",
    "            continue\n",
    "        for peptide, _ in peptides:\n",
    "            peptide = peptide.replace(\"_\", \"\") #removed stop codons\n",
    "            if \"RRRRRR\" in peptide: #took out peptide control\n",
    "                continue\n",
    "            if len(aptamer) == 40 and len(peptide) == 8: #making sure right length\n",
    "                full_dataset.append((aptamer, peptide))\n",
    "    full_dataset = list(set(full_dataset)) #removed duplicates\n",
    "    for pair in full_dataset:\n",
    "        aptamers.append(pair[0])\n",
    "        peptides.append(pair[1])\n",
    "    return full_dataset, aptamers, peptides "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_set):\n",
    "        super(TrainDataset, self).__init__() \n",
    "        self.training_set = training_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.training_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.training_set[idx]\n",
    "        return aptamer, peptide\n",
    "    \n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, test_set):\n",
    "        super(TestDataset, self).__init__() \n",
    "        self.test_set = test_set\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.test_set[idx]\n",
    "        return aptamer, peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset, aptamers, peptides = construct_dataset()\n",
    "n = len(full_dataset)\n",
    "training_set = full_dataset[:int(0.8*n)]\n",
    "test_set = full_dataset[int(0.8*n):]\n",
    "train_dataset = TrainDataset(training_set)\n",
    "test_dataset = TestDataset(test_set)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def one_hot(sequence_list, seq_type='peptide'):\n",
    "    if seq_type == 'peptide':\n",
    "        letters = aa_list\n",
    "    else:\n",
    "        letters = na_list\n",
    "    \n",
    "    one_hot = np.zeros((len(sequence_list), len(sequence_list[0]), len(letters)))\n",
    "    \n",
    "    for j in range(len(sequence_list)):\n",
    "        sequence = sequence_list[j]\n",
    "        for i in range(len(sequence)):\n",
    "            element = sequence[i]\n",
    "            idx = letters.index(element)\n",
    "            one_hot[j][i][idx] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(40, 20, 1)\n",
    "        self.cnn_apt_2 = nn.Conv2d(20, 10, 1)\n",
    "        self.cnn_apt_3 = nn.Conv2d(10, 1, 1)\n",
    "        self.fc_apt_1 = nn.Linear(160, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv2d(8, 4, 1)\n",
    "        self.cnn_pep_2 = nn.Conv2d(4, 3, 1)\n",
    "        self.fc_pep_1 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "                \n",
    "        self.sequential_pep = nn.Sequential(self.cnn_pep_1,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_pep_2)\n",
    "        \n",
    "        self.sequential_apt = nn.Sequential(self.cnn_apt_1, \n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_2, \n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.sequential_apt(apt).cuda()\n",
    "        pep = self.sequential_pep(pep).cuda()\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(40, 10, (3,1))\n",
    "        self.cnn_pep_1 = nn.Conv2d(8, 4, (2,1))\n",
    "        self.pool = nn.MaxPool2d(1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "                \n",
    "        self.sequential_pep = nn.Sequential(self.cnn_pep_1,\n",
    "                                            self.relu, \n",
    "                                            self.pool)\n",
    "        \n",
    "        self.sequential_apt = nn.Sequential(self.cnn_apt_1, \n",
    "                                            self.relu, \n",
    "                                            self.pool)\n",
    "        \n",
    "        self.fc1 = nn.Linear(96, 1)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.sequential_apt(apt).cuda()\n",
    "        pep = self.sequential_pep(pep).cuda()\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample x from P_X (assume peptides follow NNK)\n",
    "def get_x():\n",
    "    x_idx = np.random.choice(20, 7, p=pvals)\n",
    "    x = \"M\"\n",
    "    for i in x_idx:\n",
    "        x += aa_list[i]\n",
    "    return x\n",
    "\n",
    "# Sample y from P_Y (assume apatamers follow uniform)\n",
    "def get_y():\n",
    "    y_idx = np.random.randint(0, 4, 40)\n",
    "    y = \"\"\n",
    "    for i in y_idx:\n",
    "        y += na_list[i]\n",
    "    return y\n",
    "\n",
    "# Generate uniformly from S without replacement\n",
    "def get_xy(k):\n",
    "    samples = [full_dataset[i] for i in np.random.choice(len(full_dataset), k, replace=False)]\n",
    "    return samples\n",
    "\n",
    "# S' contains S with double the size of S (domain for Importance Sampling)\n",
    "def get_S_prime(k):\n",
    "    S_prime = full_dataset[:]\n",
    "    for _ in range(k):\n",
    "        S_prime.append((get_y(), get_x()))\n",
    "    return list(set(S_prime))\n",
    "\n",
    "# Sample from S' without replacement\n",
    "def get_xy_prime(k):\n",
    "    samples = [S_prime[i] for i in np.random.choice(len(S_prime), k, replace=False)]\n",
    "    return samples\n",
    "\n",
    "# Returns pmf of a peptide\n",
    "def get_x_pmf(x):\n",
    "    pmf = 1\n",
    "    for char in x[1:]: #skips first char \"M\"\n",
    "        pmf *= aa_dict[char]\n",
    "    return pmf\n",
    "\n",
    "# Returns pmf of an aptamer\n",
    "def get_y_pmf():\n",
    "    return 0.25**40\n",
    "\n",
    "S_prime = get_S_prime(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(type=\"original\"):\n",
    "    if type == \"original\":\n",
    "        xy = get_xy(1)[0]\n",
    "    else:\n",
    "        xy = get_xy_prime(1)[0]\n",
    "    x = one_hot(xy[0], seq_type='aptamer') \n",
    "    y = one_hot(xy[1], seq_type='peptide') \n",
    "    #x = torch.FloatTensor(np.reshape(x, (1, x.shape[0], x.shape[1], x.shape[2]))) #(1, 40, 1, 4) original\n",
    "    x = torch.FloatTensor(np.reshape(x, (1, x.shape[0], x.shape[2], x.shape[1]))) # (1, 40, 4, 1) simple\n",
    "    #y = torch.FloatTensor(np.reshape(y, (1, y.shape[0], y.shape[1], y.shape[2]))) #(1, 8, 1, 20) original\n",
    "    y = torch.FloatTensor(np.reshape(y, (1, y.shape[0], y.shape[2], y.shape[1]))) #(1, 8, 20, 1) simple\n",
    "    x.requires_grad=True\n",
    "    y.requires_grad=True\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    out = model(x, y)\n",
    "    return xy, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(t=1000, #num of iter\n",
    "        lamb=1e-5, #hyperparam\n",
    "        gamma=1e-4): #step size\n",
    "    \n",
    "    model.train()\n",
    "    for a, _ in enumerate(tqdm.tqdm(range(t))):\n",
    "        xy, out = update()\n",
    "        out.retain_grad()\n",
    "        log_out = torch.log(out)\n",
    "        log_out.retain_grad()\n",
    "        model.zero_grad()\n",
    "        log_out.backward()\n",
    "        \n",
    "        xy_prime, out_prime = update(\"prime\")\n",
    "        out_prime = out_prime * get_x_pmf(xy_prime[0]) * get_y_pmf() * 2 * n\n",
    "        out_prime.retain_grad()\n",
    "        model.zero_grad()\n",
    "        out_prime.backward()\n",
    "        \n",
    "        const = 0 if xy_prime in full_dataset else 1 #indicator\n",
    "        g = log_out.grad - lamb*const*out_prime.grad\n",
    "        g = g.item()\n",
    "        \n",
    "        #Update the weights according to SGD\n",
    "        for param in model.parameters():\n",
    "            param.data += gamma * g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval on test set of size k (split from our dataset)\n",
    "def recall_eval(k):\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    binding_outputs = []\n",
    "    model.eval()\n",
    "    for _, (aptamer, peptide) in enumerate(tqdm.tqdm(test_loader)):\n",
    "        if count > k:\n",
    "            break\n",
    "        pep = one_hot(peptide, seq_type='peptide')\n",
    "        apt = one_hot(aptamer, seq_type='aptamer')\n",
    "        pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[1], pep.shape[2], pep.shape[0]))).cuda() #original\n",
    "        apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[1], apt.shape[2], apt.shape[0]))).cuda() #original (1, 40, 4, 1)\n",
    "        output = model(apt, pep).cpu().detach().numpy().flatten()[0]\n",
    "        binding_outputs.append('%.2f'% output)\n",
    "        if output > 0.5:\n",
    "            correct += 1\n",
    "        count += 1\n",
    "    recall = 100*correct/count #recall rate of k samples\n",
    "    return recall, binding_outputs #list of k outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(apt, pep): \n",
    "    apt = one_hot(apt, seq_type='aptamer') #(40, 1, 4)\n",
    "    pep = one_hot(pep, seq_type='peptide') #(8, 1, 20)\n",
    "    apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[0], apt.shape[2], apt.shape[1]))).cuda() #(1, 40, 4, 1) original\n",
    "    pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[0], pep.shape[2], pep.shape[1]))).cuda() #(1, 8, 20, 1) original\n",
    "    return apt, pep\n",
    "\n",
    "# Eval on m new unseen pairs(not in our dataset)\n",
    "def evaluate(m):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    count = 0\n",
    "    for _ in range(m):\n",
    "        x, y = get_x(), get_y()\n",
    "        apt, pep = convert(y, x)\n",
    "        output = model(apt, pep).cpu().detach().numpy().flatten()[0]\n",
    "        outputs.append('%.2f'% output)\n",
    "        if output < 0.5:\n",
    "            count += 1\n",
    "    precision = 100 * count / m\n",
    "    return precision, outputs #list of m outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:19,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.12it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.1 , lambda: 0.1 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.31it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.1 , lambda: 0.01 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.41it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.1 , lambda: 0.001 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.30it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.1 , lambda: 0.0001 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.89it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.1 , lambda: 1e-05 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.68it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.01 , lambda: 0.1 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.13it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.01 , lambda: 0.01 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  8.02it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.01 , lambda: 0.001 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.50it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.01 , lambda: 0.0001 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  8.00it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.01 , lambda: 1e-05 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.33it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.001 , lambda: 0.1 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.38it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.001 , lambda: 0.01 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.44it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.001 , lambda: 0.001 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.26it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.001 , lambda: 0.0001 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.35it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.001 , lambda: 1e-05 recall:  100.00 precision:  0.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.60it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.0001 , lambda: 0.1 recall:  74.19 precision:  32.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.30it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.0001 , lambda: 0.01 recall:  96.77 precision:  2.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.63it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.0001 , lambda: 0.001 recall:  67.74 precision:  47.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.35it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.0001 , lambda: 0.0001 recall:  96.77 precision:  7.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.02it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 0.0001 , lambda: 1e-05 recall:  90.32 precision:  22.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.38it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 1e-05 , lambda: 0.1 recall:  58.06 precision:  41.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.38it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 1e-05 , lambda: 0.01 recall:  41.94 precision:  59.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.49it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 1e-05 , lambda: 0.001 recall:  67.74 precision:  42.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.68it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 1e-05 , lambda: 0.0001 recall:  70.97 precision:  48.00\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.56it/s]\n",
      "  0%|          | 0/118262 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Recall with gamma: 1e-05 , lambda: 1e-05 recall:  0.00 precision:  99.00\n"
     ]
    }
   ],
   "source": [
    "gammas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "lambdas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "recalls = []\n",
    "precisions = []\n",
    "scores = []\n",
    "\n",
    "m = int(1e2) # number of unknown samples\n",
    "k = int(30) # number of binding samples (test set size is 118262, k is just some limit we set)\n",
    "\n",
    "M = np.zeros((len(gammas), len(lambdas)))\n",
    "for g in range(len(gammas)):\n",
    "    for l in range(len(lambdas)):\n",
    "        model = SimpleConvNet()\n",
    "        model.apply(weights_init)\n",
    "        model.cuda()\n",
    "        print(\"Training...\")\n",
    "        sgd(t=100, gamma=gammas[g], lamb=lambdas[l])\n",
    "        print(\"Evaluating...\")\n",
    "        # use for AUC\n",
    "        recall, binding_outputs = recall_eval(k)\n",
    "        precision, unknown_outputs = evaluate(m)\n",
    "        scores.append((unknown_outputs, binding_outputs))\n",
    "        # use for heatmap\n",
    "        M[g][l] += recall\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        print(\"Recall with gamma: \"+ str(gammas[g]) + \" , lambda: \" + str(lambdas[l]) + \" recall: \", '%.2f'% recall\\\n",
    "             + \" precision: \", '%.2f'% precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma:  0.00001 Lambda:  0.00001 Recall:  0.00 99.00\n",
      "Gamma:  0.00001 Lambda:  0.01000 Recall:  41.94 59.00\n",
      "Gamma:  0.00001 Lambda:  0.10000 Recall:  58.06 41.00\n",
      "Gamma:  0.00010 Lambda:  0.00100 Recall:  67.74 47.00\n",
      "Gamma:  0.00001 Lambda:  0.00100 Recall:  67.74 42.00\n",
      "Gamma:  0.00001 Lambda:  0.00010 Recall:  70.97 48.00\n",
      "Gamma:  0.00010 Lambda:  0.10000 Recall:  74.19 32.00\n",
      "Gamma:  0.00010 Lambda:  0.00001 Recall:  90.32 22.00\n",
      "Gamma:  0.00010 Lambda:  0.01000 Recall:  96.77 2.00\n",
      "Gamma:  0.00010 Lambda:  0.00010 Recall:  96.77 7.00\n",
      "Gamma:  0.10000 Lambda:  0.10000 Recall:  100.00 0.00\n",
      "Gamma:  0.10000 Lambda:  0.01000 Recall:  100.00 0.00\n",
      "Gamma:  0.10000 Lambda:  0.00100 Recall:  100.00 0.00\n",
      "Gamma:  0.10000 Lambda:  0.00010 Recall:  100.00 0.00\n",
      "Gamma:  0.10000 Lambda:  0.00001 Recall:  100.00 0.00\n",
      "Gamma:  0.01000 Lambda:  0.10000 Recall:  100.00 0.00\n",
      "Gamma:  0.01000 Lambda:  0.01000 Recall:  100.00 0.00\n",
      "Gamma:  0.01000 Lambda:  0.00100 Recall:  100.00 0.00\n",
      "Gamma:  0.01000 Lambda:  0.00010 Recall:  100.00 0.00\n",
      "Gamma:  0.01000 Lambda:  0.00001 Recall:  100.00 0.00\n",
      "Gamma:  0.00100 Lambda:  0.10000 Recall:  100.00 0.00\n",
      "Gamma:  0.00100 Lambda:  0.01000 Recall:  100.00 0.00\n",
      "Gamma:  0.00100 Lambda:  0.00100 Recall:  100.00 0.00\n",
      "Gamma:  0.00100 Lambda:  0.00010 Recall:  100.00 0.00\n",
      "Gamma:  0.00100 Lambda:  0.00001 Recall:  100.00 0.00\n"
     ]
    }
   ],
   "source": [
    "# Table of recalls with different params\n",
    "idx = sorted(range(len(recalls)), key=lambda k: recalls[k])\n",
    "for i in idx:\n",
    "    g = gammas[i//len(gammas)]\n",
    "    l = lambdas[i%len(lambdas)]\n",
    "    print(\"Gamma: \", \"%.5f\" % g, \"Lambda: \", \"%.5f\" % l, \"Recall: \", \"%.2f\" % recalls[i], \"%.2f\" % precisions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.50', '0.56', '0.50', '0.50', '0.53', '0.42', '0.45', '0.53', '0.64', '0.52', '0.52', '0.50', '0.45', '0.45', '0.56', '0.55', '0.42', '0.55', '0.52', '0.48', '0.52', '0.54', '0.50', '0.46', '0.52', '0.47', '0.49', '0.47', '0.54', '0.50', '0.49', '0.53', '0.65', '0.64', '0.58', '0.65', '0.47', '0.50', '0.52', '0.46', '0.43', '0.59', '0.41', '0.55', '0.45', '0.54', '0.50', '0.39', '0.39', '0.54', '0.51', '0.47', '0.43', '0.62', '0.48', '0.70', '0.63', '0.59', '0.50', '0.57', '0.47', '0.57', '0.56', '0.46', '0.54', '0.46', '0.52', '0.48', '0.42', '0.38', '0.31', '0.40', '0.42', '0.52', '0.40', '0.55', '0.56', '0.63', '0.40', '0.59', '0.49', '0.38', '0.48', '0.63', '0.43', '0.50', '0.65', '0.51', '0.43', '0.49', '0.46', '0.53', '0.47', '0.49', '0.53', '0.60', '0.50', '0.59', '0.45', '0.47']\n"
     ]
    }
   ],
   "source": [
    "print(scores[-2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of recalls\n",
    "mat = sns.heatmap(M, vmin=0, vmax=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC (one config for now)\n",
    "unknown, binding = scores[0]\n",
    "total = unknown + binding\n",
    "plt.hist(total, 50, histtype='step', density=True, cumulative=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test other NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleConvNet()\n",
    "model.apply(weights_init)\n",
    "model.cuda()\n",
    "print(\"Training...\")\n",
    "sgd(t=1000, gamma=0.01, lamb=0.01)\n",
    "print(\"Evaluating...\")\n",
    "# use for AUC\n",
    "recall, binding_outputs = recall_eval(50)\n",
    "unknown_outputs = evaluate(500)\n",
    "# use for heatmap\n",
    "print(\"Recall with gamma: \"+ str(0.01) + \" , lambda: \" + str(0.01) + \" recall: \", '%.2f'% recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "walnutree",
   "language": "python",
   "name": "walnutree"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
