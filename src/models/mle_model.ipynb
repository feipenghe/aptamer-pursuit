{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "random.seed(42)\n",
    "device = torch.device(\"cudo:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Take out controls and generate a new dataset\n",
    "aptamer_dataset_file = \"../data/aptamer_dataset.json\"\n",
    "clustered_dataset_file = \"../data/clustered_aptamer_dataset.json\"\n",
    "\n",
    "def construct_dataset():\n",
    "    with open(clustered_dataset_file, 'r') as f:\n",
    "        aptamer_data = json.load(f)\n",
    "    full_dataset = []\n",
    "    for aptamer in aptamer_data:\n",
    "        peptides = aptamer_data[aptamer]\n",
    "        for peptide, _ in peptides:\n",
    "            peptide = peptide.replace(\"_\", \"\")\n",
    "            if len(aptamer) == 40 and len(peptide) == 7:\n",
    "                peptide = \"M\" + peptide\n",
    "                full_dataset.append((aptamer, peptide))\n",
    "    return list(set(full_dataset)) #removed duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40672\n"
     ]
    }
   ],
   "source": [
    "full_dataset = construct_dataset()\n",
    "aptamers = [p[0] for p in full_dataset]\n",
    "peptides = [p[1] for p in full_dataset]\n",
    "training_set = full_dataset[:int(0.8*len(full_dataset))]\n",
    "test_set = full_dataset[int(0.8*len(full_dataset)):]\n",
    "print(str(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, training_set):\n",
    "        super(TrainDataset, self).__init__() \n",
    "        self.training_set = training_set\n",
    "        n = len(training_set)\n",
    "        self.training_set = training_set[:n-n%BATCH_SIZE]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.training_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.training_set[idx]\n",
    "        return aptamer, peptide\n",
    "    \n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, test_set):\n",
    "        super(TestDataset, self).__init__() \n",
    "        self.test_set = test_set\n",
    "        n = len(test_set)\n",
    "        self.test_set = test_set[:n-n%BATCH_SIZE]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_set)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        aptamer, peptide = self.test_set[idx]\n",
    "        return aptamer, peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(training_set)\n",
    "test_dataset = TestDataset(test_set)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_list = ['A', 'C', 'G', 'T']\n",
    "aa_list = ['R', 'L', 'S', 'A', 'G', 'P', 'T', 'V', 'N', 'D', 'C', 'Q', 'E', 'H', 'I', 'K', 'M', 'F', 'W', 'Y']\n",
    "pvals = [0.089]*3 + [0.065]*5 + [0.034]*12\n",
    "aa_dict = dict(zip(aa_list, pvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes a peptide and aptamer sequence and converts to one-hot matrix\n",
    "def one_hot(sequence_list, seq_type='peptide'):\n",
    "    if seq_type == 'peptide':\n",
    "        letters = aa_list\n",
    "    else:\n",
    "        letters = na_list\n",
    "    \n",
    "    one_hot = np.zeros((len(sequence_list), len(sequence_list[0]), len(letters)))\n",
    "    \n",
    "    for j in range(len(sequence_list)):\n",
    "        sequence = sequence_list[j]\n",
    "        for i in range(len(sequence)):\n",
    "            element = sequence[i]\n",
    "            idx = letters.index(element)\n",
    "            one_hot[j][i][idx] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cnn_apt_1 = nn.Conv2d(40, 20, 1)\n",
    "        self.cnn_apt_2 = nn.Conv2d(20, 10, 1)\n",
    "        self.cnn_apt_3 = nn.Conv2d(10, 1, 1)\n",
    "        self.fc_apt_1 = nn.Linear(160, 1)\n",
    "        \n",
    "        self.cnn_pep_1 = nn.Conv2d(8, 4, 1)\n",
    "        self.cnn_pep_2 = nn.Conv2d(4, 3, 1)\n",
    "        self.fc_pep_1 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.sequential_pep = nn.Sequential(self.cnn_pep_1,\n",
    "                                            #self.dropout,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_pep_2)\n",
    "        \n",
    "        self.sequential_apt = nn.Sequential(self.cnn_apt_1, \n",
    "                                            #self.dropout,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_2, \n",
    "                                            #self.dropout,\n",
    "                                            self.relu, \n",
    "                                            self.pool, \n",
    "                                            self.cnn_apt_3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, BATCH_SIZE)\n",
    "        \n",
    "    def forward(self, apt, pep):\n",
    "        apt = self.sequential_apt(apt)\n",
    "        pep = self.sequential_pep(pep)\n",
    "        \n",
    "        apt = apt.view(-1, 1).T\n",
    "        pep = pep.view(-1, 1).T\n",
    "        \n",
    "        x = torch.cat((apt, pep), 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (cnn_apt_1): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cnn_apt_2): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cnn_apt_3): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc_apt_1): Linear(in_features=160, out_features=1, bias=True)\n",
       "  (cnn_pep_1): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cnn_pep_2): Conv2d(4, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc_pep_1): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (sequential_pep): Sequential(\n",
       "    (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(4, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (sequential_apt): Sequential(\n",
       "    (0): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (fc1): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias.data)\n",
    "\n",
    "model.apply(weights_init)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample x from P_X (assume peptides follow NNK)\n",
    "def get_x():\n",
    "    x_idx = np.random.choice(20, 7, p=pvals)\n",
    "    x = \"M\"\n",
    "    for i in x_idx:\n",
    "        x += aa_list[i]\n",
    "    return x\n",
    "\n",
    "# Sample y from P_Y (assume apatamers follow uniform)\n",
    "def get_y():\n",
    "    y_idx = np.random.randint(0, 4, 40)\n",
    "    y = \"\"\n",
    "    for i in y_idx:\n",
    "        y += na_list[i]\n",
    "    return y\n",
    "\n",
    "# Generate uniformly from S without replacement\n",
    "def get_xy(k):\n",
    "    samples = [full_dataset[i] for i in np.random.choice(len(full_dataset), k, replace=False)]\n",
    "    return samples\n",
    "\n",
    "# S' contains S with double the size of S (domain for Importance Sampling)\n",
    "def get_S_prime(k):\n",
    "    S_prime = full_dataset[:]\n",
    "    for _ in range(k):\n",
    "        S_prime.append((get_y(), get_x()))\n",
    "    S_prime_new = S_prime[:]\n",
    "    S_prime_new = S_prime_new[-n:]\n",
    "    return list(set(S_prime)), S_prime_new\n",
    "\n",
    "# Sample from S' without replacement\n",
    "def get_xy_prime(k):\n",
    "    samples = [S_prime[i] for i in np.random.choice(len(S_prime), k, replace=False)]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test whether naive sampling would generate pairs in S -- nope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Size of S: ', 203359)\n",
      "('Size of naively sampled dataset: ', 203359)\n",
      "('Size of set difference: ', 203359)\n"
     ]
    }
   ],
   "source": [
    "n = len(full_dataset)\n",
    "S_prime, S_prime_new = get_S_prime(n)\n",
    "print(\"Size of S: \", n)\n",
    "print(\"Size of naively sampled dataset: \", len(S_prime_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivates importance sampling in SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns pmf of a peptide\n",
    "def get_x_pmf(x):\n",
    "    pmf = 1\n",
    "    for char in x[1:]: #skips first char \"M\"\n",
    "        pmf *= aa_dict[char]\n",
    "    return pmf\n",
    "\n",
    "# Returns pmf of an aptamer\n",
    "def get_y_pmf():\n",
    "    return 0.25**40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(t=500, #num of iter\n",
    "        lamb=1e-5, #hyperparam\n",
    "        gamma=1e-5): #step size\n",
    "    \n",
    "    model.train()\n",
    "    for a, _ in enumerate(tqdm.tqdm(range(t))):\n",
    "        # From our full dataset\n",
    "        xy = get_xy(1)[0] #sample (x, y) from S\n",
    "        x = one_hot(xy[0], seq_type='aptamer') \n",
    "        y = one_hot(xy[1], seq_type='peptide') \n",
    "        x = torch.FloatTensor(np.reshape(x, (1, x.shape[0], x.shape[1], x.shape[2])))\n",
    "        y = torch.FloatTensor(np.reshape(y, (1, y.shape[0], y.shape[1], y.shape[2])))\n",
    "        x.requires_grad=True\n",
    "        y.requires_grad=True\n",
    "        out = model(x, y)\n",
    "        out.retain_grad()\n",
    "        model.zero_grad()\n",
    "        out.backward()\n",
    "        \n",
    "        # From the generated dataset\n",
    "        xy_prime = get_xy_prime(1)[0] #sample (x', y') from S'\n",
    "        x_prime = one_hot(xy_prime[0], seq_type='aptamer') \n",
    "        y_prime = one_hot(xy_prime[1], seq_type='peptide')\n",
    "        x_prime = torch.FloatTensor(np.reshape(x_prime, (1, x_prime.shape[0], x_prime.shape[1], x_prime.shape[2])))\n",
    "        y_prime = torch.FloatTensor(np.reshape(y_prime, (1, y_prime.shape[0], y_prime.shape[1], y_prime.shape[2])))\n",
    "        x_prime.requires_grad=True\n",
    "        y_prime.requires_grad=True\n",
    "        \n",
    "        out_prime = model(x_prime, y_prime)\n",
    "        out_prime = out_prime * get_x_pmf(xy_prime[0]) * get_y_pmf() * 2 * n\n",
    "        out_prime.retain_grad()\n",
    "        model.zero_grad()\n",
    "        out_prime.backward()\n",
    "        \n",
    "        const = 0 if xy_prime in full_dataset else 1 #indicator\n",
    "        g = torch.log(out.grad) - lamb*const*out_prime.grad\n",
    "        g = g.item()\n",
    "        \n",
    "        # Update the weights according to SGD\n",
    "        for param in model.parameters():\n",
    "            param.data += gamma * g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd(t=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall test\n",
    "def evaluate():\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    model.eval()\n",
    "    for batch_idx, (aptamer, peptide) in enumerate(tqdm.tqdm(test_loader)):\n",
    "        pep = one_hot(peptide, seq_type='peptide')\n",
    "        apt = one_hot(aptamer, seq_type='aptamer')\n",
    "\n",
    "        pep = torch.FloatTensor(np.reshape(pep, (1, pep.shape[1], pep.shape[2], pep.shape[0])))\n",
    "        apt = torch.FloatTensor(np.reshape(apt, (1, apt.shape[1], apt.shape[2], apt.shape[0])))\n",
    "\n",
    "        output = model(apt, pep).detach().numpy().flatten()\n",
    "        for i in range(output.shape[0]):\n",
    "            o = output[i]\n",
    "            if o > 0.5:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1\n",
    "        \n",
    "    return (100* correct/(correct + incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:40<00:00,  6.22it/s]\n",
      "  0%|          | 60/40672 [00:00<01:08, 596.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:02<00:00, 648.01it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 1e-05 , lambda: 0.1 recall: ', 70)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:36<00:00,  6.39it/s]\n",
      "  0%|          | 37/40672 [00:00<01:50, 366.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:00<00:00, 675.48it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 1e-05 , lambda: 0.01 recall: ', 47)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:31<00:00,  6.62it/s]\n",
      "  0%|          | 86/40672 [00:00<00:47, 855.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:00<00:00, 672.66it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 1e-05 , lambda: 0.001 recall: ', 40)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:37<00:00,  6.35it/s]\n",
      "  0%|          | 66/40672 [00:00<01:01, 655.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:57<00:00, 710.74it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 1e-05 , lambda: 0.0001 recall: ', 87)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:31<00:00,  6.61it/s]\n",
      "  0%|          | 66/40672 [00:00<01:02, 654.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:57<00:00, 702.74it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 1e-05 , lambda: 1e-05 recall: ', 39)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:33<00:00,  6.50it/s]\n",
      "  0%|          | 47/40672 [00:00<01:27, 465.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:01<00:00, 666.59it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.0001 , lambda: 0.1 recall: ', 24)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:38<00:00,  6.31it/s]\n",
      "  0%|          | 46/40672 [00:00<01:28, 458.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:55<00:00, 733.88it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.0001 , lambda: 0.01 recall: ', 1)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:44<00:00,  6.07it/s]\n",
      "  0%|          | 49/40672 [00:00<01:23, 487.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:00<00:00, 677.82it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.0001 , lambda: 0.001 recall: ', 58)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:37<00:00,  6.35it/s]\n",
      "  0%|          | 57/40672 [00:00<01:11, 565.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:00<00:00, 667.68it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.0001 , lambda: 0.0001 recall: ', 62)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:35<00:00,  6.43it/s]\n",
      "  0%|          | 77/40672 [00:00<00:53, 764.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:58<00:00, 699.72it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.0001 , lambda: 1e-05 recall: ', 35)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:32<00:00,  6.57it/s]\n",
      "  0%|          | 67/40672 [00:00<01:01, 665.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:00<00:00, 674.90it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.001 , lambda: 0.1 recall: ', 90)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:35<00:00,  6.42it/s]\n",
      "  0%|          | 66/40672 [00:00<01:02, 651.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:57<00:00, 707.02it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.001 , lambda: 0.01 recall: ', 6)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:41<00:00,  6.19it/s]\n",
      "  0%|          | 64/40672 [00:00<01:03, 638.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:50<00:00, 803.57it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.001 , lambda: 0.001 recall: ', 31)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:37<00:00,  6.35it/s]\n",
      "  0%|          | 38/40672 [00:00<01:50, 369.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:58<00:00, 689.62it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.001 , lambda: 0.0001 recall: ', 65)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:38<00:00,  6.30it/s]\n",
      "  0%|          | 65/40672 [00:00<01:02, 649.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:53<00:00, 759.96it/s]\n",
      "  0%|          | 1/1000 [00:00<02:31,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.001 , lambda: 1e-05 recall: ', 99)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:42<00:00,  6.16it/s]\n",
      "  0%|          | 63/40672 [00:00<01:04, 629.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:57<00:00, 702.78it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.01 , lambda: 0.1 recall: ', 100)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:35<00:00,  6.45it/s]\n",
      "  0%|          | 62/40672 [00:00<01:05, 616.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:01<00:00, 664.96it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.01 , lambda: 0.01 recall: ', 95)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:33<00:00,  6.52it/s]\n",
      "  0%|          | 67/40672 [00:00<01:01, 663.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:59<00:00, 679.24it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.01 , lambda: 0.001 recall: ', 44)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:37<00:00,  6.36it/s]\n",
      "  0%|          | 30/40672 [00:00<02:16, 296.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:55<00:00, 732.53it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.01 , lambda: 0.0001 recall: ', 54)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:36<00:00,  6.38it/s]\n",
      "  0%|          | 66/40672 [00:00<01:02, 653.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:58<00:00, 691.35it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.01 , lambda: 1e-05 recall: ', 10)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:44<00:00,  6.09it/s]\n",
      "  0%|          | 54/40672 [00:00<01:16, 532.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:58<00:00, 691.40it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.1 , lambda: 0.1 recall: ', 100)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:25<00:00,  4.88it/s]\n",
      "  0%|          | 84/40672 [00:00<00:48, 838.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [00:53<00:00, 766.42it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.1 , lambda: 0.01 recall: ', 100)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:30<00:00,  4.74it/s]\n",
      "  0%|          | 34/40672 [00:00<02:02, 332.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:01<00:00, 663.32it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.1 , lambda: 0.001 recall: ', 95)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:41<00:00,  4.52it/s]\n",
      "  0%|          | 69/40672 [00:00<00:59, 685.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:00<00:00, 672.10it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.1 , lambda: 0.0001 recall: ', 45)\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:41<00:00,  4.52it/s]\n",
      "  0%|          | 68/40672 [00:00<00:59, 678.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40672/40672 [01:00<00:00, 677.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall with gamma: 0.1 , lambda: 1e-05 recall: ', 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gamma_values = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "lambda_values = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "for g in gamma_values:\n",
    "    for l in lambda_values:\n",
    "        model = ConvNet()\n",
    "        model.apply(weights_init)\n",
    "        model.to(device)\n",
    "        print(\"Training...\")\n",
    "        sgd(t=1000, gamma=g, lamb=l)\n",
    "        print(\"Evaluating...\")\n",
    "        recall = evaluate()\n",
    "        print(\"Recall with gamma: \"+ str(g) + \" , lambda: \" + str(l) + \" recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC --> Ordering graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
